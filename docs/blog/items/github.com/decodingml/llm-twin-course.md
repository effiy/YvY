# 原始URL: https://github.com/decodingml/llm-twin-course

# 抓取时间: 2025-03-30 21:17:18

[Skip to content](https://github.com/decodingml/llm-twin-course#start-of-content)
## Navigation Menu
Toggle navigation
[ ](https://github.com/)
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fdecodingml%2Fllm-twin-course)
  * Product 
    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)
    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)
    * [ Actions Automate any workflow  ](https://github.com/features/actions)
    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)
    * [ Issues Plan and track work  ](https://github.com/features/issues)
    * [ Code Review Manage code changes  ](https://github.com/features/code-review)
    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)
    * [ Code Search Find more, search less  ](https://github.com/features/code-search)
Explore
    * [ All features ](https://github.com/features)
    * [ Documentation ](https://docs.github.com)
    * [ GitHub Skills ](https://skills.github.com)
    * [ Blog ](https://github.blog)
  * Solutions 
By company size
    * [ Enterprises ](https://github.com/enterprise)
    * [ Small and medium teams ](https://github.com/team)
    * [ Startups ](https://github.com/enterprise/startups)
    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)
By use case
    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)
    * [ DevOps ](https://github.com/solutions/use-case/devops)
    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)
    * [ View all use cases ](https://github.com/solutions/use-case)
By industry
    * [ Healthcare ](https://github.com/solutions/industry/healthcare)
    * [ Financial services ](https://github.com/solutions/industry/financial-services)
    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)
    * [ Government ](https://github.com/solutions/industry/government)
    * [ View all industries ](https://github.com/solutions/industry)
[ View all solutions ](https://github.com/solutions)
  * Resources 
Topics
    * [ AI ](https://github.com/resources/articles/ai)
    * [ DevOps ](https://github.com/resources/articles/devops)
    * [ Security ](https://github.com/resources/articles/security)
    * [ Software Development ](https://github.com/resources/articles/software-development)
    * [ View all ](https://github.com/resources/articles)
Explore
    * [ Learning Pathways ](https://resources.github.com/learn/pathways)
    * [ Events & Webinars ](https://resources.github.com)
    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)
    * [ Customer Stories ](https://github.com/customer-stories)
    * [ Partners ](https://partner.github.com)
    * [ Executive Insights ](https://github.com/solutions/executive-insights)
  * Open Source 
    * [ GitHub Sponsors Fund open source developers  ](https://github.com/sponsors)
    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)
Repositories
    * [ Topics ](https://github.com/topics)
    * [ Trending ](https://github.com/trending)
    * [ Collections ](https://github.com/collections)
  * Enterprise 
    * [ Enterprise platform AI-powered developer platform  ](https://github.com/enterprise)
Available add-ons
    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)
    * [ Copilot for business Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)
    * [ Premium Support Enterprise-grade 24/7 support  ](https://github.com/premium-support)
  * [Pricing](https://github.com/pricing)


Search or jump to...
# Search code, repositories, users, issues, pull requests...
Search 
Clear
[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)
#  Provide feedback 
We read every piece of feedback, and take your input very seriously.
Include my email address so I can be contacted
Cancel  Submit feedback 
#  Saved searches 
## Use saved searches to filter your results more quickly
Name
Query
To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). 
Cancel  Create saved search 
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fdecodingml%2Fllm-twin-course)
[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=decodingml%2Fllm-twin-course) Reseting focus
You signed in with another tab or window. [Reload](https://github.com/decodingml/llm-twin-course) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/decodingml/llm-twin-course) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/decodingml/llm-twin-course) to refresh your session. Dismiss alert
{{ message }}
[ decodingml ](https://github.com/decodingml) / **[llm-twin-course](https://github.com/decodingml/llm-twin-course) ** Public
  * [ Notifications ](https://github.com/login?return_to=%2Fdecodingml%2Fllm-twin-course) You must be signed in to change notification settings
  * [ Fork 622 ](https://github.com/login?return_to=%2Fdecodingml%2Fllm-twin-course)
  * [ Star  3.8k ](https://github.com/login?return_to=%2Fdecodingml%2Fllm-twin-course)


🤖 𝗟𝗲𝗮𝗿𝗻 for 𝗳𝗿𝗲𝗲 how to 𝗯𝘂𝗶𝗹𝗱 an end-to-end 𝗽𝗿𝗼𝗱𝘂𝗰𝘁𝗶𝗼𝗻-𝗿𝗲𝗮𝗱𝘆 𝗟𝗟𝗠 & 𝗥𝗔𝗚 𝘀𝘆𝘀𝘁𝗲𝗺 using 𝗟𝗟𝗠𝗢𝗽𝘀 best practices: ~ 𝘴𝘰𝘶𝘳𝘤𝘦 𝘤𝘰𝘥𝘦 + 12 𝘩𝘢𝘯𝘥𝘴-𝘰𝘯 𝘭𝘦𝘴𝘴𝘰𝘯𝘴 
### License
[ MIT license ](https://github.com/decodingml/llm-twin-course/blob/main/LICENSE)
[ 3.8k stars ](https://github.com/decodingml/llm-twin-course/stargazers) [ 622 forks ](https://github.com/decodingml/llm-twin-course/forks) [ Branches ](https://github.com/decodingml/llm-twin-course/branches) [ Tags ](https://github.com/decodingml/llm-twin-course/tags) [ Activity ](https://github.com/decodingml/llm-twin-course/activity)
[ Star  ](https://github.com/login?return_to=%2Fdecodingml%2Fllm-twin-course)
[ Notifications ](https://github.com/login?return_to=%2Fdecodingml%2Fllm-twin-course) You must be signed in to change notification settings
  * [ Code ](https://github.com/decodingml/llm-twin-course)
  * [ Issues 4 ](https://github.com/decodingml/llm-twin-course/issues)
  * [ Pull requests 0 ](https://github.com/decodingml/llm-twin-course/pulls)
  * [ Actions ](https://github.com/decodingml/llm-twin-course/actions)
  * [ Projects 0 ](https://github.com/decodingml/llm-twin-course/projects)
  * [ Security ](https://github.com/decodingml/llm-twin-course/security)
  * [ Insights ](https://github.com/decodingml/llm-twin-course/pulse)


Additional navigation options
  * [ Code  ](https://github.com/decodingml/llm-twin-course)
  * [ Issues  ](https://github.com/decodingml/llm-twin-course/issues)
  * [ Pull requests  ](https://github.com/decodingml/llm-twin-course/pulls)
  * [ Actions  ](https://github.com/decodingml/llm-twin-course/actions)
  * [ Projects  ](https://github.com/decodingml/llm-twin-course/projects)
  * [ Security  ](https://github.com/decodingml/llm-twin-course/security)
  * [ Insights  ](https://github.com/decodingml/llm-twin-course/pulse)


# decodingml/llm-twin-course
main
[Branches](https://github.com/decodingml/llm-twin-course/branches)[Tags](https://github.com/decodingml/llm-twin-course/tags)
[](https://github.com/decodingml/llm-twin-course/branches)[](https://github.com/decodingml/llm-twin-course/tags)
Go to file
Code
## Folders and files
Name| Name| Last commit message| Last commit date  
---|---|---|---  
## Latest commit
## History
[321 Commits](https://github.com/decodingml/llm-twin-course/commits/main/)[](https://github.com/decodingml/llm-twin-course/commits/main/)  
[.docker](https://github.com/decodingml/llm-twin-course/tree/main/.docker ".docker")| [.docker](https://github.com/decodingml/llm-twin-course/tree/main/.docker ".docker")  
[.github](https://github.com/decodingml/llm-twin-course/tree/main/.github ".github")| [.github](https://github.com/decodingml/llm-twin-course/tree/main/.github ".github")  
[data](https://github.com/decodingml/llm-twin-course/tree/main/data "data")| [data](https://github.com/decodingml/llm-twin-course/tree/main/data "data")  
[media](https://github.com/decodingml/llm-twin-course/tree/main/media "media")| [media](https://github.com/decodingml/llm-twin-course/tree/main/media "media")  
[src](https://github.com/decodingml/llm-twin-course/tree/main/src "src")| [src](https://github.com/decodingml/llm-twin-course/tree/main/src "src")  
[.env.example](https://github.com/decodingml/llm-twin-course/blob/main/.env.example ".env.example")| [.env.example](https://github.com/decodingml/llm-twin-course/blob/main/.env.example ".env.example")  
[.gitignore](https://github.com/decodingml/llm-twin-course/blob/main/.gitignore ".gitignore")| [.gitignore](https://github.com/decodingml/llm-twin-course/blob/main/.gitignore ".gitignore")  
[.python-version](https://github.com/decodingml/llm-twin-course/blob/main/.python-version ".python-version")| [.python-version](https://github.com/decodingml/llm-twin-course/blob/main/.python-version ".python-version")  
[INSTALL_AND_USAGE.md](https://github.com/decodingml/llm-twin-course/blob/main/INSTALL_AND_USAGE.md "INSTALL_AND_USAGE.md")| [INSTALL_AND_USAGE.md](https://github.com/decodingml/llm-twin-course/blob/main/INSTALL_AND_USAGE.md "INSTALL_AND_USAGE.md")  
[LICENSE](https://github.com/decodingml/llm-twin-course/blob/main/LICENSE "LICENSE")| [LICENSE](https://github.com/decodingml/llm-twin-course/blob/main/LICENSE "LICENSE")  
[Makefile](https://github.com/decodingml/llm-twin-course/blob/main/Makefile "Makefile")| [Makefile](https://github.com/decodingml/llm-twin-course/blob/main/Makefile "Makefile")  
[README.md](https://github.com/decodingml/llm-twin-course/blob/main/README.md "README.md")| [README.md](https://github.com/decodingml/llm-twin-course/blob/main/README.md "README.md")  
[docker-compose-superlinked.yml](https://github.com/decodingml/llm-twin-course/blob/main/docker-compose-superlinked.yml "docker-compose-superlinked.yml")| [docker-compose-superlinked.yml](https://github.com/decodingml/llm-twin-course/blob/main/docker-compose-superlinked.yml "docker-compose-superlinked.yml")  
[docker-compose.yml](https://github.com/decodingml/llm-twin-course/blob/main/docker-compose.yml "docker-compose.yml")| [docker-compose.yml](https://github.com/decodingml/llm-twin-course/blob/main/docker-compose.yml "docker-compose.yml")  
[poetry.lock](https://github.com/decodingml/llm-twin-course/blob/main/poetry.lock "poetry.lock")| [poetry.lock](https://github.com/decodingml/llm-twin-course/blob/main/poetry.lock "poetry.lock")  
[pyproject.toml](https://github.com/decodingml/llm-twin-course/blob/main/pyproject.toml "pyproject.toml")| [pyproject.toml](https://github.com/decodingml/llm-twin-course/blob/main/pyproject.toml "pyproject.toml")  
View all files  
## Repository files navigation
  * [README](https://github.com/decodingml/llm-twin-course)
  * [MIT license](https://github.com/decodingml/llm-twin-course)


## LLM Twin Course: Building Your Production-Ready AI Replica
[](https://github.com/decodingml/llm-twin-course#llm-twin-course-building-your-production-ready-ai-replica)
# Learn to architect and implement a production-ready LLM & RAG system by building your LLM Twin
[](https://github.com/decodingml/llm-twin-course#learn-to-architect-and-implement-a-production-ready-llm--rag-system-by-building-your-llm-twin)
### From data gathering to productionizing LLMs using LLMOps good practices.
[](https://github.com/decodingml/llm-twin-course#from-data-gathering-to-productionizing-llms-using-llmops-good-practices)
_by[Decoding ML](https://decodingml.substack.com)_
[![Your image description](https://github.com/decodingml/llm-twin-course/raw/main/media/cover.png)](https://github.com/decodingml/llm-twin-course/blob/main/media/cover.png)
## 🎯 What you'll learn
[](https://github.com/decodingml/llm-twin-course#-what-youll-learn)
_By finishing the**"LLM Twin: Building Your Production-Ready AI Replica"** free course, you will learn how to design, train, and deploy a production-ready LLM twin of yourself powered by LLMs, vector DBs, and LLMOps good practices._
**No more isolated scripts or Notebooks!** Learn production ML by building and deploying an end-to-end production-grade LLM system.
## 📖 About this course
[](https://github.com/decodingml/llm-twin-course#-about-this-course)
You will **learn** how to **architect** and **build a real-world LLM system** from **start** to **finish** - from **data collection** to **deployment**.
You will also **learn** to **leverage MLOps best practices** , such as experiment trackers, model registries, prompt monitoring, and versioning.
**The end goal?** Build and deploy your own LLM twin.
**What is an LLM Twin?** It is an AI character that learns to write like somebody by incorporating its style and personality into an LLM.
## 🪈 The architecture of the LLM Twin is split into 4 Python microservices
[](https://github.com/decodingml/llm-twin-course#-the-architecture-of-the-llm-twin-is-split-into-4-python-microservices)
[![LLM Twin Architecture](https://github.com/decodingml/llm-twin-course/raw/main/media/architecture.png)](https://github.com/decodingml/llm-twin-course/blob/main/media/architecture.png)
### The data collection pipeline
[](https://github.com/decodingml/llm-twin-course#the-data-collection-pipeline)
  * Crawl your digital data from various social media platforms, such as Medium, Substack and GitHub.
  * Clean, normalize and load the data to a [Mongo NoSQL DB](https://www.mongodb.com/) through a series of ETL pipelines.
  * Send database changes to a [RabbitMQ](https://www.rabbitmq.com/) queue using the CDC pattern.
  * Learn to package the crawlers as AWS Lambda functions.


### The feature pipeline
[](https://github.com/decodingml/llm-twin-course#the-feature-pipeline)
  * Consume messages in real-time from a queue through a [Bytewax](https://github.com/bytewax/bytewax?utm_source=github&utm_medium=decodingml&utm_campaign=2024_q1) streaming pipeline.
  * Every message will be cleaned, chunked, embedded and loaded into a [Qdrant](https://qdrant.tech/?utm_source=decodingml&utm_medium=referral&utm_campaign=llm-course) vector DB.
  * In the bonus series, we refactor the cleaning, chunking, and embedding logic using [Superlinked](https://github.com/superlinked/superlinked?utm_source=community&utm_medium=github&utm_campaign=oscourse), a specialized vector compute engine. We will also load and index the vectors to a [Redis vector DB](https://redis.io/solutions/vector-search/).


### The training pipeline
[](https://github.com/decodingml/llm-twin-course#the-training-pipeline)
  * Create a custom instruction dataset based on your custom digital data to do SFT.
  * Fine-tune an LLM using LoRA or QLoRA.
  * Use [Comet ML's](https://www.comet.com/signup/?utm_source=decoding_ml&utm_medium=partner&utm_content=github) experiment tracker to monitor the experiments.
  * Evaluate the LLM using [Opik](https://github.com/comet-ml/opik)
  * Save and version the best model to the [Hugging Face model registry](https://huggingface.co/models).
  * Run and automate the training pipeline using [AWS SageMaker](https://aws.amazon.com/sagemaker/).


### The inference pipeline
[](https://github.com/decodingml/llm-twin-course#the-inference-pipeline)
  * Load the fine-tuned LLM from the [Hugging Face model registry](https://huggingface.co/models).
  * Deploy the LLM as a scalable REST API using [AWS SageMaker inference endpoints](https://aws.amazon.com/sagemaker/deploy/).
  * Enhance the prompts using advanced RAG techniques.
  * Monitor the prompts and LLM generated results using [Opik](https://github.com/comet-ml/opik)
  * In the bonus series, we refactor the advanced RAG layer to write more optimal queries using [Superlinked](https://github.com/superlinked/superlinked?utm_source=community&utm_medium=github&utm_campaign=oscourse).
  * Wrap up everything with a Gradio UI (as seen below) where you can start playing around with the LLM Twin to generate content that follows your writing style.


[![Gradio UI](https://github.com/decodingml/llm-twin-course/raw/main/media/ui-example.png)](https://github.com/decodingml/llm-twin-course/blob/main/media/ui-example.png)
Along the 4 microservices, you will learn to integrate 4 serverless tools:
  * [Comet ML](https://www.comet.com/signup/?utm_source=decoding_ml&utm_medium=partner&utm_content=github) as your experiment tracker and data registry;
  * [Qdrant](https://qdrant.tech/?utm_source=decodingml&utm_medium=referral&utm_campaign=llm-course) as your vector DB;
  * [AWS SageMaker](https://aws.amazon.com/sagemaker/) as your ML infrastructure;
  * [Opik](https://github.com/comet-ml/opik) as your prompt evaluation and monitoring tool.

[ ![Decoding ML Logo](https://private-user-images.githubusercontent.com/28981860/419857963-f2f2f9c0-54b7-4ae3-bf8d-23a359c86982.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDMzNDA5MzIsIm5iZiI6MTc0MzM0MDYzMiwicGF0aCI6Ii8yODk4MTg2MC80MTk4NTc5NjMtZjJmMmY5YzAtNTRiNy00YWUzLWJmOGQtMjNhMzU5Yzg2OTgyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMzAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzMwVDEzMTcxMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThmYzFhNmNmMjNiZTNkNWMxNDcxYTUwOTZmZWM2MDU4OTQ1ZGRhOWM3NDRjMGQ3MmNlNThhYmExMWVlOWQyY2QmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.WG46GwCS7ytIRhSY-5woL1doUhifHSeO_nXlTMbaXA4) ](https://decodingml.substack.com/) | 
## 📬 Stay Updated
[](https://github.com/decodingml/llm-twin-course#-stay-updated) **[Join Decoding ML](https://decodingml.substack.com/)** for proven content on production-grade AI, GenAI, and information retrieval systems. Every week, straight to your inbox.  
---|---  
[ ![Subscribe Now](https://camo.githubusercontent.com/13d91d0d4ebb11dafadd168e2ac0a002a0d91dfe2c5a87c3ae9d05d8313ad657/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c266c6f676f3d737562737461636b266d6573736167653d537562736372696265204e6f77267374796c653d666f722d7468652d626164676526636f6c6f723d626c61636b267363616c653d32) ](https://decodingml.substack.com/)
## 👥 Who should join?
[](https://github.com/decodingml/llm-twin-course#-who-should-join)
**This course is ideal for:**
  * ML/AI engineers who want to learn to engineer production-ready LLM & RAG systems using LLMOps good principles
  * Data Engineers, Data Scientists, and Software Engineers wanting to understand the engineering behind LLM & RAG systems


**Note:** This course focuses on engineering practices and end-to-end system implementation rather than theoretical model optimization or research.
## 🎓 Prerequisites
[](https://github.com/decodingml/llm-twin-course#-prerequisites)
Category | Requirements  
---|---  
**Skills** | Basic understanding of Python and Machine Learning  
**Hardware** | Any modern laptop/workstation will do the job, as the LLM fine-tuning and inference will be done on AWS SageMaker.  
**Level** | Intermediate  
## 💰 Cost structure
[](https://github.com/decodingml/llm-twin-course#-cost-structure)
All tools used throughout the course will stick to their free tier, except:
  * OpenAI's API, which will cost ~$1
  * AWS for fine-tuning and inference, which will cost < $10 depending on how much you play around with our scripts and your region.


## 🥂 Open-source course: Participation is open and Free
[](https://github.com/decodingml/llm-twin-course#-open-source-course-participation-is-open-and-free)
As an open-source course, you don't have to enroll. Everything is self-paced, free of charge and with its resources freely accessible as follows:
  * **code** : this GitHub repository
  * **articles** : [Decoding ML](https://medium.com/decodingml/llm-twin-course/home)


## 📚 How will you learn?
[](https://github.com/decodingml/llm-twin-course#-how-will-youlearn)
The course contains **10 hands-on written lessons** and the **open-source code** you can access on GitHub, showing how to build an end-to-end LLM system.
Also, it includes **2 bonus lessons** on how to **improve the RAG system**.
You can read everything at your own pace.
## Lessons
[](https://github.com/decodingml/llm-twin-course#lessons)
This self-paced course consists of 12 comprehensive lessons covering theory, system design, and hands-on implementation.
Our recommendation for each module:
  1. Read the article
  2. Run the code to replicate our results
  3. Go deeper into the code by reading the `src` Python modules


Note
Check the [INSTALL_AND_USAGE](https://github.com/decodingml/llm-twin-course/blob/main/INSTALL_AND_USAGE.md) doc for a step-by-step installation and usage guide.
Lesson | Article | Category | Description | Source Code  
---|---|---|---|---  
1 | [An End-to-End Framework for Production-Ready LLM Systems](https://medium.com/decodingml/an-end-to-end-framework-for-production-ready-llm-systems-by-building-your-llm-twin-2cc6bb01141f) | System Design | Learn the overall architecture and design principles of production LLM systems. | No code  
2 | [Data Crawling](https://medium.com/decodingml/your-content-is-gold-i-turned-3-years-of-blog-posts-into-an-llm-training-d19c265bdd6e) | Data Engineering | Learn to crawl and process social media content for LLM training. | `src/data_crawling`  
3 | [CDC Magic](https://medium.com/decodingml/i-replaced-1000-lines-of-polling-code-with-50-lines-of-cdc-magic-4d31abd3bc3b) | Data Engineering | Learn to implement Change Data Capture (CDC) for syncing two data sources. | `src/data_cdc`  
4 | [Feature Streaming Pipelines](https://medium.com/decodingml/sota-python-streaming-pipelines-for-fine-tuning-llms-and-rag-in-real-time-82eb07795b87) | Feature Pipeline | Build real-time streaming pipelines for LLM and RAG data processing. | `src/feature_pipeline`  
5 | [Advanced RAG Algorithms](https://medium.com/decodingml/the-4-advanced-rag-algorithms-you-must-know-to-implement-5d0c7f1199d2) | Feature Pipeline | Implement advanced RAG techniques for better retrieval. | `src/feature_pipeline`  
6 | [Generate Fine-Tuning Instruct Datasets](https://medium.com/decodingml/turning-raw-data-into-fine-tuning-datasets-dc83657d1280) | Training Pipeline | Create custom instruct datasets for LLM fine-tuning. | `src/feature_pipeline/generate_dataset`  
7 | [LLM Fine-tuning Pipeline](https://medium.com/decodingml/8b-parameters-1-gpu-no-problems-the-ultimate-llm-fine-tuning-pipeline-f68ef6c359c2) | Training Pipeline | Build an end-to-end LLM fine-tuning pipeline and deploy it to AWS SageMaker. | `src/training_pipeline`  
8 | [LLM & RAG Evaluation](https://medium.com/decodingml/the-engineers-framework-for-llm-rag-evaluation-59897381c326) | Training Pipeline | Learn to evaluate LLM and RAG system performance. | `src/inference_pipeline/evaluation`  
9 | [Implement and Deploy the RAG Inference Pipeline](https://medium.com/decodingml/beyond-proof-of-concept-building-rag-systems-that-scale-e537d0eb063a) | Inference Pipeline | Design, implement and deploy the RAG inference to AWS SageMaker. | `src/inference_pipeline`  
10 | [Prompt Monitoring](https://medium.com/decodingml/the-ultimate-prompt-monitoring-pipeline-886cbb75ae25) | Inference Pipeline | Build the prompt monitoring and production evaluation pipeline. | `src/inference_pipeline`  
11 | [Refactor the RAG module using 74.3% Less Code ](https://medium.com/decodingml/build-a-scalable-rag-ingestion-pipeline-using-74-3-less-code-ac50095100d6) | Bonus on RAG | Optimize the RAG system. | `src/bonus_superlinked_rag`  
12 | [Multi-Index RAG Apps](https://medium.com/decodingml/build-multi-index-advanced-rag-apps-bd33d2f0ec5c) | Bonus on RAG | Build advanced multi-index RAG apps. | `src/bonus_superlinked_rag`  
[ ![Decoding ML Logo](https://private-user-images.githubusercontent.com/28981860/419857963-f2f2f9c0-54b7-4ae3-bf8d-23a359c86982.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDMzNDA5MzIsIm5iZiI6MTc0MzM0MDYzMiwicGF0aCI6Ii8yODk4MTg2MC80MTk4NTc5NjMtZjJmMmY5YzAtNTRiNy00YWUzLWJmOGQtMjNhMzU5Yzg2OTgyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMzAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzMwVDEzMTcxMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThmYzFhNmNmMjNiZTNkNWMxNDcxYTUwOTZmZWM2MDU4OTQ1ZGRhOWM3NDRjMGQ3MmNlNThhYmExMWVlOWQyY2QmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.WG46GwCS7ytIRhSY-5woL1doUhifHSeO_nXlTMbaXA4) ](https://decodingml.substack.com/) | 
## 📬 Stay Updated
[](https://github.com/decodingml/llm-twin-course#-stay-updated-1) **[Join Decoding ML](https://decodingml.substack.com/)** for proven content on production-grade AI, GenAI, and information retrieval systems. Every week, straight to your inbox.  
---|---  
[ ![Subscribe Now](https://camo.githubusercontent.com/13d91d0d4ebb11dafadd168e2ac0a002a0d91dfe2c5a87c3ae9d05d8313ad657/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c266c6f676f3d737562737461636b266d6573736167653d537562736372696265204e6f77267374796c653d666f722d7468652d626164676526636f6c6f723d626c61636b267363616c653d32) ](https://decodingml.substack.com/)
## 🏗️ Project Structure
[](https://github.com/decodingml/llm-twin-course#️-project-structure)
At Decoding ML we teach how to build production ML systems, thus the course follows the structure of a real-world Python project:
```
llm-twin-course/
├── src/           # Source code for all the ML pipelines and services
│ ├── data_crawling/     # Data collection pipeline code
│ ├── data_cdc/       # Change Data Capture (CDC) pipeline code
│ ├── feature_pipeline/   # Feature engineering pipeline code
│ ├── training_pipeline/   # Training pipeline code
│ ├── inference_pipeline/  # Inference service code
│ └── bonus_superlinked_rag/ # Bonus RAG optimization code
├── .env.example       # Example environment variables template
├── Makefile         # Commands to build and run the project
├── pyproject.toml      # Project dependencies

```

## 🚀 Install & Usage
[](https://github.com/decodingml/llm-twin-course#-install--usage)
To understand how to **install and run the LLM Twin code end-to-end** , go to the [INSTALL_AND_USAGE](https://github.com/decodingml/llm-twin-course/blob/main/INSTALL_AND_USAGE.md) dedicated document.
Note
Even though you can run everything solely using the [INSTALL_AND_USAGE](https://github.com/decodingml/llm-twin-course/blob/main/INSTALL_AND_USAGE.md) dedicated document, we recommend that you read the articles to understand the LLM Twin system and design choices fully.
## 💡 Questions and troubleshooting
[](https://github.com/decodingml/llm-twin-course#-questions-and-troubleshooting)
Have questions or running into issues? We're here to help!
Open a [GitHub issue](https://github.com/decodingml/llm-twin-course/issues) for:
  * Questions about the course material
  * Technical troubleshooting
  * Clarification on concepts


## 🥂 Contributing
[](https://github.com/decodingml/llm-twin-course#-contributing)
As an open-source course, we may not be able to fix all the bugs that arise.
If you find any bugs and know how to fix them, support future readers by contributing to this course with your bug fix.
We will deeply appreciate your support for the AI community and future readers 🤗
## Contributors
[](https://github.com/decodingml/llm-twin-course#contributors)
A big "Thank you 🙏" to all our contributors! This course is possible only because of their efforts.
[ ![](https://camo.githubusercontent.com/fcab25ccfd1fdc6af12a8b8922bfa638261ce456bdaed33f5c81c2c9b88656c3/68747470733a2f2f636f6e747269622e726f636b732f696d6167653f7265706f3d6465636f64696e676d6c2f6c6c6d2d7477696e2d636f75727365) ](https://github.com/decodingml/llm-twin-course/graphs/contributors)
## Sponsors
[](https://github.com/decodingml/llm-twin-course#sponsors)
Also, another big "Thank you 🙏" to all our sponsors who supported our work and made this course possible.
[Comet](https://www.comet.com/signup/?utm_source=decoding_ml&utm_medium=partner&utm_content=github) |  [Opik](https://github.com/comet-ml/opik) |  [Bytewax](https://github.com/bytewax/bytewax?utm_source=github&utm_medium=decodingml&utm_campaign=2024_q1) |  [Qdrant](https://qdrant.tech/?utm_source=decodingml&utm_medium=referral&utm_campaign=llm-course) |  [Superlinked](https://github.com/superlinked/superlinked?utm_source=community&utm_medium=github&utm_campaign=oscourse)  
---|---|---|---|---  
[ ![Comet](https://github.com/decodingml/llm-twin-course/raw/main/media/sponsors/comet.png) ](https://www.comet.com/signup/?utm_source=decoding_ml&utm_medium=partner&utm_content=github) |  [ ![Opik](https://github.com/decodingml/llm-twin-course/raw/main/media/sponsors/opik.svg) ](https://github.com/comet-ml/opik) |  [ ![Bytewax](https://github.com/decodingml/llm-twin-course/raw/main/media/sponsors/bytewax.png) ](https://github.com/bytewax/bytewax?utm_source=github&utm_medium=decodingml&utm_campaign=2024_q1) |  [ ![Qdrant](https://github.com/decodingml/llm-twin-course/raw/main/media/sponsors/qdrant.svg) ](https://qdrant.tech/?utm_source=decodingml&utm_medium=referral&utm_campaign=llm-course) |  [ ![Superlinked](https://github.com/decodingml/llm-twin-course/raw/main/media/sponsors/superlinked.svg) ](https://github.com/superlinked/superlinked?utm_source=community&utm_medium=github&utm_campaign=oscourse)  
## Next steps
[](https://github.com/decodingml/llm-twin-course#next-steps)
Our **LLM Engineer’s Handbook** inspired the **open-source LLM Twin course**.
Consider supporting our work by getting our book to **learn** a **complete framework** for **building and deploying production LLM & RAG systems** — from data to deployment.
Perfect for practitioners who want **both theory** and **hands-on** expertise by connecting the dots between DE, research, MLE and MLOps:
**[Buy the LLM Engineer’s Handbook](https://www.amazon.com/LLM-Engineers-Handbook-engineering-production/dp/1836200072/)**
  * [On Amazon](https://www.amazon.com/LLM-Engineers-Handbook-engineering-production/dp/1836200072/)
  * [On Packt](https://www.packtpub.com/en-us/product/llm-engineers-handbook-9781836200062)


[ ![LLM Engineer's Handbook](https://github.com/decodingml/llm-twin-course/raw/main/media/llm_engineers_handbook_cover.png) ](https://www.amazon.com/LLM-Engineers-Handbook-engineering-production/dp/1836200072/)
## License
[](https://github.com/decodingml/llm-twin-course#license)
This course is an open-source project released under the MIT license. Thus, as long you distribute our LICENSE and acknowledge our work, you can safely clone or fork this project and use it as a source of inspiration for whatever you want (e.g., university projects, college degree projects, personal projects, etc.).
[ ![Decoding ML Logo](https://private-user-images.githubusercontent.com/28981860/419857963-f2f2f9c0-54b7-4ae3-bf8d-23a359c86982.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDMzNDA5MzIsIm5iZiI6MTc0MzM0MDYzMiwicGF0aCI6Ii8yODk4MTg2MC80MTk4NTc5NjMtZjJmMmY5YzAtNTRiNy00YWUzLWJmOGQtMjNhMzU5Yzg2OTgyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMzAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzMwVDEzMTcxMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThmYzFhNmNmMjNiZTNkNWMxNDcxYTUwOTZmZWM2MDU4OTQ1ZGRhOWM3NDRjMGQ3MmNlNThhYmExMWVlOWQyY2QmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.WG46GwCS7ytIRhSY-5woL1doUhifHSeO_nXlTMbaXA4) ](https://decodingml.substack.com/) | 
## 📬 Stay Updated
[](https://github.com/decodingml/llm-twin-course#-stay-updated-2) **[Join Decoding ML](https://decodingml.substack.com/)** for proven content on production-grade AI, GenAI, and information retrieval systems. Every week, straight to your inbox.  
---|---  
[ ![Subscribe Now](https://camo.githubusercontent.com/13d91d0d4ebb11dafadd168e2ac0a002a0d91dfe2c5a87c3ae9d05d8313ad657/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c266c6f676f3d737562737461636b266d6573736167653d537562736372696265204e6f77267374796c653d666f722d7468652d626164676526636f6c6f723d626c61636b267363616c653d32) ](https://decodingml.substack.com/)
## About
🤖 𝗟𝗲𝗮𝗿𝗻 for 𝗳𝗿𝗲𝗲 how to 𝗯𝘂𝗶𝗹𝗱 an end-to-end 𝗽𝗿𝗼𝗱𝘂𝗰𝘁𝗶𝗼𝗻-𝗿𝗲𝗮𝗱𝘆 𝗟𝗟𝗠 & 𝗥𝗔𝗚 𝘀𝘆𝘀𝘁𝗲𝗺 using 𝗟𝗟𝗠𝗢𝗽𝘀 best practices: ~ 𝘴𝘰𝘶𝘳𝘤𝘦 𝘤𝘰𝘥𝘦 + 12 𝘩𝘢𝘯𝘥𝘴-𝘰𝘯 𝘭𝘦𝘴𝘴𝘰𝘯𝘴 
### Topics
[ docker ](https://github.com/topics/docker "Topic: docker") [ aws ](https://github.com/topics/aws "Topic: aws") [ course ](https://github.com/topics/course "Topic: course") [ infrastructure-as-code ](https://github.com/topics/infrastructure-as-code "Topic: infrastructure-as-code") [ machine-learning-engineering ](https://github.com/topics/machine-learning-engineering "Topic: machine-learning-engineering") [ comet-ml ](https://github.com/topics/comet-ml "Topic: comet-ml") [ rag ](https://github.com/topics/rag "Topic: rag") [ mlops ](https://github.com/topics/mlops "Topic: mlops") [ pulumi ](https://github.com/topics/pulumi "Topic: pulumi") [ qdrant ](https://github.com/topics/qdrant "Topic: qdrant") [ large-language-models ](https://github.com/topics/large-language-models "Topic: large-language-models") [ bytewax ](https://github.com/topics/bytewax "Topic: bytewax") [ generative-ai ](https://github.com/topics/generative-ai "Topic: generative-ai") [ qwak ](https://github.com/topics/qwak "Topic: qwak") [ llmops ](https://github.com/topics/llmops "Topic: llmops") [ ml-system-design ](https://github.com/topics/ml-system-design "Topic: ml-system-design") [ superlinked ](https://github.com/topics/superlinked "Topic: superlinked")
### Resources
[ Readme ](https://github.com/decodingml/llm-twin-course#readme-ov-file)
### License
[ MIT license ](https://github.com/decodingml/llm-twin-course#MIT-1-ov-file)
[ Activity](https://github.com/decodingml/llm-twin-course/activity)
[ Custom properties](https://github.com/decodingml/llm-twin-course/custom-properties)
### Stars
[ **3.8k** stars](https://github.com/decodingml/llm-twin-course/stargazers)
### Watchers
[ **73** watching](https://github.com/decodingml/llm-twin-course/watchers)
### Forks
[ **622** forks](https://github.com/decodingml/llm-twin-course/forks)
[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fdecodingml%2Fllm-twin-course&report=decodingml+%28user%29)
##  [Contributors 8](https://github.com/decodingml/llm-twin-course/graphs/contributors)
## Languages
  * [ Python 96.3% ](https://github.com/decodingml/llm-twin-course/search?l=python)
  * [ Makefile 2.1% ](https://github.com/decodingml/llm-twin-course/search?l=makefile)
  * Other 1.6%


## Footer
[ ](https://github.com "GitHub") © 2025 GitHub, Inc. 
### Footer navigation
  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
  * [Security](https://github.com/security)
  * [Status](https://www.githubstatus.com/)
  * [Docs](https://docs.github.com/)
  * [Contact](https://support.github.com?tags=dotcom-footer)
  * Manage cookies 
  * Do not share my personal information 


You can’t perform that action at this time. 
