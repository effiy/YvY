# 原始URL: https://github.com/collabora/WhisperSpeech

# 抓取时间: 2025-03-30 21:16:51

[Skip to content](https://github.com/collabora/WhisperSpeech#start-of-content)
## Navigation Menu
Toggle navigation
[ ](https://github.com/)
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FWhisperSpeech%2FWhisperSpeech)
  * Product 
    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)
    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)
    * [ Actions Automate any workflow  ](https://github.com/features/actions)
    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)
    * [ Issues Plan and track work  ](https://github.com/features/issues)
    * [ Code Review Manage code changes  ](https://github.com/features/code-review)
    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)
    * [ Code Search Find more, search less  ](https://github.com/features/code-search)
Explore
    * [ All features ](https://github.com/features)
    * [ Documentation ](https://docs.github.com)
    * [ GitHub Skills ](https://skills.github.com)
    * [ Blog ](https://github.blog)
  * Solutions 
By company size
    * [ Enterprises ](https://github.com/enterprise)
    * [ Small and medium teams ](https://github.com/team)
    * [ Startups ](https://github.com/enterprise/startups)
    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)
By use case
    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)
    * [ DevOps ](https://github.com/solutions/use-case/devops)
    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)
    * [ View all use cases ](https://github.com/solutions/use-case)
By industry
    * [ Healthcare ](https://github.com/solutions/industry/healthcare)
    * [ Financial services ](https://github.com/solutions/industry/financial-services)
    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)
    * [ Government ](https://github.com/solutions/industry/government)
    * [ View all industries ](https://github.com/solutions/industry)
[ View all solutions ](https://github.com/solutions)
  * Resources 
Topics
    * [ AI ](https://github.com/resources/articles/ai)
    * [ DevOps ](https://github.com/resources/articles/devops)
    * [ Security ](https://github.com/resources/articles/security)
    * [ Software Development ](https://github.com/resources/articles/software-development)
    * [ View all ](https://github.com/resources/articles)
Explore
    * [ Learning Pathways ](https://resources.github.com/learn/pathways)
    * [ Events & Webinars ](https://resources.github.com)
    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)
    * [ Customer Stories ](https://github.com/customer-stories)
    * [ Partners ](https://partner.github.com)
    * [ Executive Insights ](https://github.com/solutions/executive-insights)
  * Open Source 
    * [ GitHub Sponsors Fund open source developers  ](https://github.com/sponsors)
    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)
Repositories
    * [ Topics ](https://github.com/topics)
    * [ Trending ](https://github.com/trending)
    * [ Collections ](https://github.com/collections)
  * Enterprise 
    * [ Enterprise platform AI-powered developer platform  ](https://github.com/enterprise)
Available add-ons
    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)
    * [ Copilot for business Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)
    * [ Premium Support Enterprise-grade 24/7 support  ](https://github.com/premium-support)
  * [Pricing](https://github.com/pricing)


Search or jump to...
# Search code, repositories, users, issues, pull requests...
Search 
Clear
[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)
#  Provide feedback 
We read every piece of feedback, and take your input very seriously.
Include my email address so I can be contacted
Cancel  Submit feedback 
#  Saved searches 
## Use saved searches to filter your results more quickly
Name
Query
To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). 
Cancel  Create saved search 
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FWhisperSpeech%2FWhisperSpeech)
[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=WhisperSpeech%2FWhisperSpeech) Reseting focus
You signed in with another tab or window. [Reload](https://github.com/collabora/WhisperSpeech) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/collabora/WhisperSpeech) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/collabora/WhisperSpeech) to refresh your session. Dismiss alert
{{ message }}
[ WhisperSpeech ](https://github.com/WhisperSpeech) / **[WhisperSpeech](https://github.com/WhisperSpeech/WhisperSpeech) ** Public
  * [ Notifications ](https://github.com/login?return_to=%2FWhisperSpeech%2FWhisperSpeech) You must be signed in to change notification settings
  * [ Fork 234 ](https://github.com/login?return_to=%2FWhisperSpeech%2FWhisperSpeech)
  * [ Star  4.2k ](https://github.com/login?return_to=%2FWhisperSpeech%2FWhisperSpeech)


An Open Source text-to-speech system built by inverting Whisper. 
[whisperspeech.github.io/WhisperSpeech/](https://whisperspeech.github.io/WhisperSpeech/ "https://whisperspeech.github.io/WhisperSpeech/")
### License
[ MIT license ](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/LICENSE)
[ 4.2k stars ](https://github.com/WhisperSpeech/WhisperSpeech/stargazers) [ 234 forks ](https://github.com/WhisperSpeech/WhisperSpeech/forks) [ Branches ](https://github.com/WhisperSpeech/WhisperSpeech/branches) [ Tags ](https://github.com/WhisperSpeech/WhisperSpeech/tags) [ Activity ](https://github.com/WhisperSpeech/WhisperSpeech/activity)
[ Star  ](https://github.com/login?return_to=%2FWhisperSpeech%2FWhisperSpeech)
[ Notifications ](https://github.com/login?return_to=%2FWhisperSpeech%2FWhisperSpeech) You must be signed in to change notification settings
  * [ Code ](https://github.com/WhisperSpeech/WhisperSpeech)
  * [ Issues 66 ](https://github.com/WhisperSpeech/WhisperSpeech/issues)
  * [ Pull requests 2 ](https://github.com/WhisperSpeech/WhisperSpeech/pulls)
  * [ Discussions ](https://github.com/WhisperSpeech/WhisperSpeech/discussions)
  * [ Actions ](https://github.com/WhisperSpeech/WhisperSpeech/actions)
  * [ Projects 0 ](https://github.com/WhisperSpeech/WhisperSpeech/projects)
  * [ Security ](https://github.com/WhisperSpeech/WhisperSpeech/security)
  * [ Insights ](https://github.com/WhisperSpeech/WhisperSpeech/pulse)


Additional navigation options
  * [ Code  ](https://github.com/WhisperSpeech/WhisperSpeech)
  * [ Issues  ](https://github.com/WhisperSpeech/WhisperSpeech/issues)
  * [ Pull requests  ](https://github.com/WhisperSpeech/WhisperSpeech/pulls)
  * [ Discussions  ](https://github.com/WhisperSpeech/WhisperSpeech/discussions)
  * [ Actions  ](https://github.com/WhisperSpeech/WhisperSpeech/actions)
  * [ Projects  ](https://github.com/WhisperSpeech/WhisperSpeech/projects)
  * [ Security  ](https://github.com/WhisperSpeech/WhisperSpeech/security)
  * [ Insights  ](https://github.com/WhisperSpeech/WhisperSpeech/pulse)


# WhisperSpeech/WhisperSpeech
main
[Branches](https://github.com/WhisperSpeech/WhisperSpeech/branches)[Tags](https://github.com/WhisperSpeech/WhisperSpeech/tags)
[](https://github.com/WhisperSpeech/WhisperSpeech/branches)[](https://github.com/WhisperSpeech/WhisperSpeech/tags)
Go to file
Code
## Folders and files
Name| Name| Last commit message| Last commit date  
---|---|---|---  
## Latest commit
## History
[237 Commits](https://github.com/WhisperSpeech/WhisperSpeech/commits/main/)[](https://github.com/WhisperSpeech/WhisperSpeech/commits/main/)  
[.github/workflows](https://github.com/WhisperSpeech/WhisperSpeech/tree/main/.github/workflows "This path skips through empty directories")| [.github/workflows](https://github.com/WhisperSpeech/WhisperSpeech/tree/main/.github/workflows "This path skips through empty directories")  
[examples](https://github.com/WhisperSpeech/WhisperSpeech/tree/main/examples "examples")| [examples](https://github.com/WhisperSpeech/WhisperSpeech/tree/main/examples "examples")  
[makefiles](https://github.com/WhisperSpeech/WhisperSpeech/tree/main/makefiles "makefiles")| [makefiles](https://github.com/WhisperSpeech/WhisperSpeech/tree/main/makefiles "makefiles")  
[nbs](https://github.com/WhisperSpeech/WhisperSpeech/tree/main/nbs "nbs")| [nbs](https://github.com/WhisperSpeech/WhisperSpeech/tree/main/nbs "nbs")  
[whisper-finetuning](https://github.com/WhisperSpeech/WhisperSpeech/tree/main/whisper-finetuning "whisper-finetuning")| [whisper-finetuning](https://github.com/WhisperSpeech/WhisperSpeech/tree/main/whisper-finetuning "whisper-finetuning")  
[whisperspeech](https://github.com/WhisperSpeech/WhisperSpeech/tree/main/whisperspeech "whisperspeech")| [whisperspeech](https://github.com/WhisperSpeech/WhisperSpeech/tree/main/whisperspeech "whisperspeech")  
[.gitignore](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/.gitignore ".gitignore")| [.gitignore](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/.gitignore ".gitignore")  
[Inference example.ipynb](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/Inference%20example.ipynb "Inference example.ipynb")| [Inference example.ipynb](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/Inference%20example.ipynb "Inference example.ipynb")  
[LICENSE](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/LICENSE "LICENSE")| [LICENSE](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/LICENSE "LICENSE")  
[Long-form inference.ipynb](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/Long-form%20inference.ipynb "Long-form inference.ipynb")| [Long-form inference.ipynb](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/Long-form%20inference.ipynb "Long-form inference.ipynb")  
[MANIFEST.in](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/MANIFEST.in "MANIFEST.in")| [MANIFEST.in](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/MANIFEST.in "MANIFEST.in")  
[README.md](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/README.md "README.md")| [README.md](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/README.md "README.md")  
[extract_distill_data.py](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/extract_distill_data.py "extract_distill_data.py")| [extract_distill_data.py](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/extract_distill_data.py "extract_distill_data.py")  
[settings.ini](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/settings.ini "settings.ini")| [settings.ini](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/settings.ini "settings.ini")  
[setup.py](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/setup.py "setup.py")| [setup.py](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/setup.py "setup.py")  
[whisper-block.png](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/whisper-block.png "whisper-block.png")| [whisper-block.png](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/whisper-block.png "whisper-block.png")  
[whisperspeech-diagram.png](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/whisperspeech-diagram.png "whisperspeech-diagram.png")| [whisperspeech-diagram.png](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/whisperspeech-diagram.png "whisperspeech-diagram.png")  
View all files  
## Repository files navigation
  * [README](https://github.com/collabora/WhisperSpeech)
  * [MIT license](https://github.com/collabora/WhisperSpeech)


# WhisperSpeech
[](https://github.com/collabora/WhisperSpeech#whisperspeech)
[![Test it out yourself in Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/drive/1xxGlTbwBmaY6GKA24strRixTXGBOlyiw) [![](https://camo.githubusercontent.com/093bd7706ccd9fc5fb8d835a33e88d13aa7e29bf1241e4c7521c503f62fca990/68747470733a2f2f646362616467652e76657263656c2e6170702f6170692f7365727665722f46414e77347248443545)](https://discord.gg/FANw4rHD5E) _If you have questions or you want to help you can find us in the #audio-generation channel on the LAION Discord server._
An Open Source text-to-speech system built by inverting Whisper. Previously known as **spear-tts-pytorch**.
We want this model to be like Stable Diffusion but for speech – both powerful and easily customizable.
We are working only with properly licensed speech recordings and all the code is Open Source so the model will be always safe to use for commercial applications.
Currently the models are trained on the English LibreLight dataset. In the next release we want to target multiple languages (Whisper and EnCodec are both multilanguage).
Sample of the synthesized voice:
whisperspeech-sample.mp4
## Progress update [2024-01-29]
[](https://github.com/collabora/WhisperSpeech#progress-update-2024-01-29)
We successfully trained a `tiny` S2A model on an en+pl+fr dataset and it can do voice cloning in French:
fr-voice-clone-2.mp4 fr-voice-clone-1.mp4
We were able to do this with frozen semantic tokens that were only trained on English and Polish. This supports the idea that we will be able to train a single semantic token model to support all the languages in the world. Quite likely even ones that are not currently well supported by the Whisper model. Stay tuned for more updates on this front. :)
## Progress update [2024-01-18]
[](https://github.com/collabora/WhisperSpeech#progress-update-2024-01-18)
We spend the last week optimizing inference performance. We integrated `torch.compile`, added kv-caching and tuned some of the layers – we are now working over 12x faster than real-time on a consumer 4090!
We can mix languages in a single sentence (here the highlighted English project names are seamlessly mixed into Polish speech):
> To jest pierwszy test wielojęzycznego `Whisper Speech` modelu zamieniającego tekst na mowę, który `Collabora` i `Laion` nauczyli na superkomputerze `Jewels`.
pl-en-mix.mp4
We also added an easy way to test voice-cloning. Here is a sample voice cloned from [a famous speech by Winston Churchill](https://en.wikipedia.org/wiki/File:Winston_Churchill_-_Be_Ye_Men_of_Valour.ogg) (the radio static is a feature, not a bug ;) – it is part of the reference recording):
en-cloning.mp4
You can [test all of these on Colab](https://colab.research.google.com/drive/1xxGlTbwBmaY6GKA24strRixTXGBOlyiw) (we optimized the dependencies so now it takes less than 30 seconds to install). A Huggingface Space is coming soon.
## Progress update [2024-01-10]
[](https://github.com/collabora/WhisperSpeech#progress-update-2024-01-10)
We’ve pushed a new SD S2A model that is a lot faster while still generating high-quality speech. We’ve also added an example of voice cloning based on a reference audio file.
As always, you can [check out our Colab](https://colab.research.google.com/drive/1xxGlTbwBmaY6GKA24strRixTXGBOlyiw) to try it yourself!
## Progress update [2023-12-10]
[](https://github.com/collabora/WhisperSpeech#progress-update-2023-12-10)
Another trio of models, this time they support multiple languages (English and Polish). Here are two new samples for a sneak peek. You can [check out our Colab](https://colab.research.google.com/drive/1xxGlTbwBmaY6GKA24strRixTXGBOlyiw) to try it yourself!
English speech, female voice (transferred from a Polish language dataset):
whisperspeech-sample.mp4
A Polish sample, male voice:
whisperspeech-sample-pl.mp4
[Older progress updates are archived here](https://github.com/collabora/WhisperSpeech/issues/23)
## Downloads
[](https://github.com/collabora/WhisperSpeech#downloads)
We encourage you to start with the Google Colab link above or run the provided notebook locally. If you want to download manually or train the models from scratch then both [the WhisperSpeech pre-trained models](https://huggingface.co/collabora/whisperspeech) as well as [the converted datasets](https://huggingface.co/datasets/collabora/whisperspeech) are available on HuggingFace.
## Roadmap
[](https://github.com/collabora/WhisperSpeech#roadmap)
  * [Gather a bigger emotive speech dataset](https://github.com/collabora/spear-tts-pytorch/issues/11)
  * Figure out a way to condition the generation on emotions and prosody
  * Create a community effort to gather freely licensed speech in multiple languages
  * [Train final multi-language models](https://github.com/collabora/spear-tts-pytorch/issues/12)


## Architecture
[](https://github.com/collabora/WhisperSpeech#architecture)
The general architecture is similar to [AudioLM](https://google-research.github.io/seanet/audiolm/examples/), [SPEAR TTS](https://google-research.github.io/seanet/speartts/examples/) from Google and [MusicGen](https://ai.honu.io/papers/musicgen/) from Meta. We avoided the NIH syndrome and built it on top of powerful Open Source models: [Whisper](https://github.com/openai/whisper) from OpenAI to generate semantic tokens and perform transcription, [EnCodec](https://github.com/facebookresearch/encodec) from Meta for acoustic modeling and [Vocos](https://github.com/charactr-platform/vocos) from Charactr Inc as the high-quality vocoder.
We gave two presentation diving deeper into WhisperSpeech. The first one talks about the challenges of large scale training:
[![](https://camo.githubusercontent.com/323d4cadc93640989e8ddd5f6f421b049f50be03ae6e8923994209c07f1dacfd/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f3646722d72712d796a586f2f302e6a7067)](https://www.youtube.com/watch?v=6Fr-rq-yjXo)
Tricks Learned from Scaling WhisperSpeech Models to 80k+ Hours of Speech - video recording by Jakub Cłapa, Collabora
The other one goes a bit more into the architectural choices we made:
[![](https://camo.githubusercontent.com/542c82ca5a53a0777f45877254f83e5ea666864c4a7c5d2b9ed727b4673c7fe6/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f314f4276663333533737592f302e6a7067)](https://www.youtube.com/watch?v=1OBvf33S77Y)
Open Source Text-To-Speech Projects: WhisperSpeech - In Depth Discussion
### Whisper for modeling semantic tokens
[](https://github.com/collabora/WhisperSpeech#whisper-for-modeling-semantic-tokens)
We utilize the OpenAI Whisper encoder block to generate embeddings which we then quantize to get semantic tokens.
If the language is already supported by Whisper then this process requires only audio files (without ground truth transcriptions).
[![Using Whisper for semantic token extraction diagram](https://github.com/WhisperSpeech/WhisperSpeech/raw/main/whisper-block.png)](https://github.com/WhisperSpeech/WhisperSpeech/blob/main/whisper-block.png)
## EnCodec for modeling acoustic tokens
[](https://github.com/collabora/WhisperSpeech#encodec-for-modeling-acoustic-tokens)
We use EnCodec to model the audio waveform. Out of the box it delivers reasonable quality at 1.5kbps and we can bring this to high-quality by using Vocos – a vocoder pretrained on EnCodec tokens.
[![EnCodec block diagram](https://github.com/facebookresearch/encodec/raw/main/architecture.png)](https://github.com/facebookresearch/encodec/raw/main/architecture.png)
## Appreciation
[](https://github.com/collabora/WhisperSpeech#appreciation)
[![Collabora logo](https://user-images.githubusercontent.com/107984/229537027-a6d7462b-0c9c-4fd4-b69e-58e98c3ee63f.png)](https://www.collabora.com) [![LAION logo](https://user-images.githubusercontent.com/107984/229535036-c741d775-4a9b-4193-89a0-9ddb89ecd011.png)](https://laion.ai)
This work would not be possible without the generous sponsorships from:
  * [Collabora](https://www.collabora.com) – code development and model training
  * [LAION](https://laion.ai) – community building and datasets (special thanks to
  * [Jülich Supercomputing Centre](https://www.fz-juelich.de/en) - JUWELS Booster supercomputer


We gratefully acknowledge the Gauss Centre for Supercomputing e.V. ([www.gauss-centre.eu](http://www.gauss-centre.eu)) for funding part of this work by providing computing time through the John von Neumann Institute for Computing (NIC) on the GCS Supercomputer JUWELS Booster at Jülich Supercomputing Centre (JSC), with access to compute provided via LAION cooperation on foundation models research.
We’d like to also thank individual contributors for their great help in building this model:
  * [inevitable-2031](https://github.com/inevitable-2031) (`qwerty_qwer` on Discord) for dataset curation


## Consulting
[](https://github.com/collabora/WhisperSpeech#consulting)
We are available to help you with both Open Source and proprietary AI projects. You can reach us via the Collabora website or on Discord ([![](https://camo.githubusercontent.com/b1be1756318841eee2d527af5ebda3a2cfe7721974b0bed9a0b9cc2bf5b4d376/68747470733a2f2f646362616467652e76657263656c2e6170702f6170692f736869656c642f3237303236373133343936303037343736323f7374796c653d666c6174)](https://discordapp.com/users/270267134960074762) and [![](https://camo.githubusercontent.com/9096a4a6069a2a9e399c13bc2080091b06da463c1748e9ba06dd042d13ddeedc/68747470733a2f2f646362616467652e76657263656c2e6170702f6170692f736869656c642f313038383933383038363430303031363437353f7374796c653d666c6174)](https://discordapp.com/users/1088938086400016475))
## Citations
[](https://github.com/collabora/WhisperSpeech#citations)
We rely on many amazing Open Source projects and research papers:
```
@article{SpearTTS,
 title = {Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision},
 url = {https://arxiv.org/abs/2302.03540},
 author = {Kharitonov, Eugene and Vincent, Damien and Borsos, Zalán and Marinier, Raphaël and Girgin, Sertan and Pietquin, Olivier and Sharifi, Matt and Tagliasacchi, Marco and Zeghidour, Neil},
 publisher = {arXiv},
 year = {2023},
}
```

```
@article{MusicGen,
 title={Simple and Controllable Music Generation}, 
 url = {https://arxiv.org/abs/2306.05284},
 author={Jade Copet and Felix Kreuk and Itai Gat and Tal Remez and David Kant and Gabriel Synnaeve and Yossi Adi and Alexandre Défossez},
 publisher={arXiv},
 year={2023},
}
```

```
@article{Whisper
 title = {Robust Speech Recognition via Large-Scale Weak Supervision},
 url = {https://arxiv.org/abs/2212.04356},
 author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
 publisher = {arXiv},
 year = {2022},
}
```

```
@article{EnCodec
 title = {High Fidelity Neural Audio Compression},
 url = {https://arxiv.org/abs/2210.13438},
 author = {Défossez, Alexandre and Copet, Jade and Synnaeve, Gabriel and Adi, Yossi},
 publisher = {arXiv},
 year = {2022},
}
```

```
@article{Vocos
 title={Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis}, 
 url = {https://arxiv.org/abs/2306.00814},
 author={Hubert Siuzdak},
 publisher={arXiv},
 year={2023},
}
```

## About
An Open Source text-to-speech system built by inverting Whisper. 
[whisperspeech.github.io/WhisperSpeech/](https://whisperspeech.github.io/WhisperSpeech/ "https://whisperspeech.github.io/WhisperSpeech/")
### Topics
[ pytorch ](https://github.com/topics/pytorch "Topic: pytorch") [ tts ](https://github.com/topics/tts "Topic: tts") [ speech-synthesis ](https://github.com/topics/speech-synthesis "Topic: speech-synthesis")
### Resources
[ Readme ](https://github.com/collabora/WhisperSpeech#readme-ov-file)
### License
[ MIT license ](https://github.com/collabora/WhisperSpeech#MIT-1-ov-file)
[ Activity](https://github.com/WhisperSpeech/WhisperSpeech/activity)
[ Custom properties](https://github.com/WhisperSpeech/WhisperSpeech/custom-properties)
### Stars
[ **4.2k** stars](https://github.com/WhisperSpeech/WhisperSpeech/stargazers)
### Watchers
[ **78** watching](https://github.com/WhisperSpeech/WhisperSpeech/watchers)
### Forks
[ **234** forks](https://github.com/WhisperSpeech/WhisperSpeech/forks)
[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FWhisperSpeech%2FWhisperSpeech&report=WhisperSpeech+%28user%29)
##  [Contributors 11](https://github.com/WhisperSpeech/WhisperSpeech/graphs/contributors)
  * [ ![@jpc](https://avatars.githubusercontent.com/u/107984?s=64&v=4) ](https://github.com/jpc)
  * [ ![@BBC-Esq](https://avatars.githubusercontent.com/u/108230321?s=64&v=4) ](https://github.com/BBC-Esq)
  * [ ![@github-actions\[bot\]](https://avatars.githubusercontent.com/in/15368?s=64&v=4) ](https://github.com/apps/github-actions)
  * [ ![@signalprime](https://avatars.githubusercontent.com/u/15487280?s=64&v=4) ](https://github.com/signalprime)
  * [ ![@makaveli10](https://avatars.githubusercontent.com/u/39617050?s=64&v=4) ](https://github.com/makaveli10)
  * [ ![@zoq](https://avatars.githubusercontent.com/u/4209744?s=64&v=4) ](https://github.com/zoq)
  * [ ![@tuanlda78202](https://avatars.githubusercontent.com/u/77523560?s=64&v=4) ](https://github.com/tuanlda78202)
  * [ ![@v3ucn](https://avatars.githubusercontent.com/u/1288038?s=64&v=4) ](https://github.com/v3ucn)
  * [ ![@vbawa](https://avatars.githubusercontent.com/u/1940176?s=64&v=4) ](https://github.com/vbawa)
  * [ ![@mengting7tw](https://avatars.githubusercontent.com/u/20589238?s=64&v=4) ](https://github.com/mengting7tw)
  * [ ![@akorzh](https://avatars.githubusercontent.com/u/25698784?s=64&v=4) ](https://github.com/akorzh)


## Languages
  * [ Jupyter Notebook 98.5% ](https://github.com/WhisperSpeech/WhisperSpeech/search?l=jupyter-notebook)
  * [ Python 1.5% ](https://github.com/WhisperSpeech/WhisperSpeech/search?l=python)


## Footer
[ ](https://github.com "GitHub") © 2025 GitHub, Inc. 
### Footer navigation
  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
  * [Security](https://github.com/security)
  * [Status](https://www.githubstatus.com/)
  * [Docs](https://docs.github.com/)
  * [Contact](https://support.github.com?tags=dotcom-footer)
  * Manage cookies 
  * Do not share my personal information 


You can’t perform that action at this time. 
