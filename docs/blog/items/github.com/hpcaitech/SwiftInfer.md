# 原始URL: https://github.com/hpcaitech/SwiftInfer

# 抓取时间: 2025-03-30 21:12:56

[Skip to content](https://github.com/hpcaitech/SwiftInfer#start-of-content)
## Navigation Menu
Toggle navigation
[ ](https://github.com/)
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fhpcaitech%2FSwiftInfer)
  * Product 
    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)
    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)
    * [ Actions Automate any workflow  ](https://github.com/features/actions)
    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)
    * [ Issues Plan and track work  ](https://github.com/features/issues)
    * [ Code Review Manage code changes  ](https://github.com/features/code-review)
    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)
    * [ Code Search Find more, search less  ](https://github.com/features/code-search)
Explore
    * [ All features ](https://github.com/features)
    * [ Documentation ](https://docs.github.com)
    * [ GitHub Skills ](https://skills.github.com)
    * [ Blog ](https://github.blog)
  * Solutions 
By company size
    * [ Enterprises ](https://github.com/enterprise)
    * [ Small and medium teams ](https://github.com/team)
    * [ Startups ](https://github.com/enterprise/startups)
    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)
By use case
    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)
    * [ DevOps ](https://github.com/solutions/use-case/devops)
    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)
    * [ View all use cases ](https://github.com/solutions/use-case)
By industry
    * [ Healthcare ](https://github.com/solutions/industry/healthcare)
    * [ Financial services ](https://github.com/solutions/industry/financial-services)
    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)
    * [ Government ](https://github.com/solutions/industry/government)
    * [ View all industries ](https://github.com/solutions/industry)
[ View all solutions ](https://github.com/solutions)
  * Resources 
Topics
    * [ AI ](https://github.com/resources/articles/ai)
    * [ DevOps ](https://github.com/resources/articles/devops)
    * [ Security ](https://github.com/resources/articles/security)
    * [ Software Development ](https://github.com/resources/articles/software-development)
    * [ View all ](https://github.com/resources/articles)
Explore
    * [ Learning Pathways ](https://resources.github.com/learn/pathways)
    * [ Events & Webinars ](https://resources.github.com)
    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)
    * [ Customer Stories ](https://github.com/customer-stories)
    * [ Partners ](https://partner.github.com)
    * [ Executive Insights ](https://github.com/solutions/executive-insights)
  * Open Source 
    * [ GitHub Sponsors Fund open source developers  ](https://github.com/sponsors)
    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)
Repositories
    * [ Topics ](https://github.com/topics)
    * [ Trending ](https://github.com/trending)
    * [ Collections ](https://github.com/collections)
  * Enterprise 
    * [ Enterprise platform AI-powered developer platform  ](https://github.com/enterprise)
Available add-ons
    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)
    * [ Copilot for business Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)
    * [ Premium Support Enterprise-grade 24/7 support  ](https://github.com/premium-support)
  * [Pricing](https://github.com/pricing)


Search or jump to...
# Search code, repositories, users, issues, pull requests...
Search 
Clear
[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)
#  Provide feedback 
We read every piece of feedback, and take your input very seriously.
Include my email address so I can be contacted
Cancel  Submit feedback 
#  Saved searches 
## Use saved searches to filter your results more quickly
Name
Query
To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). 
Cancel  Create saved search 
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fhpcaitech%2FSwiftInfer)
[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=hpcaitech%2FSwiftInfer) Reseting focus
You signed in with another tab or window. [Reload](https://github.com/hpcaitech/SwiftInfer) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/hpcaitech/SwiftInfer) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/hpcaitech/SwiftInfer) to refresh your session. Dismiss alert
{{ message }}
[ hpcaitech ](https://github.com/hpcaitech) / **[SwiftInfer](https://github.com/hpcaitech/SwiftInfer) ** Public
  * [ Notifications ](https://github.com/login?return_to=%2Fhpcaitech%2FSwiftInfer) You must be signed in to change notification settings
  * [ Fork 28 ](https://github.com/login?return_to=%2Fhpcaitech%2FSwiftInfer)
  * [ Star  469 ](https://github.com/login?return_to=%2Fhpcaitech%2FSwiftInfer)


Efficient AI Inference & Serving 
[hpc-ai.com/](https://hpc-ai.com/ "https://hpc-ai.com/")
### License
[ Apache-2.0 license ](https://github.com/hpcaitech/SwiftInfer/blob/main/LICENSE)
[ 469 stars ](https://github.com/hpcaitech/SwiftInfer/stargazers) [ 28 forks ](https://github.com/hpcaitech/SwiftInfer/forks) [ Branches ](https://github.com/hpcaitech/SwiftInfer/branches) [ Tags ](https://github.com/hpcaitech/SwiftInfer/tags) [ Activity ](https://github.com/hpcaitech/SwiftInfer/activity)
[ Star  ](https://github.com/login?return_to=%2Fhpcaitech%2FSwiftInfer)
[ Notifications ](https://github.com/login?return_to=%2Fhpcaitech%2FSwiftInfer) You must be signed in to change notification settings
  * [ Code ](https://github.com/hpcaitech/SwiftInfer)
  * [ Issues 3 ](https://github.com/hpcaitech/SwiftInfer/issues)
  * [ Pull requests 0 ](https://github.com/hpcaitech/SwiftInfer/pulls)
  * [ Actions ](https://github.com/hpcaitech/SwiftInfer/actions)
  * [ Projects 0 ](https://github.com/hpcaitech/SwiftInfer/projects)
  * [ Security ](https://github.com/hpcaitech/SwiftInfer/security)
  * [ Insights ](https://github.com/hpcaitech/SwiftInfer/pulse)


Additional navigation options
  * [ Code  ](https://github.com/hpcaitech/SwiftInfer)
  * [ Issues  ](https://github.com/hpcaitech/SwiftInfer/issues)
  * [ Pull requests  ](https://github.com/hpcaitech/SwiftInfer/pulls)
  * [ Actions  ](https://github.com/hpcaitech/SwiftInfer/actions)
  * [ Projects  ](https://github.com/hpcaitech/SwiftInfer/projects)
  * [ Security  ](https://github.com/hpcaitech/SwiftInfer/security)
  * [ Insights  ](https://github.com/hpcaitech/SwiftInfer/pulse)


# hpcaitech/SwiftInfer
main
[Branches](https://github.com/hpcaitech/SwiftInfer/branches)[Tags](https://github.com/hpcaitech/SwiftInfer/tags)
[](https://github.com/hpcaitech/SwiftInfer/branches)[](https://github.com/hpcaitech/SwiftInfer/tags)
Go to file
Code
## Folders and files
Name| Name| Last commit message| Last commit date  
---|---|---|---  
## Latest commit
## History
[4 Commits](https://github.com/hpcaitech/SwiftInfer/commits/main/)[](https://github.com/hpcaitech/SwiftInfer/commits/main/)  
[3rdparty](https://github.com/hpcaitech/SwiftInfer/tree/main/3rdparty "3rdparty")| [3rdparty](https://github.com/hpcaitech/SwiftInfer/tree/main/3rdparty "3rdparty")  
[assets](https://github.com/hpcaitech/SwiftInfer/tree/main/assets "assets")| [assets](https://github.com/hpcaitech/SwiftInfer/tree/main/assets "assets")  
[examples](https://github.com/hpcaitech/SwiftInfer/tree/main/examples "examples")| [examples](https://github.com/hpcaitech/SwiftInfer/tree/main/examples "examples")  
[requirements](https://github.com/hpcaitech/SwiftInfer/tree/main/requirements "requirements")| [requirements](https://github.com/hpcaitech/SwiftInfer/tree/main/requirements "requirements")  
[scripts](https://github.com/hpcaitech/SwiftInfer/tree/main/scripts "scripts")| [scripts](https://github.com/hpcaitech/SwiftInfer/tree/main/scripts "scripts")  
[swiftinfer](https://github.com/hpcaitech/SwiftInfer/tree/main/swiftinfer "swiftinfer")| [swiftinfer](https://github.com/hpcaitech/SwiftInfer/tree/main/swiftinfer "swiftinfer")  
[tests/test_layers](https://github.com/hpcaitech/SwiftInfer/tree/main/tests/test_layers "This path skips through empty directories")| [tests/test_layers](https://github.com/hpcaitech/SwiftInfer/tree/main/tests/test_layers "This path skips through empty directories")  
[.clang-format](https://github.com/hpcaitech/SwiftInfer/blob/main/.clang-format ".clang-format")| [.clang-format](https://github.com/hpcaitech/SwiftInfer/blob/main/.clang-format ".clang-format")  
[.gitignore](https://github.com/hpcaitech/SwiftInfer/blob/main/.gitignore ".gitignore")| [.gitignore](https://github.com/hpcaitech/SwiftInfer/blob/main/.gitignore ".gitignore")  
[.gitmodules](https://github.com/hpcaitech/SwiftInfer/blob/main/.gitmodules ".gitmodules")| [.gitmodules](https://github.com/hpcaitech/SwiftInfer/blob/main/.gitmodules ".gitmodules")  
[.isort.cfg](https://github.com/hpcaitech/SwiftInfer/blob/main/.isort.cfg ".isort.cfg")| [.isort.cfg](https://github.com/hpcaitech/SwiftInfer/blob/main/.isort.cfg ".isort.cfg")  
[.pre-commit-config.yaml](https://github.com/hpcaitech/SwiftInfer/blob/main/.pre-commit-config.yaml ".pre-commit-config.yaml")| [.pre-commit-config.yaml](https://github.com/hpcaitech/SwiftInfer/blob/main/.pre-commit-config.yaml ".pre-commit-config.yaml")  
[LICENSE](https://github.com/hpcaitech/SwiftInfer/blob/main/LICENSE "LICENSE")| [LICENSE](https://github.com/hpcaitech/SwiftInfer/blob/main/LICENSE "LICENSE")  
[MANIFEST.in](https://github.com/hpcaitech/SwiftInfer/blob/main/MANIFEST.in "MANIFEST.in")| [MANIFEST.in](https://github.com/hpcaitech/SwiftInfer/blob/main/MANIFEST.in "MANIFEST.in")  
[README.md](https://github.com/hpcaitech/SwiftInfer/blob/main/README.md "README.md")| [README.md](https://github.com/hpcaitech/SwiftInfer/blob/main/README.md "README.md")  
[pytest.ini](https://github.com/hpcaitech/SwiftInfer/blob/main/pytest.ini "pytest.ini")| [pytest.ini](https://github.com/hpcaitech/SwiftInfer/blob/main/pytest.ini "pytest.ini")  
[setup.py](https://github.com/hpcaitech/SwiftInfer/blob/main/setup.py "setup.py")| [setup.py](https://github.com/hpcaitech/SwiftInfer/blob/main/setup.py "setup.py")  
[version.txt](https://github.com/hpcaitech/SwiftInfer/blob/main/version.txt "version.txt")| [version.txt](https://github.com/hpcaitech/SwiftInfer/blob/main/version.txt "version.txt")  
View all files  
## Repository files navigation
  * [README](https://github.com/hpcaitech/SwiftInfer)
  * [Apache-2.0 license](https://github.com/hpcaitech/SwiftInfer)


# 🚀 SwiftInfer
[](https://github.com/hpcaitech/SwiftInfer#-swiftinfer)
## 🔗 Table of Contents
[](https://github.com/hpcaitech/SwiftInfer#-table-of-contents)
  * [🚀 SwiftInfer](https://github.com/hpcaitech/SwiftInfer#-swiftinfer)
    * [🔗 Table of Contents](https://github.com/hpcaitech/SwiftInfer#-table-of-contents)
    * [📌 Overview](https://github.com/hpcaitech/SwiftInfer#-overview)
    * [🚗 Quick Start](https://github.com/hpcaitech/SwiftInfer#-quick-start)
      * [🛠 Installation](https://github.com/hpcaitech/SwiftInfer#-installation)
      * [🕹 Run Llama example](https://github.com/hpcaitech/SwiftInfer#-run-llama-example)
    * [⚖️ Benchmark](https://github.com/hpcaitech/SwiftInfer#-benchmark)
    * [🗺 Roadmap](https://github.com/hpcaitech/SwiftInfer#-roadmap)
    * [📃 Acknowledgement](https://github.com/hpcaitech/SwiftInfer#-acknowledgement)
    * [📝 Citation](https://github.com/hpcaitech/SwiftInfer#-citation)


## 📌 Overview
[](https://github.com/hpcaitech/SwiftInfer#-overview)
[**Streaming-LLM**](https://github.com/mit-han-lab/streaming-llm) is a technique to support infinite input length for LLM inference. It leverages [**Attention Sink**](https://arxiv.org/abs/2309.17453) to prevent the model collapse when the attention window shifts. The original work is implemented in PyTorch, we offer **SwiftInfer** , a TensorRT implementation to make StreamingLLM more production-grade. Our implementation was built upon the recently released [**TensorRT-LLM**](https://github.com/NVIDIA/TensorRT-LLM) project.
## 🚗 Quick Start
[](https://github.com/hpcaitech/SwiftInfer#-quick-start)
### 🛠 Installation
[](https://github.com/hpcaitech/SwiftInfer#-installation)
We use the API in [**TensorRT-LLM**](https://github.com/NVIDIA/TensorRT-LLM) to construct the model and run inference. As the API of TensorRT-LLM is not stable and changing rapidly, we bind our implementation with the `42af740db51d6f11442fd5509ef745a4c043ce51` commit whose version is `v0.6.0`. We may upgrade this repository as TensorRT-LLM's APIs become more stable.
If you have build **TensorRT-LLM V0.6.0** , simply run:
```
git clone https://github.com/hpcaitech/SwiftInfer.git
cd SwiftInfer
pip install .
```

Otherwise, you should install TensorRT-LLM first.
#### Install TensorRT-LLM with Docker
[](https://github.com/hpcaitech/SwiftInfer#install-tensorrt-llm-with-docker)
If using docker, you can follow [TensorRT-LLM Installation](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/installation.md) to install **TensorRT-LLM V0.6.0**.
By using docker, you can install SwiftInfer by simply running:
```
git clone https://github.com/hpcaitech/SwiftInfer.git
cd SwiftInfer
pip install .
```

#### Install TensorRT-LLM without Docker
[](https://github.com/hpcaitech/SwiftInfer#install-tensorrt-llm-without-docker)
If not using docker, we provide a script to install TensorRT-LLM automatically.
**Prerequisites**
Please ensure that you have installed the following packages:
  * python
  * build essentials, including gcc/g++, make, cmake
  * CUDA toolkit
  * cuDNN
  * NCCL
  * TensorRT
  * PyTorch


Make sure the version of TensorRT >= 9.1.0 and CUDA toolkit >= 12.2.
To install tensorrt:
```
ARCH=$(uname -m)
if [ "$ARCH" = "arm64" ];then ARCH="aarch64";fi
if [ "$ARCH" = "amd64" ];then ARCH="x86_64";fi
if [ "$ARCH" = "aarch64" ];then OS="ubuntu-22.04"; else OS="linux";fi
wget https://developer.nvidia.com/downloads/compute/machine-learning/tensorrt/secure/9.1.0/tars/tensorrt-9.1.0.4.$OS.$ARCH-gnu.cuda-12.2.tar.gz
tar xzvf tensorrt-9.1.0.4.linux.x86_64-gnu.cuda-12.2.tar.gz
PY_VERSION=$(python -c 'import sys; print(".".join(map(str, sys.version_info[0:2])))')
PARSED_PY_VERSION=$(echo "${PY_VERSION//./}")
pip install TensorRT-9.1.0.4/python/tensorrt-*-cp${PARSED_PY_VERSION}-*.whl
export TRT_ROOT=$(realpath TensorRT-9.1.0.4)
```

To download nccl, follow [NCCL download page](https://developer.nvidia.com/nccl/nccl-download).
To download cudnn, follow [cuDNN download page](https://developer.nvidia.com/rdp/cudnn-download).
**Commands**
Before running the following commands, please ensure that you have set `nvcc` correctly. To check it, run:
```
nvcc --version
```

To install TensorRT-LLM and SwiftInfer, run:
```
git clone https://github.com/hpcaitech/SwiftInfer.git
cd SwiftInfer
TRT_ROOT=xxx NCCL_ROOT=xxx CUDNN_ROOT=xxx pip install .
```

### 🕹 Run Llama example
[](https://github.com/hpcaitech/SwiftInfer#-run-llama-example)
To run the Llama example, you need to first clone the Hugging Face repository for the [meta-llama/Llama-2-7b-chat-hf](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf) model or other Llama-based variants such as [lmsys/vicuna-7b-v1.3](https://huggingface.co/lmsys/vicuna-7b-v1.3). Then, you can run the following command to build the TensorRT engine. **You need to replace`<model-dir>` with the actual path to the Llama model.**
```
cd examples/llama
python build.py \
--model_dir <model-dir> \
--dtype float16 \
--enable_context_fmha \
--use_gemm_plugin float16 \
--max_input_len 2048 \
--max_output_len 1024 \
--output_dir ./output/7B-streaming-8k-1k-4-2000/trt_engines/fp16/1-gpu/ \
--max_batch_size 1
```

Next, you need to download the [MT-Bench](https://github.com/lm-sys/FastChat/blob/main/fastchat/llm_judge/README.md#mt-bench) data provided by [LMSYS-FastChat](https://github.com/lm-sys/FastChat).
```
mkdir mt_bench_data
wget -P ./mt_bench_data https://raw.githubusercontent.com/lm-sys/FastChat/main/fastchat/llm_judge/data/mt_bench/question.jsonl
```

Finally, you are ready to run the Llama example with the following command.
❗️❗️❗️ **Before that, please note that:**
  1. The `only_n_first` argument is used to control the number of samples to be evaluated. If you want to evaluate all samples, please remove this argument.


```
python ../run_conversation.py \
--max_input_length 2048 \
--max_output_len 1024 \
--tokenizer_dir <model-dir> \
--engine_dir ./output/7B-streaming-8k-1k-4-2000/trt_engines/fp16/1-gpu/ \
--input_file ./mt_bench_data/question.jsonl \
--streaming_llm_start_size 4 \
--only_n_first 5
```

You should expect to see the generation out as follows:
[![generation output](https://github.com/hpcaitech/SwiftInfer/raw/main/assets/inference-result.png)](https://github.com/hpcaitech/SwiftInfer/blob/main/assets/inference-result.png)
## ⚖️ Benchmark
[](https://github.com/hpcaitech/SwiftInfer#️-benchmark)
We have benchmarked our implementations of Streaming-LLM with the [original PyTorch version](https://github.com/mit-han-lab/streaming-llm). The benchmark command for our implementation is given in the [Run Llama Example](https://github.com/hpcaitech/SwiftInfer#%F0%9F%95%B9-run-llama-example) section while that for the original PyTorch implementation is given in the [torch_streamingllm](https://github.com/hpcaitech/SwiftInfer/blob/main/examples/torch_streamingllm) folder. The hardware used is listed below:
  * GPU: Nvidia H800 (80GB)
  * CPU: Intel(R) Xeon(R) Platinum 8468
  * RAM: 2TB


The results (20 rounds of conversations) are:
[![performance](https://github.com/hpcaitech/SwiftInfer/raw/main/assets/performance.jpg)](https://github.com/hpcaitech/SwiftInfer/blob/main/assets/performance.jpg)
We are still working on further performance improvement and adapting to the TensorRT V0.7.1 APIs. We also notice that TensorRT-LLM has integrated StreamingLLM in their [example](https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/llama#run-llama-with-streamingllm) but it seems it is more suitable for single text generation instead of multi-round conversations.
## 🗺 Roadmap
[](https://github.com/hpcaitech/SwiftInfer#-roadmap)
  * Streaming-LLM attention implementation based on TRT-LLM APIs
  * KV cache adaptation
  * Early stop adaptation
  * Contiguous tensor fix
  * Llama example for multi-round conversation


## 📃 Acknowledgement
[](https://github.com/hpcaitech/SwiftInfer#-acknowledgement)
This work is inspired by Streaming-LLM to make it usable for production. Throughout development, we have referenced the following materials and we wish to acknowledge their efforts and contribution to the open-source community and academia.
  * Streaming-LLM 
    * [Paper](https://arxiv.org/abs/2309.17453)
    * [Slides](https://github.com/mit-han-lab/streaming-llm/blob/main/assets/StreamingLLM.pdf)
    * [GitHub Repository](https://github.com/mit-han-lab/streaming-llm)
  * TensorRT-LLM 
    * [Documentation](https://nvidia.github.io/TensorRT-LLM/)
    * [GitHub Repository](https://github.com/NVIDIA/TensorRT-LLM)


## 📝 Citation
[](https://github.com/hpcaitech/SwiftInfer#-citation)
If you find StreamingLLM and our TensorRT implementation useful, please kindly cite our repository and the original work proposed by [Xiao et al.](https://github.com/Guangxuan-Xiao) from [MIT Han Lab](https://github.com/mit-han-lab).
```
# our repository
# NOTE: the listed authors have equal contribution
@misc{streamingllmtrt2023,
 title = {SwiftInfer},
 year = {2023},
 publisher = {GitHub},
 journal = {GitHub repository},
 howpublished = {\url{https://github.com/hpcaitech/SwiftInfer}},
}
# Xiao's original paper
@article{xiao2023streamingllm,
    title={Efficient Streaming Language Models with Attention Sinks},
    author={Xiao, Guangxuan and Tian, Yuandong and Chen, Beidi and Han, Song and Lewis, Mike},
    journal={arXiv},
    year={2023}
    }
# TensorRT-LLM repo
# as TensorRT-LLM team does not provide a bibtex
# please let us know if there is any change needed
@misc{trtllm2023,
 title = {TensorRT-LLM},
 year = {2023},
 publisher = {GitHub},
 journal = {GitHub repository},
 howpublished = {\url{https://github.com/NVIDIA/TensorRT-LLM}},
}
```

## About
Efficient AI Inference & Serving 
[hpc-ai.com/](https://hpc-ai.com/ "https://hpc-ai.com/")
### Topics
[ deep-learning ](https://github.com/topics/deep-learning "Topic: deep-learning") [ inference ](https://github.com/topics/inference "Topic: inference") [ artificial-intelligence ](https://github.com/topics/artificial-intelligence "Topic: artificial-intelligence") [ llama ](https://github.com/topics/llama "Topic: llama") [ gpt ](https://github.com/topics/gpt "Topic: gpt") [ llm-serving ](https://github.com/topics/llm-serving "Topic: llm-serving") [ llm-inference ](https://github.com/topics/llm-inference "Topic: llm-inference") [ llama2 ](https://github.com/topics/llama2 "Topic: llama2")
### Resources
[ Readme ](https://github.com/hpcaitech/SwiftInfer#readme-ov-file)
### License
[ Apache-2.0 license ](https://github.com/hpcaitech/SwiftInfer#Apache-2.0-1-ov-file)
[ Activity](https://github.com/hpcaitech/SwiftInfer/activity)
[ Custom properties](https://github.com/hpcaitech/SwiftInfer/custom-properties)
### Stars
[ **469** stars](https://github.com/hpcaitech/SwiftInfer/stargazers)
### Watchers
[ **5** watching](https://github.com/hpcaitech/SwiftInfer/watchers)
### Forks
[ **28** forks](https://github.com/hpcaitech/SwiftInfer/forks)
[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fhpcaitech%2FSwiftInfer&report=hpcaitech+%28user%29)
##  [Releases](https://github.com/hpcaitech/SwiftInfer/releases)
No releases published
##  [Packages 0](https://github.com/orgs/hpcaitech/packages?repo_name=SwiftInfer)
No packages published 
##  [Contributors 2](https://github.com/hpcaitech/SwiftInfer/graphs/contributors)
## Languages
  * [ Python 99.7% ](https://github.com/hpcaitech/SwiftInfer/search?l=python)
  * [ Shell 0.3% ](https://github.com/hpcaitech/SwiftInfer/search?l=shell)


## Footer
[ ](https://github.com "GitHub") © 2025 GitHub, Inc. 
### Footer navigation
  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
  * [Security](https://github.com/security)
  * [Status](https://www.githubstatus.com/)
  * [Docs](https://docs.github.com/)
  * [Contact](https://support.github.com?tags=dotcom-footer)
  * Manage cookies 
  * Do not share my personal information 


You can’t perform that action at this time. 
