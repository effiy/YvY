# 原始URL: https://github.com/hpcaitech/Open-Sora

# 抓取时间: 2025-03-30 21:13:08

[Skip to content](https://github.com/hpcaitech/Open-Sora#start-of-content)
## Navigation Menu
Toggle navigation
[ ](https://github.com/)
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fhpcaitech%2FOpen-Sora)
  * Product 
    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)
    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)
    * [ Actions Automate any workflow  ](https://github.com/features/actions)
    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)
    * [ Issues Plan and track work  ](https://github.com/features/issues)
    * [ Code Review Manage code changes  ](https://github.com/features/code-review)
    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)
    * [ Code Search Find more, search less  ](https://github.com/features/code-search)
Explore
    * [ All features ](https://github.com/features)
    * [ Documentation ](https://docs.github.com)
    * [ GitHub Skills ](https://skills.github.com)
    * [ Blog ](https://github.blog)
  * Solutions 
By company size
    * [ Enterprises ](https://github.com/enterprise)
    * [ Small and medium teams ](https://github.com/team)
    * [ Startups ](https://github.com/enterprise/startups)
    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)
By use case
    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)
    * [ DevOps ](https://github.com/solutions/use-case/devops)
    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)
    * [ View all use cases ](https://github.com/solutions/use-case)
By industry
    * [ Healthcare ](https://github.com/solutions/industry/healthcare)
    * [ Financial services ](https://github.com/solutions/industry/financial-services)
    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)
    * [ Government ](https://github.com/solutions/industry/government)
    * [ View all industries ](https://github.com/solutions/industry)
[ View all solutions ](https://github.com/solutions)
  * Resources 
Topics
    * [ AI ](https://github.com/resources/articles/ai)
    * [ DevOps ](https://github.com/resources/articles/devops)
    * [ Security ](https://github.com/resources/articles/security)
    * [ Software Development ](https://github.com/resources/articles/software-development)
    * [ View all ](https://github.com/resources/articles)
Explore
    * [ Learning Pathways ](https://resources.github.com/learn/pathways)
    * [ Events & Webinars ](https://resources.github.com)
    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)
    * [ Customer Stories ](https://github.com/customer-stories)
    * [ Partners ](https://partner.github.com)
    * [ Executive Insights ](https://github.com/solutions/executive-insights)
  * Open Source 
    * [ GitHub Sponsors Fund open source developers  ](https://github.com/sponsors)
    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)
Repositories
    * [ Topics ](https://github.com/topics)
    * [ Trending ](https://github.com/trending)
    * [ Collections ](https://github.com/collections)
  * Enterprise 
    * [ Enterprise platform AI-powered developer platform  ](https://github.com/enterprise)
Available add-ons
    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)
    * [ Copilot for business Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)
    * [ Premium Support Enterprise-grade 24/7 support  ](https://github.com/premium-support)
  * [Pricing](https://github.com/pricing)


Search or jump to...
# Search code, repositories, users, issues, pull requests...
Search 
Clear
[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)
#  Provide feedback 
We read every piece of feedback, and take your input very seriously.
Include my email address so I can be contacted
Cancel  Submit feedback 
#  Saved searches 
## Use saved searches to filter your results more quickly
Name
Query
To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). 
Cancel  Create saved search 
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fhpcaitech%2FOpen-Sora)
[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=hpcaitech%2FOpen-Sora) Reseting focus
You signed in with another tab or window. [Reload](https://github.com/hpcaitech/Open-Sora) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/hpcaitech/Open-Sora) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/hpcaitech/Open-Sora) to refresh your session. Dismiss alert
{{ message }}
[ hpcaitech ](https://github.com/hpcaitech) / **[Open-Sora](https://github.com/hpcaitech/Open-Sora) ** Public
  * [ Notifications ](https://github.com/login?return_to=%2Fhpcaitech%2FOpen-Sora) You must be signed in to change notification settings
  * [ Fork 2.5k ](https://github.com/login?return_to=%2Fhpcaitech%2FOpen-Sora)
  * [ Star  25.9k ](https://github.com/login?return_to=%2Fhpcaitech%2FOpen-Sora)


Open-Sora: Democratizing Efficient Video Production for All 
[hpcaitech.github.io/Open-Sora/](https://hpcaitech.github.io/Open-Sora/ "https://hpcaitech.github.io/Open-Sora/")
### License
[ Apache-2.0 license ](https://github.com/hpcaitech/Open-Sora/blob/main/LICENSE)
[ 25.9k stars ](https://github.com/hpcaitech/Open-Sora/stargazers) [ 2.5k forks ](https://github.com/hpcaitech/Open-Sora/forks) [ Branches ](https://github.com/hpcaitech/Open-Sora/branches) [ Tags ](https://github.com/hpcaitech/Open-Sora/tags) [ Activity ](https://github.com/hpcaitech/Open-Sora/activity)
[ Star  ](https://github.com/login?return_to=%2Fhpcaitech%2FOpen-Sora)
[ Notifications ](https://github.com/login?return_to=%2Fhpcaitech%2FOpen-Sora) You must be signed in to change notification settings
  * [ Code ](https://github.com/hpcaitech/Open-Sora)
  * [ Issues 16 ](https://github.com/hpcaitech/Open-Sora/issues)
  * [ Pull requests 1 ](https://github.com/hpcaitech/Open-Sora/pulls)
  * [ Actions ](https://github.com/hpcaitech/Open-Sora/actions)
  * [ Projects 0 ](https://github.com/hpcaitech/Open-Sora/projects)
  * [ Security ](https://github.com/hpcaitech/Open-Sora/security)
  * [ Insights ](https://github.com/hpcaitech/Open-Sora/pulse)


Additional navigation options
  * [ Code  ](https://github.com/hpcaitech/Open-Sora)
  * [ Issues  ](https://github.com/hpcaitech/Open-Sora/issues)
  * [ Pull requests  ](https://github.com/hpcaitech/Open-Sora/pulls)
  * [ Actions  ](https://github.com/hpcaitech/Open-Sora/actions)
  * [ Projects  ](https://github.com/hpcaitech/Open-Sora/projects)
  * [ Security  ](https://github.com/hpcaitech/Open-Sora/security)
  * [ Insights  ](https://github.com/hpcaitech/Open-Sora/pulse)


# hpcaitech/Open-Sora
main
[Branches](https://github.com/hpcaitech/Open-Sora/branches)[Tags](https://github.com/hpcaitech/Open-Sora/tags)
[](https://github.com/hpcaitech/Open-Sora/branches)[](https://github.com/hpcaitech/Open-Sora/tags)
Go to file
Code
## Folders and files
Name| Name| Last commit message| Last commit date  
---|---|---|---  
## Latest commit
## History
[1,332 Commits](https://github.com/hpcaitech/Open-Sora/commits/main/)[](https://github.com/hpcaitech/Open-Sora/commits/main/)  
[.github/workflows](https://github.com/hpcaitech/Open-Sora/tree/main/.github/workflows "This path skips through empty directories")| [.github/workflows](https://github.com/hpcaitech/Open-Sora/tree/main/.github/workflows "This path skips through empty directories")  
[assets/texts](https://github.com/hpcaitech/Open-Sora/tree/main/assets/texts "This path skips through empty directories")| [assets/texts](https://github.com/hpcaitech/Open-Sora/tree/main/assets/texts "This path skips through empty directories")  
[configs](https://github.com/hpcaitech/Open-Sora/tree/main/configs "configs")| [configs](https://github.com/hpcaitech/Open-Sora/tree/main/configs "configs")  
[docs](https://github.com/hpcaitech/Open-Sora/tree/main/docs "docs")| [docs](https://github.com/hpcaitech/Open-Sora/tree/main/docs "docs")  
[gradio](https://github.com/hpcaitech/Open-Sora/tree/main/gradio "gradio")| [gradio](https://github.com/hpcaitech/Open-Sora/tree/main/gradio "gradio")  
[opensora](https://github.com/hpcaitech/Open-Sora/tree/main/opensora "opensora")| [opensora](https://github.com/hpcaitech/Open-Sora/tree/main/opensora "opensora")  
[scripts](https://github.com/hpcaitech/Open-Sora/tree/main/scripts "scripts")| [scripts](https://github.com/hpcaitech/Open-Sora/tree/main/scripts "scripts")  
[.gitignore](https://github.com/hpcaitech/Open-Sora/blob/main/.gitignore ".gitignore")| [.gitignore](https://github.com/hpcaitech/Open-Sora/blob/main/.gitignore ".gitignore")  
[.pre-commit-config.yaml](https://github.com/hpcaitech/Open-Sora/blob/main/.pre-commit-config.yaml ".pre-commit-config.yaml")| [.pre-commit-config.yaml](https://github.com/hpcaitech/Open-Sora/blob/main/.pre-commit-config.yaml ".pre-commit-config.yaml")  
[CONTRIBUTING.md](https://github.com/hpcaitech/Open-Sora/blob/main/CONTRIBUTING.md "CONTRIBUTING.md")| [CONTRIBUTING.md](https://github.com/hpcaitech/Open-Sora/blob/main/CONTRIBUTING.md "CONTRIBUTING.md")  
[LICENSE](https://github.com/hpcaitech/Open-Sora/blob/main/LICENSE "LICENSE")| [LICENSE](https://github.com/hpcaitech/Open-Sora/blob/main/LICENSE "LICENSE")  
[README.md](https://github.com/hpcaitech/Open-Sora/blob/main/README.md "README.md")| [README.md](https://github.com/hpcaitech/Open-Sora/blob/main/README.md "README.md")  
[requirements.txt](https://github.com/hpcaitech/Open-Sora/blob/main/requirements.txt "requirements.txt")| [requirements.txt](https://github.com/hpcaitech/Open-Sora/blob/main/requirements.txt "requirements.txt")  
[setup.py](https://github.com/hpcaitech/Open-Sora/blob/main/setup.py "setup.py")| [setup.py](https://github.com/hpcaitech/Open-Sora/blob/main/setup.py "setup.py")  
View all files  
## Repository files navigation
  * [README](https://github.com/hpcaitech/Open-Sora)
  * [Apache-2.0 license](https://github.com/hpcaitech/Open-Sora)


[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/readme/icon.png)](https://github.com/hpcaitech/Open-Sora-Demo/blob/main/readme/icon.png)
[![](https://camo.githubusercontent.com/64dc5b1be7ac7304da43242a6c24d75daef4cd39b58c9a77caa4762efd4627e4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6870636169746563682f4f70656e2d536f72613f7374796c653d736f6369616c)](https://github.com/hpcaitech/Open-Sora/stargazers) [![](https://camo.githubusercontent.com/f61d8de5f4074d678d8f5912c11c1b514e6614458305f95365bcc4f40375b983/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d54656368205265706f727420322e30266d6573736167653d417278697626636f6c6f723d726564)](https://arxiv.org/abs/2503.09642v1) [![](https://camo.githubusercontent.com/63ceb3688154019683b497f0a9d97fc578b62a44e24c359a427505ae6f41faa8/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d54656368205265706f727420312e32266d6573736167653d417278697626636f6c6f723d726564)](https://arxiv.org/abs/2412.20404) [![](https://camo.githubusercontent.com/6a7c7defd338f0d8e965abbf262d459baf33a13e9e2a148f55aafb1801347459/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f47616c6c6572792d566965772d6f72616e67653f6c6f676f3d26)](https://hpcaitech.github.io/Open-Sora/)
[![](https://camo.githubusercontent.com/efaeaefeb4bdb61d02b270e599f8a6df0df0fa80b904b7031aa5b3f7a068e2cf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446973636f72642d6a6f696e2d626c756576696f6c65743f6c6f676f3d646973636f726426)](https://discord.gg/kZakZzrSUT) [![](https://camo.githubusercontent.com/2c27268dea0dc7284d61e6d51ff0d8f4c316037a82a46b6139efe7a514cfb24c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f536c61636b2d436f6c6f7373616c41492d626c756576696f6c65743f6c6f676f3d736c61636b26)](https://join.slack.com/t/colossalaiworkspace/shared_invite/zt-247ipg9fk-KRRYmUl~u2ll2637WRURVA) [![](https://camo.githubusercontent.com/e270c337c83d11e774315a1c88ac5ce4466d8a9a569ce6b6572c2309738d10de/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f547769747465722d446973637573732d626c75653f6c6f676f3d7477697474657226)](https://x.com/YangYou1991/status/1899973689460044010) [![](https://camo.githubusercontent.com/ce33304a9340ae787c7cda8d19b6f3a343872353b0477771508e64a145c95fa3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652fe5beaee4bfa12de5b08fe58aa9e6898be58aa0e7bea42d677265656e3f6c6f676f3d77656368617426)](https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/WeChat.png)
## Open-Sora: Democratizing Efficient Video Production for All
[](https://github.com/hpcaitech/Open-Sora#open-sora-democratizing-efficient-video-production-for-all)
We design and implement **Open-Sora** , an initiative dedicated to **efficiently** producing high-quality video. We hope to make the model, tools and all details accessible to all. By embracing **open-source** principles, Open-Sora not only democratizes access to advanced video generation techniques, but also offers a streamlined and user-friendly platform that simplifies the complexities of video generation. With Open-Sora, our goal is to foster innovation, creativity, and inclusivity within the field of content creation.
🎬 For a professional AI video-generation product, try [Video Ocean](https://video-ocean.com/) — powered by a superior model.
[ ![](https://github.com/hpcaitech/public_assets/raw/main/colossalai/img/3.gif) ](https://video-ocean.com/)
[ ![](https://github.com/hpcaitech/public_assets/raw/main/colossalai/img/1.gif) ](https://hpc-ai.com/?utm_source=github&utm_medium=social&utm_campaign=promotion-opensora)
## 📰 News
[](https://github.com/hpcaitech/Open-Sora#-news)
  * **[2025.03.12]** 🔥 We released **Open-Sora 2.0** (11B). 🎬 11B model achieves [on-par performance](https://github.com/hpcaitech/Open-Sora#evaluation) with 11B HunyuanVideo & 30B Step-Video on 📐VBench & 📊Human Preference. 🛠️ Fully open-source: checkpoints and training codes for training with only **$200K**. [[report]](https://arxiv.org/abs/2503.09642v1)
  * **[2025.02.20]** 🔥 We released **Open-Sora 1.3** (1B). With the upgraded VAE and Transformer architecture, the quality of our generated videos has been greatly improved 🚀. [[checkpoints]](https://github.com/hpcaitech/Open-Sora#open-sora-13-model-weights) [[report]](https://github.com/hpcaitech/Open-Sora/blob/main/docs/report_04.md) [[demo]](https://huggingface.co/spaces/hpcai-tech/open-sora)
  * **[2024.12.23]** The development cost of video generation models has saved by 50%! Open-source solutions are now available with H200 GPU vouchers. [[blog]](https://company.hpc-ai.com/blog/the-development-cost-of-video-generation-models-has-saved-by-50-open-source-solutions-are-now-available-with-h200-gpu-vouchers) [[code]](https://github.com/hpcaitech/Open-Sora/blob/main/scripts/train.py) [[vouchers]](https://colossalai.org/zh-Hans/docs/get_started/bonus/)
  * **[2024.06.17]** We released **Open-Sora 1.2** , which includes **3D-VAE** , **rectified flow** , and **score condition**. The video quality is greatly improved. [[checkpoints]](https://github.com/hpcaitech/Open-Sora#open-sora-12-model-weights) [[report]](https://github.com/hpcaitech/Open-Sora/blob/main/docs/report_03.md) [[arxiv]](https://arxiv.org/abs/2412.20404)
  * **[2024.04.25]** 🤗 We released the [Gradio demo for Open-Sora](https://huggingface.co/spaces/hpcai-tech/open-sora) on Hugging Face Spaces.
  * **[2024.04.25]** We released **Open-Sora 1.1** , which supports **2s~15s, 144p to 720p, any aspect ratio** text-to-image, **text-to-video, image-to-video, video-to-video, infinite time** generation. In addition, a full video processing pipeline is released. [[checkpoints]](https://github.com/hpcaitech/Open-Sora#open-sora-11-model-weights) [[report]](https://github.com/hpcaitech/Open-Sora/blob/main/docs/report_02.md)
  * **[2024.03.18]** We released **Open-Sora 1.0** , a fully open-source project for video generation. Open-Sora 1.0 supports a full pipeline of video data preprocessing, training with [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/readme/colossal_ai.png)](https://github.com/hpcaitech/ColossalAI) acceleration, inference, and more. Our model can produce 2s 512x512 videos with only 3 days training. [[checkpoints]](https://github.com/hpcaitech/Open-Sora#open-sora-10-model-weights) [[blog]](https://hpc-ai.com/blog/open-sora-v1.0) [[report]](https://github.com/hpcaitech/Open-Sora/blob/main/docs/report_01.md)
  * **[2024.03.04]** Open-Sora provides training with 46% cost reduction. [[blog]](https://hpc-ai.com/blog/open-sora)


📍 Since Open-Sora is under active development, we remain different branches for different versions. The latest version is [main](https://github.com/hpcaitech/Open-Sora). Old versions include: [v1.0](https://github.com/hpcaitech/Open-Sora/tree/opensora/v1.0), [v1.1](https://github.com/hpcaitech/Open-Sora/tree/opensora/v1.1), [v1.2](https://github.com/hpcaitech/Open-Sora/tree/opensora/v1.2), [v1.3](https://github.com/hpcaitech/Open-Sora/tree/opensora/v1.3).
## 🎥 Latest Demo
[](https://github.com/hpcaitech/Open-Sora#-latest-demo)
Demos are presented in compressed GIF format for convenience. For original quality samples and their corresponding prompts, please visit our [Gallery](https://hpcaitech.github.io/Open-Sora/).
**5s 1024×576** | **5s 576×1024** | **5s 576×1024**  
---|---|---  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/ft_0001_1_1.gif)](https://streamable.com/e/8g9y9h?autoplay=1) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/movie_0160.gif)](https://streamable.com/e/k50mnv?autoplay=1) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/movie_0017.gif)](https://streamable.com/e/bzrn9n?autoplay=1)  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/ft_0012_1_1.gif)](https://streamable.com/e/dsv8da?autoplay=1) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/douyin_0005.gif)](https://streamable.com/e/3wif07?autoplay=1) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/movie_0037.gif)](https://streamable.com/e/us2w7h?autoplay=1)  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/ft_0055_1_1.gif)](https://streamable.com/e/yfwk8i?autoplay=1) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/sora_0019.gif)](https://streamable.com/e/jgjil0?autoplay=1) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/movie_0463.gif)](https://streamable.com/e/lsoai1?autoplay=1)  
OpenSora 1.3 Demo **5s 720×1280** | **5s 720×1280** | **5s 720×1280**  
---|---|---  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_tomato.gif)](https://streamable.com/e/r0imrp?quality=highest&autoplay=1) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_fisherman.gif)](https://streamable.com/e/hfvjkh?quality=highest&autoplay=1) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_girl2.gif)](https://streamable.com/e/kutmma?quality=highest&autoplay=1)  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_grape.gif)](https://streamable.com/e/osn1la?quality=highest&autoplay=1) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_mushroom.gif)](https://streamable.com/e/l1pzws?quality=highest&autoplay=1) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_parrot.gif)](https://streamable.com/e/2vqari?quality=highest&autoplay=1)  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_trans.gif)](https://streamable.com/e/1in7d6?quality=highest&autoplay=1) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_bear.gif)](https://streamable.com/e/e9bi4o?quality=highest&autoplay=1) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_futureflower.gif)](https://streamable.com/e/09z7xi?quality=highest&autoplay=1)  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_fire.gif)](https://streamable.com/e/16c3hk?quality=highest&autoplay=1) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_man.gif)](https://streamable.com/e/wi250w?quality=highest&autoplay=1) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.3/demo_black.gif)](https://streamable.com/e/vw5b64?quality=highest&autoplay=1)  
OpenSora 1.2 Demo **4s 720×1280** | **4s 720×1280** | **4s 720×1280**  
---|---|---  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_0013.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/7895aab6-ed23-488c-8486-091480c26327) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_1718.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/20f07c7b-182b-4562-bbee-f1df74c86c9a) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_0087.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/3d897e0d-dc21-453a-b911-b3bda838acc2)  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_0052.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/644bf938-96ce-44aa-b797-b3c0b513d64c) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_1719.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/272d88ac-4b4a-484d-a665-8d07431671d0) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_0002.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/ebbac621-c34e-4bb4-9543-1c34f8989764)  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_0011.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/a1e3a1a3-4abd-45f5-8df2-6cced69da4ca) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_0004.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/d6ce9c13-28e1-4dff-9644-cc01f5f11926) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.2/sample_0061.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/561978f8-f1b0-4f4d-ae7b-45bec9001b4a)  
OpenSora 1.1 Demo **2s 240×426** | **2s 240×426**  
---|---  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sample_16x240x426_9.gif)](https://github.com/hpcaitech/Open-Sora-dev/assets/99191637/c31ebc52-de39-4a4e-9b1e-9211d45e05b2) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sora_16x240x426_26.gif)](https://github.com/hpcaitech/Open-Sora-dev/assets/99191637/c31ebc52-de39-4a4e-9b1e-9211d45e05b2)  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sora_16x240x426_27.gif)](https://github.com/hpcaitech/Open-Sora-dev/assets/99191637/f7ce4aaa-528f-40a8-be7a-72e61eaacbbd) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sora_16x240x426_40.gif)](https://github.com/hpcaitech/Open-Sora-dev/assets/99191637/5d58d71e-1fda-4d90-9ad3-5f2f7b75c6a9)  
**2s 426×240** | **4s 480×854**  
---|---  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sora_16x426x240_24.gif)](https://github.com/hpcaitech/Open-Sora-dev/assets/99191637/34ecb4a0-4eef-4286-ad4c-8e3a87e5a9fd) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sample_32x480x854_9.gif)](https://github.com/hpcaitech/Open-Sora-dev/assets/99191637/c1619333-25d7-42ba-a91c-18dbc1870b18)  
**16s 320×320** | **16s 224×448** | **2s 426×240**  
---|---|---  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sample_16s_320x320.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/3cab536e-9b43-4b33-8da8-a0f9cf842ff2) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sample_16s_224x448.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/9fb0b9e0-c6f4-4935-b29e-4cac10b373c4) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.1/sora_16x426x240_3.gif)](https://github.com/hpcaitech/Open-Sora-dev/assets/99191637/3e892ad2-9543-4049-b005-643a4c1bf3bf)  
OpenSora 1.0 Demo **2s 512×512** | **2s 512×512** | **2s 512×512**  
---|---|---  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.0/sample_0.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/de1963d3-b43b-4e68-a670-bb821ebb6f80) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.0/sample_1.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/13f8338f-3d42-4b71-8142-d234fbd746cc) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.0/sample_2.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/fa6a65a6-e32a-4d64-9a9e-eabb0ebb8c16)  
A serene night scene in a forested area. [...] The video is a time-lapse, capturing the transition from day to night, with the lake and forest serving as a constant backdrop. | A soaring drone footage captures the majestic beauty of a coastal cliff, [...] The water gently laps at the rock base and the greenery that clings to the top of the cliff. | The majestic beauty of a waterfall cascading down a cliff into a serene lake. [...] The camera angle provides a bird's eye view of the waterfall.  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.0/sample_3.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/64232f84-1b36-4750-a6c0-3e610fa9aa94) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.0/sample_4.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/983a1965-a374-41a7-a76b-c07941a6c1e9) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v1.0/sample_5.gif)](https://github.com/hpcaitech/Open-Sora/assets/99191637/ec10c879-9767-4c31-865f-2e8d6cf11e65)  
A bustling city street at night, filled with the glow of car headlights and the ambient light of streetlights. [...] | The vibrant beauty of a sunflower field. The sunflowers are arranged in neat rows, creating a sense of order and symmetry. [...] | A serene underwater scene featuring a sea turtle swimming through a coral reef. The turtle, with its greenish-brown shell [...]  
Videos are downsampled to `.gif` for display. Click for original videos. Prompts are trimmed for display, see [here](https://github.com/hpcaitech/Open-Sora/blob/main/assets/texts/t2v_samples.txt) for full prompts.
## 🔆 Reports
[](https://github.com/hpcaitech/Open-Sora#-reports)
  * **[Tech Report of Open-Sora 2.0](https://arxiv.org/abs/2503.09642v1)**
  * **[Step by step to train or finetune your own model](https://github.com/hpcaitech/Open-Sora/blob/main/docs/train.md)**
  * **[Step by step to train and evaluate an video autoencoder](https://github.com/hpcaitech/Open-Sora/blob/main/docs/ae.md)**
  * **[Visit the high compression video autoencoder](https://github.com/hpcaitech/Open-Sora/blob/main/docs/hcae.md)**
  * Reports of previous version (better see in according branch): 
    * [Open-Sora 1.3](https://github.com/hpcaitech/Open-Sora/blob/main/docs/report_04.md): shift-window attention, unified spatial-temporal VAE, etc.
    * [Open-Sora 1.2](https://github.com/hpcaitech/Open-Sora/blob/main/docs/report_03.md), [Tech Report](https://arxiv.org/abs/2412.20404): rectified flow, 3d-VAE, score condition, evaluation, etc.
    * [Open-Sora 1.1](https://github.com/hpcaitech/Open-Sora/blob/main/docs/report_02.md): multi-resolution/length/aspect-ratio, image/video conditioning/editing, data preprocessing, etc.
    * [Open-Sora 1.0](https://github.com/hpcaitech/Open-Sora/blob/main/docs/report_01.md): architecture, captioning, etc.


📍 Since Open-Sora is under active development, we remain different branches for different versions. The latest version is [main](https://github.com/hpcaitech/Open-Sora). Old versions include: [v1.0](https://github.com/hpcaitech/Open-Sora/tree/opensora/v1.0), [v1.1](https://github.com/hpcaitech/Open-Sora/tree/opensora/v1.1), [v1.2](https://github.com/hpcaitech/Open-Sora/tree/opensora/v1.2), [v1.3](https://github.com/hpcaitech/Open-Sora/tree/opensora/v1.3).
## Quickstart
[](https://github.com/hpcaitech/Open-Sora#quickstart)
### Installation
[](https://github.com/hpcaitech/Open-Sora#installation)
```
# create a virtual env and activate (conda as an example)
conda create -n opensora python=3.10
conda activate opensora
# download the repo
git clone https://github.com/hpcaitech/Open-Sora
cd Open-Sora
# Ensure torch >= 2.4.0
pip install -v . # for development mode, `pip install -v -e .`
pip install xformers==0.0.27.post2 --index-url https://download.pytorch.org/whl/cu121 # install xformers according to your cuda version
pip install flash-attn --no-build-isolation
```

Optionally, you can install flash attention 3 for faster speed.
```
git clone https://github.com/Dao-AILab/flash-attention # 4f0640d5
cd flash-attention/hopper
python setup.py install
```

### Model Download
[](https://github.com/hpcaitech/Open-Sora#model-download)
Our 11B model supports 256px and 768px resolution. Both T2V and I2V are supported by one model. 🤗 [Huggingface](https://huggingface.co/hpcai-tech/Open-Sora-v2) 🤖 [ModelScope](https://modelscope.cn/models/luchentech/Open-Sora-v2).
Download from huggingface:
```
pip install "huggingface_hub[cli]"
huggingface-cli download hpcai-tech/Open-Sora-v2 --local-dir ./ckpts
```

Download from ModelScope:
```
pip install modelscope
modelscope download hpcai-tech/Open-Sora-v2 --local_dir ./ckpts
```

### Text-to-Video Generation
[](https://github.com/hpcaitech/Open-Sora#text-to-video-generation)
Our model is optimized for image-to-video generation, but it can also be used for text-to-video generation. To generate high quality videos, with the help of flux text-to-image model, we build a text-to-image-to-video pipeline. For 256x256 resolution:
```
# Generate one given prompt
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_256px.py --save-dir samples --prompt "raining, sea"
# Save memory with offloading
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_256px.py --save-dir samples --prompt "raining, sea" --offload True
# Generation with csv
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_256px.py --save-dir samples --dataset.data-path assets/texts/example.csv
```

For 768x768 resolution:
```
# One GPU
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_768px.py --save-dir samples --prompt "raining, sea"
# Multi-GPU with colossalai sp
torchrun --nproc_per_node 8 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_768px.py --save-dir samples --prompt "raining, sea"
```

You can adjust the generation aspect ratio by `--aspect_ratio` and the generation length by `--num_frames`. Candidate values for aspect_ratio includes `16:9`, `9:16`, `1:1`, `2.39:1`. Candidate values for num_frames should be `4k+1` and less than 129.
You can also run direct text-to-video by:
```
# One GPU for 256px
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/256px.py --prompt "raining, sea"
# Multi-GPU for 768px
torchrun --nproc_per_node 8 --standalone scripts/diffusion/inference.py configs/diffusion/inference/768px.py --prompt "raining, sea"
```

### Image-to-Video Generation
[](https://github.com/hpcaitech/Open-Sora#image-to-video-generation)
Given a prompt and a reference image, you can generate a video with the following command:
```
# 256px
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/256px.py --cond_type i2v_head --prompt "A plump pig wallows in a muddy pond on a rustic farm, its pink snout poking out as it snorts contentedly. The camera captures the pig's playful splashes, sending ripples through the water under the midday sun. Wooden fences and a red barn stand in the background, framed by rolling green hills. The pig's muddy coat glistens in the sunlight, showcasing the simple pleasures of its carefree life." --ref assets/texts/i2v.png
# 256px with csv
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/256px.py --cond_type i2v_head --dataset.data-path assets/texts/i2v.csv
# Multi-GPU 768px
torchrun --nproc_per_node 8 --standalone scripts/diffusion/inference.py configs/diffusion/inference/768px.py --cond_type i2v_head --dataset.data-path assets/texts/i2v.csv
```

## Advanced Usage
[](https://github.com/hpcaitech/Open-Sora#advanced-usage)
### Motion Score
[](https://github.com/hpcaitech/Open-Sora#motion-score)
During training, we provide motion score into the text prompt. During inference, you can use the following command to generate videos with motion score (the default score is 4):
```
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_256px.py --save-dir samples --prompt "raining, sea" --motion-score 4
```

We also provide a dynamic motion score evaluator. After setting your OpenAI API key, you can use the following command to evaluate the motion score of a video:
```
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_256px.py --save-dir samples --prompt "raining, sea" --motion-score dynamic
```

Score | 1 | 4 | 7  
---|---|---|---  
[![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/motion_score_1.gif)](https://github.com/hpcaitech/Open-Sora-Demo/blob/main/demo/v2.0/motion_score_1.gif) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/motion_score_4.gif)](https://github.com/hpcaitech/Open-Sora-Demo/blob/main/demo/v2.0/motion_score_4.gif) | [![](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/demo/v2.0/motion_score_7.gif)](https://github.com/hpcaitech/Open-Sora-Demo/blob/main/demo/v2.0/motion_score_7.gif)  
### Prompt Refine
[](https://github.com/hpcaitech/Open-Sora#prompt-refine)
We take advantage of ChatGPT to refine the prompt. You can use the following command to refine the prompt. The function is available for both text-to-video and image-to-video generation.
```
export OPENAI_API_KEY=sk-xxxx
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_256px.py --save-dir samples --prompt "raining, sea" --refine-prompt True
```

### Reproductivity
[](https://github.com/hpcaitech/Open-Sora#reproductivity)
To make the results reproducible, you can set the random seed by:
```
torchrun --nproc_per_node 1 --standalone scripts/diffusion/inference.py configs/diffusion/inference/t2i2v_256px.py --save-dir samples --prompt "raining, sea" --sampling_option.seed 42 --seed 42
```

Use `--num-sample k` to generate `k` samples for each prompt.
## Computational Efficiency
[](https://github.com/hpcaitech/Open-Sora#computational-efficiency)
We test the computational efficiency of text-to-video on H100/H800 GPU. For 256x256, we use colossalai's tensor parallelism, and `--offload True` is used. For 768x768, we use colossalai's sequence parallelism. All use number of steps 50. The results are presented in the format: $\color{blue}{\text{Total time (s)}}/\color{red}{\text{peak GPU memory (GB)}}$
Resolution | 1x GPU | 2x GPUs | 4x GPUs | 8x GPUs  
---|---|---|---|---  
256x256 | $\color{blue}{60}/\color{red}{52.5}$ | $\color{blue}{40}/\color{red}{44.3}$ | $\color{blue}{34}/\color{red}{44.3}$  
768x768 | $\color{blue}{1656}/\color{red}{60.3}$ | $\color{blue}{863}/\color{red}{48.3}$ | $\color{blue}{466}/\color{red}{44.3}$ | $\color{blue}{276}/\color{red}{44.3}$  
## Evaluation
[](https://github.com/hpcaitech/Open-Sora#evaluation)
On [VBench](https://huggingface.co/spaces/Vchitect/VBench_Leaderboard), Open-Sora 2.0 significantly narrows the gap with OpenAI’s Sora, reducing it from 4.52% → 0.69% compared to Open-Sora 1.2.
[![VBench](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/readme/v2_vbench.png)](https://github.com/hpcaitech/Open-Sora-Demo/blob/main/readme/v2_vbench.png)
Human preference results show our model is on par with HunyuanVideo 11B and Step-Video 30B.
[![Win Rate](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/readme/v2_winrate.png)](https://github.com/hpcaitech/Open-Sora-Demo/blob/main/readme/v2_winrate.png)
With strong performance, Open-Sora 2.0 is cost-effective.
[![Cost](https://github.com/hpcaitech/Open-Sora-Demo/raw/main/readme/v2_cost.png)](https://github.com/hpcaitech/Open-Sora-Demo/blob/main/readme/v2_cost.png)
## Contribution
[](https://github.com/hpcaitech/Open-Sora#contribution)
Thanks goes to these wonderful contributors:
[ ![](https://camo.githubusercontent.com/5cdddbfc17e31a502cd3dded290742ffb4d51dfa670ba13e6467959245f94ba4/68747470733a2f2f636f6e747269622e726f636b732f696d6167653f7265706f3d6870636169746563682f4f70656e2d536f7261) ](https://github.com/hpcaitech/Open-Sora/graphs/contributors)
If you wish to contribute to this project, please refer to the [Contribution Guideline](https://github.com/hpcaitech/Open-Sora/blob/main/CONTRIBUTING.md).
## Acknowledgement
[](https://github.com/hpcaitech/Open-Sora#acknowledgement)
Here we only list a few of the projects. For other works and datasets, please refer to our report.
  * [ColossalAI](https://github.com/hpcaitech/ColossalAI): A powerful large model parallel acceleration and optimization system.
  * [DiT](https://github.com/facebookresearch/DiT): Scalable Diffusion Models with Transformers.
  * [OpenDiT](https://github.com/NUS-HPC-AI-Lab/OpenDiT): An acceleration for DiT training. We adopt valuable acceleration strategies for training progress from OpenDiT.
  * [PixArt](https://github.com/PixArt-alpha/PixArt-alpha): An open-source DiT-based text-to-image model.
  * [Flux](https://github.com/black-forest-labs/flux): A powerful text-to-image generation model.
  * [Latte](https://github.com/Vchitect/Latte): An attempt to efficiently train DiT for video.
  * [HunyuanVideo](https://github.com/Tencent/HunyuanVideo/tree/main?tab=readme-ov-file): Open-Source text-to-video model.
  * [StabilityAI VAE](https://huggingface.co/stabilityai/sd-vae-ft-mse-original): A powerful image VAE model.
  * [DC-AE](https://github.com/mit-han-lab/efficientvit): Deep Compression AutoEncoder for image compression.
  * [CLIP](https://github.com/openai/CLIP): A powerful text-image embedding model.
  * [T5](https://github.com/google-research/text-to-text-transfer-transformer): A powerful text encoder.
  * [LLaVA](https://github.com/haotian-liu/LLaVA): A powerful image captioning model based on [Mistral-7B](https://huggingface.co/mistralai/Mistral-7B-v0.1) and [Yi-34B](https://huggingface.co/01-ai/Yi-34B).
  * [PLLaVA](https://github.com/magic-research/PLLaVA): A powerful video captioning model.
  * [MiraData](https://github.com/mira-space/MiraData): A large-scale video dataset with long durations and structured caption.


## Citation
[](https://github.com/hpcaitech/Open-Sora#citation)
```
@article{opensora,
 title={Open-sora: Democratizing efficient video production for all},
 author={Zheng, Zangwei and Peng, Xiangyu and Yang, Tianji and Shen, Chenhui and Li, Shenggui and Liu, Hongxin and Zhou, Yukun and Li, Tianyi and You, Yang},
 journal={arXiv preprint arXiv:2412.20404},
 year={2024}
}
@article{opensora2,
  title={Open-Sora 2.0: Training a Commercial-Level Video Generation Model in $200k}, 
  author={Xiangyu Peng and Zangwei Zheng and Chenhui Shen and Tom Young and Xinying Guo and Binluo Wang and Hang Xu and Hongxin Liu and Mingyan Jiang and Wenjun Li and Yuhui Wang and Anbang Ye and Gang Ren and Qianran Ma and Wanying Liang and Xiang Lian and Xiwen Wu and Yuting Zhong and Zhuangyan Li and Chaoyu Gong and Guojun Lei and Leijun Cheng and Limin Zhang and Minghao Li and Ruijie Zhang and Silan Hu and Shijie Huang and Xiaokang Wang and Yuanheng Zhao and Yuqi Wang and Ziang Wei and Yang You},
  year={2025},
  journal={arXiv preprint arXiv:2503.09642},
}
```

## Star History
[](https://github.com/hpcaitech/Open-Sora#star-history)
[![Star History Chart](https://camo.githubusercontent.com/3fe4ff7323fb8ded741d90823b8c8937c6f43e029539c3ca8721a70f0bd1fc2e/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6870636169746563682f4f70656e2d536f726126747970653d44617465)](https://star-history.com/#hpcaitech/Open-Sora&Date)
## About
Open-Sora: Democratizing Efficient Video Production for All 
[hpcaitech.github.io/Open-Sora/](https://hpcaitech.github.io/Open-Sora/ "https://hpcaitech.github.io/Open-Sora/")
### Resources
[ Readme ](https://github.com/hpcaitech/Open-Sora#readme-ov-file)
### License
[ Apache-2.0 license ](https://github.com/hpcaitech/Open-Sora#Apache-2.0-1-ov-file)
[ Activity](https://github.com/hpcaitech/Open-Sora/activity)
[ Custom properties](https://github.com/hpcaitech/Open-Sora/custom-properties)
### Stars
[ **25.9k** stars](https://github.com/hpcaitech/Open-Sora/stargazers)
### Watchers
[ **204** watching](https://github.com/hpcaitech/Open-Sora/watchers)
### Forks
[ **2.5k** forks](https://github.com/hpcaitech/Open-Sora/forks)
[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fhpcaitech%2FOpen-Sora&report=hpcaitech+%28user%29)
##  [Releases 4](https://github.com/hpcaitech/Open-Sora/releases)
[ Open-Sora V1.3 Release Latest  Feb 21, 2025 ](https://github.com/hpcaitech/Open-Sora/releases/tag/v1.3)
[+ 3 releases](https://github.com/hpcaitech/Open-Sora/releases)
##  [Packages 0](https://github.com/orgs/hpcaitech/packages?repo_name=Open-Sora)
No packages published 
##  [Contributors 59](https://github.com/hpcaitech/Open-Sora/graphs/contributors)
  * [ ![@zhengzangw](https://avatars.githubusercontent.com/u/30647653?s=64&v=4) ](https://github.com/zhengzangw)
  * [ ![@Shen-Chenhui](https://avatars.githubusercontent.com/u/24800477?s=64&v=4) ](https://github.com/Shen-Chenhui)
  * [ ![@FrankLeeeee](https://avatars.githubusercontent.com/u/31818963?s=64&v=4) ](https://github.com/FrankLeeeee)
  * [ ![@tomyoung903](https://avatars.githubusercontent.com/u/44153440?s=64&v=4) ](https://github.com/tomyoung903)
  * [ ![@xyupeng](https://avatars.githubusercontent.com/u/99191637?s=64&v=4) ](https://github.com/xyupeng)
  * [ ![@Yanjia0](https://avatars.githubusercontent.com/u/42895286?s=64&v=4) ](https://github.com/Yanjia0)
  * [ ![@ver217](https://avatars.githubusercontent.com/u/23111350?s=64&v=4) ](https://github.com/ver217)
  * [ ![@Sze-qq](https://avatars.githubusercontent.com/u/68757353?s=64&v=4) ](https://github.com/Sze-qq)
  * [ ![@1zeryu](https://avatars.githubusercontent.com/u/90625606?s=64&v=4) ](https://github.com/1zeryu)
  * [ ![@binmakeswell](https://avatars.githubusercontent.com/u/61670638?s=64&v=4) ](https://github.com/binmakeswell)
  * [ ![@eltociear](https://avatars.githubusercontent.com/u/22633385?s=64&v=4) ](https://github.com/eltociear)
  * [ ![@gxyes](https://avatars.githubusercontent.com/u/96687844?s=64&v=4) ](https://github.com/gxyes)
  * [ ![@ChangeFWorld](https://avatars.githubusercontent.com/u/90496029?s=64&v=4) ](https://github.com/ChangeFWorld)
  * [ ![@BurkeHulk](https://avatars.githubusercontent.com/u/173246433?s=64&v=4) ](https://github.com/BurkeHulk)


[+ 45 contributors](https://github.com/hpcaitech/Open-Sora/graphs/contributors)
## Languages
  * [ Python 100.0% ](https://github.com/hpcaitech/Open-Sora/search?l=python)


## Footer
[ ](https://github.com "GitHub") © 2025 GitHub, Inc. 
### Footer navigation
  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
  * [Security](https://github.com/security)
  * [Status](https://www.githubstatus.com/)
  * [Docs](https://docs.github.com/)
  * [Contact](https://support.github.com?tags=dotcom-footer)
  * Manage cookies 
  * Do not share my personal information 


You can’t perform that action at this time. 
