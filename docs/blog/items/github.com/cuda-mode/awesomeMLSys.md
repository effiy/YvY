# 原始URL: https://github.com/cuda-mode/awesomeMLSys

# 抓取时间: 2025-03-30 21:25:07

[Skip to content](https://github.com/cuda-mode/awesomeMLSys#start-of-content)
## Navigation Menu
Toggle navigation
[ ](https://github.com/)
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fgpu-mode%2FawesomeMLSys)
  * Product 
    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)
    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)
    * [ Actions Automate any workflow  ](https://github.com/features/actions)
    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)
    * [ Issues Plan and track work  ](https://github.com/features/issues)
    * [ Code Review Manage code changes  ](https://github.com/features/code-review)
    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)
    * [ Code Search Find more, search less  ](https://github.com/features/code-search)
Explore
    * [ All features ](https://github.com/features)
    * [ Documentation ](https://docs.github.com)
    * [ GitHub Skills ](https://skills.github.com)
    * [ Blog ](https://github.blog)
  * Solutions 
By company size
    * [ Enterprises ](https://github.com/enterprise)
    * [ Small and medium teams ](https://github.com/team)
    * [ Startups ](https://github.com/enterprise/startups)
    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)
By use case
    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)
    * [ DevOps ](https://github.com/solutions/use-case/devops)
    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)
    * [ View all use cases ](https://github.com/solutions/use-case)
By industry
    * [ Healthcare ](https://github.com/solutions/industry/healthcare)
    * [ Financial services ](https://github.com/solutions/industry/financial-services)
    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)
    * [ Government ](https://github.com/solutions/industry/government)
    * [ View all industries ](https://github.com/solutions/industry)
[ View all solutions ](https://github.com/solutions)
  * Resources 
Topics
    * [ AI ](https://github.com/resources/articles/ai)
    * [ DevOps ](https://github.com/resources/articles/devops)
    * [ Security ](https://github.com/resources/articles/security)
    * [ Software Development ](https://github.com/resources/articles/software-development)
    * [ View all ](https://github.com/resources/articles)
Explore
    * [ Learning Pathways ](https://resources.github.com/learn/pathways)
    * [ Events & Webinars ](https://resources.github.com)
    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)
    * [ Customer Stories ](https://github.com/customer-stories)
    * [ Partners ](https://partner.github.com)
    * [ Executive Insights ](https://github.com/solutions/executive-insights)
  * Open Source 
    * [ GitHub Sponsors Fund open source developers  ](https://github.com/sponsors)
    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)
Repositories
    * [ Topics ](https://github.com/topics)
    * [ Trending ](https://github.com/trending)
    * [ Collections ](https://github.com/collections)
  * Enterprise 
    * [ Enterprise platform AI-powered developer platform  ](https://github.com/enterprise)
Available add-ons
    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)
    * [ Copilot for business Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)
    * [ Premium Support Enterprise-grade 24/7 support  ](https://github.com/premium-support)
  * [Pricing](https://github.com/pricing)


Search or jump to...
# Search code, repositories, users, issues, pull requests...
Search 
Clear
[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)
#  Provide feedback 
We read every piece of feedback, and take your input very seriously.
Include my email address so I can be contacted
Cancel  Submit feedback 
#  Saved searches 
## Use saved searches to filter your results more quickly
Name
Query
To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). 
Cancel  Create saved search 
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fgpu-mode%2FawesomeMLSys)
[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=gpu-mode%2FawesomeMLSys) Reseting focus
You signed in with another tab or window. [Reload](https://github.com/cuda-mode/awesomeMLSys) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/cuda-mode/awesomeMLSys) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/cuda-mode/awesomeMLSys) to refresh your session. Dismiss alert
{{ message }}
[ gpu-mode ](https://github.com/gpu-mode) / **[awesomeMLSys](https://github.com/gpu-mode/awesomeMLSys) ** Public
  * [ Notifications ](https://github.com/login?return_to=%2Fgpu-mode%2FawesomeMLSys) You must be signed in to change notification settings
  * [ Fork 26 ](https://github.com/login?return_to=%2Fgpu-mode%2FawesomeMLSys)
  * [ Star  738 ](https://github.com/login?return_to=%2Fgpu-mode%2FawesomeMLSys)


An ML Systems Onboarding list 
[ 738 stars ](https://github.com/gpu-mode/awesomeMLSys/stargazers) [ 26 forks ](https://github.com/gpu-mode/awesomeMLSys/forks) [ Branches ](https://github.com/gpu-mode/awesomeMLSys/branches) [ Tags ](https://github.com/gpu-mode/awesomeMLSys/tags) [ Activity ](https://github.com/gpu-mode/awesomeMLSys/activity)
[ Star  ](https://github.com/login?return_to=%2Fgpu-mode%2FawesomeMLSys)
[ Notifications ](https://github.com/login?return_to=%2Fgpu-mode%2FawesomeMLSys) You must be signed in to change notification settings
  * [ Code ](https://github.com/gpu-mode/awesomeMLSys)
  * [ Issues 0 ](https://github.com/gpu-mode/awesomeMLSys/issues)
  * [ Pull requests 0 ](https://github.com/gpu-mode/awesomeMLSys/pulls)
  * [ Actions ](https://github.com/gpu-mode/awesomeMLSys/actions)
  * [ Projects 0 ](https://github.com/gpu-mode/awesomeMLSys/projects)
  * [ Security ](https://github.com/gpu-mode/awesomeMLSys/security)
  * [ Insights ](https://github.com/gpu-mode/awesomeMLSys/pulse)


Additional navigation options
  * [ Code  ](https://github.com/gpu-mode/awesomeMLSys)
  * [ Issues  ](https://github.com/gpu-mode/awesomeMLSys/issues)
  * [ Pull requests  ](https://github.com/gpu-mode/awesomeMLSys/pulls)
  * [ Actions  ](https://github.com/gpu-mode/awesomeMLSys/actions)
  * [ Projects  ](https://github.com/gpu-mode/awesomeMLSys/projects)
  * [ Security  ](https://github.com/gpu-mode/awesomeMLSys/security)
  * [ Insights  ](https://github.com/gpu-mode/awesomeMLSys/pulse)


# gpu-mode/awesomeMLSys
main
[Branches](https://github.com/gpu-mode/awesomeMLSys/branches)[Tags](https://github.com/gpu-mode/awesomeMLSys/tags)
[](https://github.com/gpu-mode/awesomeMLSys/branches)[](https://github.com/gpu-mode/awesomeMLSys/tags)
Go to file
Code
## Folders and files
Name| Name| Last commit message| Last commit date  
---|---|---|---  
## Latest commit
## History
[14 Commits](https://github.com/gpu-mode/awesomeMLSys/commits/main/)[](https://github.com/gpu-mode/awesomeMLSys/commits/main/)  
[README.md](https://github.com/gpu-mode/awesomeMLSys/blob/main/README.md "README.md")| [README.md](https://github.com/gpu-mode/awesomeMLSys/blob/main/README.md "README.md")  
[conferences.md](https://github.com/gpu-mode/awesomeMLSys/blob/main/conferences.md "conferences.md")| [conferences.md](https://github.com/gpu-mode/awesomeMLSys/blob/main/conferences.md "conferences.md")  
View all files  
## Repository files navigation
  * [README](https://github.com/cuda-mode/awesomeMLSys)


## ML Systems Onboarding Reading List
[](https://github.com/cuda-mode/awesomeMLSys#ml-systems-onboarding-reading-list)
This is a reading list of papers/videos/repos I've personally found useful as I was ramping up on ML Systems and that I wish more people would just sit and study carefully during their work hours. If you're looking for more recommendations, go through the citations of the below papers and enjoy!
[Conferences](https://github.com/gpu-mode/awesomeMLSys/blob/main/conferences.md) where MLSys papers get published
## Attention Mechanism
[](https://github.com/cuda-mode/awesomeMLSys#attention-mechanism)
  * [Attention is all you need](https://arxiv.org/abs/1706.03762): Start here, Still one of the best intros
  * [Online normalizer calculation for softmax](https://arxiv.org/abs/1805.02867): A must read before reading the flash attention. Will help you get the main "trick"
  * [Self Attention does not need O(n^2) memory](https://arxiv.org/abs/2112.05682):
  * [Flash Attention 2](https://arxiv.org/abs/2307.08691): The diagrams here do a better job of explaining flash attention 1 as well
  * [Llama 2 paper](https://arxiv.org/abs/2307.09288): Skim it for the model details
  * [gpt-fast](https://github.com/pytorch-labs/gpt-fast): A great repo to come back to for minimal yet performant code
  * [Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation](https://arxiv.org/abs/2108.12409): There's tons of papers on long context lengths but I found this to be among the clearest
  * Google the different kinds of attention: cosine, dot product, cross, local, sparse, convolutional


## Performance Optimizations
[](https://github.com/cuda-mode/awesomeMLSys#performance-optimizations)
  * [Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems](https://arxiv.org/abs/2312.15234): Wonderful survey, start here
  * [Efficiently Scaling transformer inference](https://arxiv.org/abs/2211.05102): Introduced many ideas most notably KV caches
  * [Making Deep Learning go Brrr from First Principles](https://horace.io/brrr_intro.html): One of the best intros to fusions and overhead
  * [Fast Inference from Transformers via Speculative Decoding](https://arxiv.org/abs/2211.17192): This is the paper that helped me grok the difference in performance characteristics between prefill and autoregressive decoding
  * [Group Query Attention](https://arxiv.org/pdf/2305.13245): KV caches can be chunky this is how you fix it
  * [Orca: A Distributed Serving System for Transformer-Based Generative Models](https://www.usenix.org/conference/osdi22/presentation/yu): introduced continuous batching (great pre-read for the PagedAttention paper).
  * [Efficient Memory Management for Large Language Model Serving with PagedAttention](https://arxiv.org/abs/2309.06180): the most crucial optimization for high throughput batch inference
  * [Colfax Research Blog](https://research.colfax-intl.com/blog/): Excellent blog if you're interested in learning more about CUTLASS and modern GPU programming
  * [Sarathi LLM](https://arxiv.org/abs/2308.16369): Introduces chunked prefill to make workloads more balanced between prefill and decode
  * [Epilogue Visitor Tree](https://dl.acm.org/doi/10.1145/3620666.3651369): Fuse custom epilogues by adding more epilogues to the same class (visitor design pattern) and represent the whole epilogue as a tree


## Quantization
[](https://github.com/cuda-mode/awesomeMLSys#quantization)
  * [A White Paper on Neural Network Quantization](https://arxiv.org/abs/2106.08295): Start here this is will give you the foundation to quickly skim all the other papers
  * [LLM.int8](https://arxiv.org/abs/2208.07339): All of Dettmers papers are great but this is a natural intro
  * [FP8 formats for deep learning](https://arxiv.org/abs/2209.05433): For a first hand look of how new number formats come about
  * [Smoothquant](https://arxiv.org/abs/2211.10438): Balancing rounding errors between weights and activations
  * [Mixed precision training](https://arxiv.org/abs/1710.03740): The OG paper describing mixed precision training strategies for half


## Long context length
[](https://github.com/cuda-mode/awesomeMLSys#long-context-length)
  * [RoFormer: Enhanced Transformer with Rotary Position Embedding](https://arxiv.org/abs/2104.09864): The paper that introduced rotary positional embeddings
  * [YaRN: Efficient Context Window Extension of Large Language Models](https://arxiv.org/abs/2309.00071): Extend base model context lengths with finetuning
  * [Ring Attention with Blockwise Transformers for Near-Infinite Context](https://arxiv.org/abs/2310.01889): Scale to infinite context lengths as long as you can stack more GPUs


## Sparsity
[](https://github.com/cuda-mode/awesomeMLSys#sparsity)
  * [Venom](https://arxiv.org/pdf/2310.02065): Vectorized N:M Format for sparse tensor cores when hardware only supports 2:4
  * [Megablocks](https://arxiv.org/pdf/2211.15841): Efficient Sparse training with mixture of experts
  * [ReLu Strikes Back](https://openreview.net/pdf?id=osoWxY8q2E): Really enjoyed this paper as an example of doing model surgery for more efficient inference


## Distributed
[](https://github.com/cuda-mode/awesomeMLSys#distributed)
  * [Singularity](https://arxiv.org/abs/2202.07848): Shows how to make jobs preemptible, migratable and elastic
  * [Local SGD](https://arxiv.org/abs/1805.09767): So hot right now
  * [OpenDiloco](https://arxiv.org/abs/2407.07852): Asynchronous training for decentralized training
  * [torchtitan](https://arxiv.org/abs/2410.06511): Minimal repository showing how to implement 4D parallelism in pure PyTorch
  * [pipedream](https://arxiv.org/abs/1806.03377): The pipeline parallel paper
  * [jit checkpointing](https://dl.acm.org/doi/pdf/10.1145/3627703.3650085): a very clever alternative to periodic checkpointing
  * [Reducing Activation Recomputation in Large Transformer models](https://arxiv.org/abs/2205.05198): THe paper thatt introduced selective activation checkpointing and goes over activation recomputation strategies
  * [Breaking the computation and communication abstraction barrier](https://arxiv.org/abs/2105.05720): God tier paper that goes over research at the intersection of distributed computing and compilers to maximize comms overlap
  * [ZeRO: Memory Optimizations Toward Training Trillion Parameter Models](https://arxiv.org/abs/1910.02054): The ZeRO algorithm behind FSDP and DeepSpeed intelligently reducing memory usage for data parallelism.
  * [Megatron-LM](https://arxiv.org/abs/1909.08053): For an introduction to Tensor Parallelism


## About
An ML Systems Onboarding list 
### Resources
[ Readme ](https://github.com/cuda-mode/awesomeMLSys#readme-ov-file)
[ Activity](https://github.com/gpu-mode/awesomeMLSys/activity)
[ Custom properties](https://github.com/gpu-mode/awesomeMLSys/custom-properties)
### Stars
[ **738** stars](https://github.com/gpu-mode/awesomeMLSys/stargazers)
### Watchers
[ **18** watching](https://github.com/gpu-mode/awesomeMLSys/watchers)
### Forks
[ **26** forks](https://github.com/gpu-mode/awesomeMLSys/forks)
[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fgpu-mode%2FawesomeMLSys&report=gpu-mode+%28user%29)
##  [Releases](https://github.com/gpu-mode/awesomeMLSys/releases)
No releases published
##  [Packages 0](https://github.com/orgs/gpu-mode/packages?repo_name=awesomeMLSys)
No packages published 
##  [Contributors 3](https://github.com/gpu-mode/awesomeMLSys/graphs/contributors)
  * [ ![@msaroufim](https://avatars.githubusercontent.com/u/3282513?s=64&v=4) ](https://github.com/msaroufim) [ **msaroufim** Mark Saroufim ](https://github.com/msaroufim)
  * [ ![@ByronHsu](https://avatars.githubusercontent.com/u/24364830?s=64&v=4) ](https://github.com/ByronHsu) [ **ByronHsu** Byron Hsu ](https://github.com/ByronHsu)
  * [ ![@gordicaleksa](https://avatars.githubusercontent.com/u/29271842?s=64&v=4) ](https://github.com/gordicaleksa) [ **gordicaleksa** Aleksa Gordić ](https://github.com/gordicaleksa)


## Footer
[ ](https://github.com "GitHub") © 2025 GitHub, Inc. 
### Footer navigation
  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
  * [Security](https://github.com/security)
  * [Status](https://www.githubstatus.com/)
  * [Docs](https://docs.github.com/)
  * [Contact](https://support.github.com?tags=dotcom-footer)
  * Manage cookies 
  * Do not share my personal information 


You can’t perform that action at this time. 
