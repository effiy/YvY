# 原始URL: https://github.com/janreges/siteone-crawler

# 抓取时间: 2025-03-30 21:17:58

[Skip to content](https://github.com/janreges/siteone-crawler#start-of-content)
## Navigation Menu
Toggle navigation
[ ](https://github.com/)
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fjanreges%2Fsiteone-crawler)
  * Product 
    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)
    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)
    * [ Actions Automate any workflow  ](https://github.com/features/actions)
    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)
    * [ Issues Plan and track work  ](https://github.com/features/issues)
    * [ Code Review Manage code changes  ](https://github.com/features/code-review)
    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)
    * [ Code Search Find more, search less  ](https://github.com/features/code-search)
Explore
    * [ All features ](https://github.com/features)
    * [ Documentation ](https://docs.github.com)
    * [ GitHub Skills ](https://skills.github.com)
    * [ Blog ](https://github.blog)
  * Solutions 
By company size
    * [ Enterprises ](https://github.com/enterprise)
    * [ Small and medium teams ](https://github.com/team)
    * [ Startups ](https://github.com/enterprise/startups)
    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)
By use case
    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)
    * [ DevOps ](https://github.com/solutions/use-case/devops)
    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)
    * [ View all use cases ](https://github.com/solutions/use-case)
By industry
    * [ Healthcare ](https://github.com/solutions/industry/healthcare)
    * [ Financial services ](https://github.com/solutions/industry/financial-services)
    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)
    * [ Government ](https://github.com/solutions/industry/government)
    * [ View all industries ](https://github.com/solutions/industry)
[ View all solutions ](https://github.com/solutions)
  * Resources 
Topics
    * [ AI ](https://github.com/resources/articles/ai)
    * [ DevOps ](https://github.com/resources/articles/devops)
    * [ Security ](https://github.com/resources/articles/security)
    * [ Software Development ](https://github.com/resources/articles/software-development)
    * [ View all ](https://github.com/resources/articles)
Explore
    * [ Learning Pathways ](https://resources.github.com/learn/pathways)
    * [ Events & Webinars ](https://resources.github.com)
    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)
    * [ Customer Stories ](https://github.com/customer-stories)
    * [ Partners ](https://partner.github.com)
    * [ Executive Insights ](https://github.com/solutions/executive-insights)
  * Open Source 
    * [ GitHub Sponsors Fund open source developers  ](https://github.com/sponsors)
    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)
Repositories
    * [ Topics ](https://github.com/topics)
    * [ Trending ](https://github.com/trending)
    * [ Collections ](https://github.com/collections)
  * Enterprise 
    * [ Enterprise platform AI-powered developer platform  ](https://github.com/enterprise)
Available add-ons
    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)
    * [ Copilot for business Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)
    * [ Premium Support Enterprise-grade 24/7 support  ](https://github.com/premium-support)
  * [Pricing](https://github.com/pricing)


Search or jump to...
# Search code, repositories, users, issues, pull requests...
Search 
Clear
[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)
#  Provide feedback 
We read every piece of feedback, and take your input very seriously.
Include my email address so I can be contacted
Cancel  Submit feedback 
#  Saved searches 
## Use saved searches to filter your results more quickly
Name
Query
To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). 
Cancel  Create saved search 
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fjanreges%2Fsiteone-crawler)
[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=janreges%2Fsiteone-crawler) Reseting focus
You signed in with another tab or window. [Reload](https://github.com/janreges/siteone-crawler) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/janreges/siteone-crawler) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/janreges/siteone-crawler) to refresh your session. Dismiss alert
{{ message }}
[ janreges ](https://github.com/janreges) / **[siteone-crawler](https://github.com/janreges/siteone-crawler) ** Public
  * [ Notifications ](https://github.com/login?return_to=%2Fjanreges%2Fsiteone-crawler) You must be signed in to change notification settings
  * [ Fork 34 ](https://github.com/login?return_to=%2Fjanreges%2Fsiteone-crawler)
  * [ Star  453 ](https://github.com/login?return_to=%2Fjanreges%2Fsiteone-crawler)


SiteOne Crawler is a cross-platform website crawler and analyzer for SEO, security, accessibility, and performance optimization—ideal for developers, DevOps, QA engineers, and consultants. Supports Windows, macOS, and Linux (x64 and arm64). 
[crawler.siteone.io/](https://crawler.siteone.io/ "https://crawler.siteone.io/")
### License
[ MIT license ](https://github.com/janreges/siteone-crawler/blob/main/LICENSE)
[ 453 stars ](https://github.com/janreges/siteone-crawler/stargazers) [ 34 forks ](https://github.com/janreges/siteone-crawler/forks) [ Branches ](https://github.com/janreges/siteone-crawler/branches) [ Tags ](https://github.com/janreges/siteone-crawler/tags) [ Activity ](https://github.com/janreges/siteone-crawler/activity)
[ Star  ](https://github.com/login?return_to=%2Fjanreges%2Fsiteone-crawler)
[ Notifications ](https://github.com/login?return_to=%2Fjanreges%2Fsiteone-crawler) You must be signed in to change notification settings
  * [ Code ](https://github.com/janreges/siteone-crawler)
  * [ Issues 22 ](https://github.com/janreges/siteone-crawler/issues)
  * [ Pull requests 0 ](https://github.com/janreges/siteone-crawler/pulls)
  * [ Discussions ](https://github.com/janreges/siteone-crawler/discussions)
  * [ Actions ](https://github.com/janreges/siteone-crawler/actions)
  * [ Projects 0 ](https://github.com/janreges/siteone-crawler/projects)
  * [ Security ](https://github.com/janreges/siteone-crawler/security)
  * [ Insights ](https://github.com/janreges/siteone-crawler/pulse)


Additional navigation options
  * [ Code  ](https://github.com/janreges/siteone-crawler)
  * [ Issues  ](https://github.com/janreges/siteone-crawler/issues)
  * [ Pull requests  ](https://github.com/janreges/siteone-crawler/pulls)
  * [ Discussions  ](https://github.com/janreges/siteone-crawler/discussions)
  * [ Actions  ](https://github.com/janreges/siteone-crawler/actions)
  * [ Projects  ](https://github.com/janreges/siteone-crawler/projects)
  * [ Security  ](https://github.com/janreges/siteone-crawler/security)
  * [ Insights  ](https://github.com/janreges/siteone-crawler/pulse)


# janreges/siteone-crawler
main
[Branches](https://github.com/janreges/siteone-crawler/branches)[Tags](https://github.com/janreges/siteone-crawler/tags)
[](https://github.com/janreges/siteone-crawler/branches)[](https://github.com/janreges/siteone-crawler/tags)
Go to file
Code
## Folders and files
Name| Name| Last commit message| Last commit date  
---|---|---|---  
## Latest commit
## History
[387 Commits](https://github.com/janreges/siteone-crawler/commits/main/)[](https://github.com/janreges/siteone-crawler/commits/main/)  
[bin](https://github.com/janreges/siteone-crawler/tree/main/bin "bin")| [bin](https://github.com/janreges/siteone-crawler/tree/main/bin "bin")  
[docs](https://github.com/janreges/siteone-crawler/tree/main/docs "docs")| [docs](https://github.com/janreges/siteone-crawler/tree/main/docs "docs")  
[log](https://github.com/janreges/siteone-crawler/tree/main/log "log")| [log](https://github.com/janreges/siteone-crawler/tree/main/log "log")  
[src](https://github.com/janreges/siteone-crawler/tree/main/src "src")| [src](https://github.com/janreges/siteone-crawler/tree/main/src "src")  
[tests](https://github.com/janreges/siteone-crawler/tree/main/tests "tests")| [tests](https://github.com/janreges/siteone-crawler/tree/main/tests "tests")  
[tmp](https://github.com/janreges/siteone-crawler/tree/main/tmp "tmp")| [tmp](https://github.com/janreges/siteone-crawler/tree/main/tmp "tmp")  
[.gitignore](https://github.com/janreges/siteone-crawler/blob/main/.gitignore ".gitignore")| [.gitignore](https://github.com/janreges/siteone-crawler/blob/main/.gitignore ".gitignore")  
[CHANGELOG.md](https://github.com/janreges/siteone-crawler/blob/main/CHANGELOG.md "CHANGELOG.md")| [CHANGELOG.md](https://github.com/janreges/siteone-crawler/blob/main/CHANGELOG.md "CHANGELOG.md")  
[LICENSE](https://github.com/janreges/siteone-crawler/blob/main/LICENSE "LICENSE")| [LICENSE](https://github.com/janreges/siteone-crawler/blob/main/LICENSE "LICENSE")  
[README.md](https://github.com/janreges/siteone-crawler/blob/main/README.md "README.md")| [README.md](https://github.com/janreges/siteone-crawler/blob/main/README.md "README.md")  
[composer.json](https://github.com/janreges/siteone-crawler/blob/main/composer.json "composer.json")| [composer.json](https://github.com/janreges/siteone-crawler/blob/main/composer.json "composer.json")  
[composer.lock](https://github.com/janreges/siteone-crawler/blob/main/composer.lock "composer.lock")| [composer.lock](https://github.com/janreges/siteone-crawler/blob/main/composer.lock "composer.lock")  
[crawler](https://github.com/janreges/siteone-crawler/blob/main/crawler "crawler")| [crawler](https://github.com/janreges/siteone-crawler/blob/main/crawler "crawler")  
[crawler.bat](https://github.com/janreges/siteone-crawler/blob/main/crawler.bat "crawler.bat")| [crawler.bat](https://github.com/janreges/siteone-crawler/blob/main/crawler.bat "crawler.bat")  
[package.json](https://github.com/janreges/siteone-crawler/blob/main/package.json "package.json")| [package.json](https://github.com/janreges/siteone-crawler/blob/main/package.json "package.json")  
[phpstan.neon](https://github.com/janreges/siteone-crawler/blob/main/phpstan.neon "phpstan.neon")| [phpstan.neon](https://github.com/janreges/siteone-crawler/blob/main/phpstan.neon "phpstan.neon")  
[phpunit.xml](https://github.com/janreges/siteone-crawler/blob/main/phpunit.xml "phpunit.xml")| [phpunit.xml](https://github.com/janreges/siteone-crawler/blob/main/phpunit.xml "phpunit.xml")  
View all files  
## Repository files navigation
  * [README](https://github.com/janreges/siteone-crawler)
  * [MIT license](https://github.com/janreges/siteone-crawler)


# SiteOne Crawler
[](https://github.com/janreges/siteone-crawler#siteone-crawler)
SiteOne Crawler is a very useful and easy-to-use **website analyzer & cloner/exporter/converter** you'll ♥ as a Dev/DevOps, SEO specialist, QA engineer, website owner or consultant. Works on all popular platforms - **Windows** , **macOS** and **Linux** (**x64** and **arm64** too).
The main capability of the crawler is to **generate a detailed HTML report** with lots of useful information about your website (see sample [nextjs.org report](https://crawler.siteone.io/html/2024-08-23/forever/cl8xw4r-fdag8wg-44dd.html)) and at the same time it can clone/export/convert the website offline (see browsable [nextjs.org clone](https://crawler.siteone.io/examples-exports/nextjs.org/)) or to **markdown** (see [examples](https://github.com/janreges/siteone-crawler-markdown-examples/)).
It will crawl your entire website in depth, analyze and report problems, show useful statistics and reports, generate an offline version of the website, generate sitemaps or send reports via email. Watch a detailed [video with a sample report](https://www.youtube.com/watch?v=PHIFSOmk0gk) for the [astro.build](https://astro.build/?utm_source=siteone-crawler-github) website.
This crawler can be used as a command-line tool (see [releases](https://github.com/janreges/siteone-crawler/releases) and [video](https://www.youtube.com/watch?v=25T_yx13naA&list=PL9mElgTe-s1Csfg0jXWmDS0MHFN7Cpjwp)), or you can use a [multi-platform desktop application](https://github.com/janreges/siteone-crawler-gui) with graphical interface (see [video](https://www.youtube.com/watch?v=rFW8LNEVNdw) about app).
I also recommend looking at the project website [crawler.siteone.io](https://crawler.siteone.io/) with detailed [documentation](https://crawler.siteone.io/configuration/command-line-options/).
GIF animation of the crawler in action (also available as a [video](https://www.youtube.com/watch?v=25T_yx13naA&list=PL9mElgTe-s1Csfg0jXWmDS0MHFN7Cpjwp)):
[![SiteOne Crawler](https://github.com/janreges/siteone-crawler/raw/main/docs/siteone-crawler-command-line.gif)](https://github.com/janreges/siteone-crawler/blob/main/docs/siteone-crawler-command-line.gif)
## Table of contents
[](https://github.com/janreges/siteone-crawler#table-of-contents)
  * [Features](https://github.com/janreges/siteone-crawler#features)
    * [Crawler](https://github.com/janreges/siteone-crawler#crawler)
    * [Dev/DevOps assistant](https://github.com/janreges/siteone-crawler#devdevops-assistant)
    * [Analyzer](https://github.com/janreges/siteone-crawler#analyzer)
    * [Reporter](https://github.com/janreges/siteone-crawler#reporter)
    * [Offline website generator](https://github.com/janreges/siteone-crawler#offline-website-generator)
    * [Sitemap generator](https://github.com/janreges/siteone-crawler#sitemap-generator)
    * [For active contributors](https://github.com/janreges/siteone-crawler#for-active-contributors)
  * [Installation](https://github.com/janreges/siteone-crawler#installation)
    * [Ready-to-use releases](https://github.com/janreges/siteone-crawler#ready-to-use-releases)
    * [Linux (x64)](https://github.com/janreges/siteone-crawler#linux-x64)
    * [Windows (x64)](https://github.com/janreges/siteone-crawler#windows-x64)
    * [macOS (arm64, x64)](https://github.com/janreges/siteone-crawler#macos-arm64-x64)
    * [Linux (arm64)](https://github.com/janreges/siteone-crawler#linux-arm64)
  * [Usage](https://github.com/janreges/siteone-crawler#usage)
    * [Basic example](https://github.com/janreges/siteone-crawler#basic-example)
    * [Fully-featured example](https://github.com/janreges/siteone-crawler#fully-featured-example)
    * [Arguments](https://github.com/janreges/siteone-crawler#arguments)
      * [Basic settings](https://github.com/janreges/siteone-crawler#basic-settings)
      * [Output settings](https://github.com/janreges/siteone-crawler#output-settings)
      * [Resource filtering](https://github.com/janreges/siteone-crawler#resource-filtering)
      * [Advanced crawler settings](https://github.com/janreges/siteone-crawler#advanced-crawler-settings)
      * [File export settings](https://github.com/janreges/siteone-crawler#file-export-settings)
      * [Mailer options](https://github.com/janreges/siteone-crawler#mailer-options)
      * [Upload options](https://github.com/janreges/siteone-crawler#upload-options)
      * [Offline exporter options](https://github.com/janreges/siteone-crawler#offline-exporter-options)
      * [Markdown exporter options](https://github.com/janreges/siteone-crawler#markdown-exporter-options)
      * [Sitemap options](https://github.com/janreges/siteone-crawler#sitemap-options)
      * [Expert options](https://github.com/janreges/siteone-crawler#expert-options)
  * [Roadmap](https://github.com/janreges/siteone-crawler#roadmap)
  * [Motivation to create this tool](https://github.com/janreges/siteone-crawler#motivation-to-create-this-tool)
  * [Disclaimer](https://github.com/janreges/siteone-crawler#disclaimer)
  * [License](https://github.com/janreges/siteone-crawler#license)
  * [Output examples](https://github.com/janreges/siteone-crawler#output-examples)
    * [Text output](https://github.com/janreges/siteone-crawler#text-output)
    * [JSON output](https://github.com/janreges/siteone-crawler#json-output)


## Features
[](https://github.com/janreges/siteone-crawler#features)
In short, the main benefits can be summarized in these points:
  * **Crawler** - very powerful crawler of the entire website reporting useful information about each URL (status code, response time, size, custom headers, titles, etc.)
  * **Dev/DevOps assistant** - offers a set of very useful and often necessary features for developers and devops (stress test, warm up cache, localhost testing, etc.)
  * **Analyzer** - analyzes all webpages and reports strange or error behaviour and useful statistics (404, redirects, bad practices, SEO and security issues, heading structures, etc.)
  * **Reporter** - sends a HTML report to your email addresses with all the information about the crawled website
  * **Offline website generator** - allows you to export the entire website to offline form, where it is possible to browse the site through local HTML files (without HTTP server) including all images, styles, scripts, fonts, etc.
  * **Website to markdown converter** - allows you to export/convert the entire website with all subpages to browsable markdown. Optionally with images and other files (PDF, etc.) included. Great for documentation and archiving purposes. See [markdown examples](https://github.com/janreges/siteone-crawler-markdown-examples/).
  * **Sitemap generator** - allows you to generate `sitemap.xml` and `sitemap.txt` files with a list of all pages on your website


The following features are summarized in greater detail:
### Crawler
[](https://github.com/janreges/siteone-crawler#crawler)
  * **all major platforms** supported without complicated installation or dependencies (Linux, Windows, macOS, arm64)
  * has incredible **C++ performance** (thanks to Swoole's coroutines)
  * provide simulation of **different device types** (desktop/mobile/tablet) thanks to predefined User-Agents
  * will crawl **all files** , styles, scripts, fonts, images, documents, etc. on your website
  * will respect the `robots.txt` file and will not crawl the pages that are not allowed
  * has a **beautiful interactive** and **colourful output**
  * it will **clearly warn you** of any wrong use of the tool (e.g. input parameters validation or wrong permissions)
  * **captures CTRL+C** and ends with the statistics for at least the current processed URLs
  * as `--url` parameter, you can specify also a `sitemap.xml` file (or [sitemap index](https://www.sitemaps.org/protocol.html#index)), which will be processed as a list of URLs. Note: gzip pre-compressed sitemaps `*.xml.gz` are not supported.


### Dev/DevOps assistant
[](https://github.com/janreges/siteone-crawler#devdevops-assistant)
  * allows testing **public** and **local projects on specific ports** (e.g. `http://localhost:3000/`)
  * will perform a **stress test** and allow you to test the protection of the infrastructure against DoS attacks
  * will help you **warm up the application cache** or the **cache on the reverse proxy** of the entire website


### Analyzer
[](https://github.com/janreges/siteone-crawler#analyzer)
  * will **find the weak points** or **strange behavior** of your website
  * allows you to implement **your own analyzers** by simply adding an analyzer class that implements the `Crawler\Analyzer` interface.


### Reporter
[](https://github.com/janreges/siteone-crawler#reporter)
  * will provide you with data for **SEO analysis** , just add the `Title`, `Keywords` and `Description`
  * will send you a **nice HTML report** to your email addresses
  * will **export** the output to JSON, HTML or text for **your integrations** will provide useful **summaries and statistics** at the end of the processing


### Offline website generator
[](https://github.com/janreges/siteone-crawler#offline-website-generator)
  * will help you **export the entire website** to offline form, where it is possible to browse the site through local HTML files (without HTTP server) including all document, images, styles, scripts, fonts, etc.
  * you can **limit what assets** you want to download and export (see `--disable-*` directives) .. for some types of websites the best result is with the `--disable-javascript` option.
  * you can specify by `--allowed-domain-for-external-files` (short `-adf`) from which **external domains** it is possible to **download ** assets (JS, CSS, fonts, images, documents) including `*` option for all domains.
  * you can specify by `--allowed-domain-for-crawling` (short `-adc`) which **other domains** should be included in the **crawling** if there are any links pointing to them. You can enable e.g. `mysite.*` to export all language mutations that have a different TLD or `*.mysite.tld` to export all subdomains.
  * you can try `---disable-styles` and `---disable-fonts` and see how well you handle **accessibility** and **semantics**
  * you can use `--single-page` to **export only one page** to which the URL is given (and its assets), but do not follow other pages.
  * you can use `--single-foreign-page` to **export only one page** from another domain (if allowed by `--allowed-domain-for-crawling`), but do not follow other pages.
  * you can use `--replace-content` to **replace content** in HTML/JS/CSS with `foo -> bar` or regexp in PREG format, e.g. `/card[0-9]/i -> card`. Can be specified multiple times.
  * you can use `--replace-query-string` to **replace chars in query string** in the filename.
  * you can use `--max-depth` to set the **maximum crawling depth** (for pages, not assets). `1` means `/about` or `/about/`, `2` means `/about/contacts` etc.
  * you can use it to **export your website to a static form** and host it on GitHub Pages, Netlify, Vercel, etc. as a static backup and part of your **disaster recovery plan** or **archival/legal needs**
  * works great with **older conventional websites** but also **modern ones** , built on frameworks like Next.js, Nuxt.js, SvelteKit, Astro, Gatsby, etc. When a JS framework is detected, the export also performs some framework-specific code modifications for optimal results. For example, most frameworks can't handle the relative location of a project and linking assets from root `/`, which doesn't work with `file://` mode.
  * **try it** for your website, and you will be very pleasantly surprised :-)
  * roadmap: we are also planning to release a version of the export compatible with **Nginx** that will preserve all original URLs for your website and allow you to host it on your own infrastructure.


### Website to markdown converter
[](https://github.com/janreges/siteone-crawler#website-to-markdown-converter)
  * will help you **export/convert the entire website** with all subpages to **browsable markdown**.
  * you can optionally disable export and hide images and other files (PDF, etc.) which are included by default.
  * you can set multiple selectors (CSS like) to **remove unwanted elements** from the exported markdown.
  * to prevent that at the beginning of the markdown of all pages the header, long menu etc. will be repeated, so the first occurrence of the most important heading (typically h1) is searched and all content before this heading is moved to the end of the page below the line `---`.
  * converter has implemented **code block detection** and **syntax highlighting** for the most popular languages
  * html tables are converted to **markdown tables**
  * see all available [markdown exporter options](https://github.com/janreges/siteone-crawler#markdown-exporter-options).


Tip: you can push the exported markdown folder to your GitHub repository, where it will be automatically rendered as a browsable documentation. You can look at the [examples](https://github.com/janreges/siteone-crawler-markdown-examples/) of converted websites to markdown.
### Sitemap generator
[](https://github.com/janreges/siteone-crawler#sitemap-generator)
  * will help you create a `sitemap.xml` and `sitemap.xml` for your website
  * you can set the priority of individual pages based on the number of slashes in the URL


Don't hesitate and try it. You will love it as we do! ♥
### For active contributors
[](https://github.com/janreges/siteone-crawler#for-active-contributors)
  * the crawler code provides some useful functionality that facilitates further **development** and **extensibility** of the project


## Installation
[](https://github.com/janreges/siteone-crawler#installation)
### Ready-to-use releases
[](https://github.com/janreges/siteone-crawler#ready-to-use-releases)
You can download ready-to-use releases from [GitHub releases](https://github.com/janreges/siteone-crawler/releases) for all major platforms (Linux, Windows, macOS, arm64).
Unpack the downloaded archive, and you will find the `crawler` or `crawler.bat` (Windows) executable binary and run crawler by `./crawler --url=https://my.domain.tld`.
**Note for Windows users** : use Cygwin-based release `*-win-x64.zip` only if you can't use WSL (Ubuntu/Debian), what is recommended. If you really have to use the Cygwin version, set `--workers=1` for higher stability.
**Note for macOS users** : In case that Mac refuses to start the crawler from your Download folder, move the entire folder with the Crawler **via the terminal** to another location, for example to the homefolder `~`.
### Linux (x64)
[](https://github.com/janreges/siteone-crawler#linux-x64)
Most easily installation is on most Linux (x64) distributions.
```
git clone https://github.com/janreges/siteone-crawler.git
cd siteone-crawler
# run crawler with basic options
./crawler --url=https://my.domain.tld
```

### Windows (x64)
[](https://github.com/janreges/siteone-crawler#windows-x64)
If using Windows, the best choice is to use [Ubuntu](https://ubuntu.com/wsl) or [Debian](https://www.linuxfordevices.com/tutorials/linux/install-debian-on-windows-wsl) in [WSL](https://learn.microsoft.com/en-us/windows/wsl/install).
Otherwise, you can download [swoole-cli-v4.8.13-cygwin-x64.zip](https://github.com/swoole/swoole-src/releases/download/v4.8.13/swoole-cli-v4.8.13-cygwin-x64.zip) from [Swoole releases](https://github.com/swoole/swoole-src/releases) and use precompiled Cygwin-based `bin/swoole-cli.exe`.
A really functional and tested Windows command looks like this (modify path to your `swoole-cli.exe` and `src\crawler.php`):
```
c:\Tools\swoole-cli-v4.8.13-cygwin-x64\bin\swoole-cli.exe C:\Tools\siteone-crawler\src\crawler.php --url=https://www.siteone.io/
```

**NOTICE** : Cygwin does not support STDERR with rewritable lines in the console. Therefore, the output is not as beautiful as on Linux or macOS.
### macOS (arm64, x64)
[](https://github.com/janreges/siteone-crawler#macos-arm64-x64)
If using macOS with latest arm64 M1/M2 CPU, download arm64 version [swoole-cli-v4.8.13-macos-arm64.tar.xz](https://github.com/swoole/swoole-src/releases/download/v4.8.13/swoole-cli-v4.8.13-macos-arm64.tar.xz), unpack and use its precompiled `swoole-cli`.
If using macOS with Intel CPU (x64), download x64 version [swoole-cli-v4.8.13-macos-x64.tar.xz](https://github.com/swoole/swoole-src/releases/download/v4.8.13/swoole-cli-v4.8.13-macos-x64.tar.xz), unpack and use its precompiled `swoole-cli`.
### Linux (arm64)
[](https://github.com/janreges/siteone-crawler#linux-arm64)
If using arm64 Linux, you can download [swoole-cli-v4.8.13-linux-arm64.tar.xz](https://github.com/swoole/swoole-src/releases/download/v4.8.13/swoole-cli-v4.8.13-linux-arm64.tar.xz) and use its precompiled `swoole-cli`.
## Usage
[](https://github.com/janreges/siteone-crawler#usage)
To run the crawler, execute the `crawler` executable file from the command line and provide the required arguments:
### Basic example
[](https://github.com/janreges/siteone-crawler#basic-example)
```
./crawler --url=https://mydomain.tld/ --device=mobile
```

### Fully-featured example
[](https://github.com/janreges/siteone-crawler#fully-featured-example)
```
./crawler --url=https://mydomain.tld/ \
 --output=text \
 --workers=2 \
 --max-reqs-per-sec=10 \
 --memory-limit=1024M \
 --resolve='mydomain.tld:443:127.0.0.1' \
 --timeout=5 \
 --proxy=proxy.mydomain.tld:8080 \
 --http-auth=myuser:secretPassword123 \
 --user-agent="My User-Agent String" \
 --extra-columns="DOM,X-Cache(10),Title(40),Keywords(50),Description(50>),Heading1=xpath://h1/text()(20>),ProductPrice=regexp:/Price:\s*\$?(\d+(?:\.\d{2})?)/i#1(10)" \
 --accept-encoding="gzip, deflate" \
 --url-column-size=100 \
 --max-queue-length=3000 \
 --max-visited-urls=10000 \
 --max-url-length=5000 \
 --max-non200-responses-per-basename=10 \
 --include-regex="/^.*\/technologies.*/" \
 --include-regex="/^.*\/fashion.*/" \
 --ignore-regex="/^.*\/downloads\/.*\.pdf$/i" \
 --analyzer-filter-regex="/^.*$/i" \
 --remove-query-params \
 --add-random-query-params \
 --show-scheme-and-host \
 --do-not-truncate-url \
 --output-html-report=tmp/myreport.html \
 --output-json-file=/dir/report.json \
 --output-text-file=/dir/report.txt \
 --add-timestamp-to-output-file \
 --add-host-to-output-file \
 --offline-export-dir=tmp/mydomain.tld \
 --replace-content='/<foo[^>]+>/ -> <bar>' \
 --ignore-store-file-error \
 --sitemap-xml-file==/dir/sitemap.xml \
 --sitemap-txt-file==/dir/sitemap.txt \
 --sitemap-base-priority=0.5 \
 --sitemap-priority-increase=0.1 \
 --markdown-export-dir=tmp/mydomain.tld.md \
 --markdown-move-content-before-h1-to-end \
 --markdown-disable-images \
 --markdown-disable-files \
 --markdown-exclude-selector='.exclude-me' \
 --markdown-replace-content='/<foo[^>]+>/ -> <bar>' \
 --mail-to=your.name@my-mail.tld \
 --mail-to=your.friend.name@my-mail.tld \
 --mail-from=crawler@ymy-mail.tld \
 --mail-from-name="SiteOne Crawler" \
 --mail-subject-template="Crawler Report for %domain% (%date%)" \
 --mail-smtp-host=smtp.my-mail.tld \
 --mail-smtp-port=25 \
 --mail-smtp-user=smtp.user \
 --mail-smtp-pass=secretPassword123
```

## Arguments
[](https://github.com/janreges/siteone-crawler#arguments)
For a clearer list, I recommend going to the documentation: <https://crawler.siteone.io/configuration/command-line-options/>
### Basic settings
[](https://github.com/janreges/siteone-crawler#basic-settings)
Parameter | Description  
---|---  
`--url=<url>` | Required. HTTP or HTTPS URL address of the website or sitemap xml to be crawled.Use quotation marks `''` if the URL contains query parameters.  
`--single-page` | Load only one page to which the URL is given (and its assets), but do not follow other pages.  
`--max-depth=<int>` | Maximum crawling depth (for pages, not assets). Default is `0` (no limit). `1` means `/about`or `/about/`, `2` means `/about/contacts` etc.  
`--device=<val>` | Device type for choosing a predefined User-Agent. Ignored when `--user-agent` is defined.Supported values: `desktop`, `mobile`, `tablet`. Defaults is `desktop`.  
`--user-agent=<val>` | Custom User-Agent header. Use quotation marks. If specified, it takes precedence overthe device parameter. If you add `!` at the end, the siteone-crawler/version will not beadded as a signature at the end of the final user-agent.  
`--timeout=<int>` | Request timeout in seconds. Default is `3`.  
`--proxy=<host:port>` | HTTP proxy to use in `host:port` format. Host can be hostname, IPv4 or IPv6.  
`--http-auth=<user:pass>` | Basic HTTP authentication in `username:password` format.  
### Output settings
[](https://github.com/janreges/siteone-crawler#output-settings)
Parameter | Description  
---|---  
`--output=<val>` | Output type. Supported values: `text`, `json`. Default is `text`.  
`--extra-columns=<values>` | Comma delimited list of extra columns added to output table. You can specify HTTP headers(e.g. `X-Cache`), predefined values (`Title`, `Keywords`, `Description`, `DOM`), or customextraction from text files (HTML, JS, CSS, TXT, JSON, XML, etc.) using XPath or regexp.For custom extraction, use the format `Custom_column_name=method:pattern#group(length)`, where`method` is `xpath` or `regexp`, `pattern` is the extraction pattern, an optional `#group` specifies thecapturing group (or node index for XPath) to return (defaulting to the entire match or first node), and anoptional `(length)` sets the maximum output length (append `>` to disable truncation).For example, use `Heading1=xpath://h1/text()(20>)` to extract the text of the first H1 elementfrom the HTML document, and `ProductPrice=regexp:/Price:\s*\$?(\d+(?:\.\d{2})?)/i#1(10)`to extract a numeric price (e.g., "29.99") from a string like "Price: $29.99".  
`--url-column-size=<num>` | Basic URL column width. By default, it is calculated from the size of your terminal window.  
`--rows-limit=<num>` | Max. number of rows to display in tables with analysis results (protection against very long and slow report).Default is `200`.  
`--timezone=<val>` | Timezone for datetimes in HTML reports and timestamps in output folders/files, e.g. `Europe/Prague`.Default is `UTC`. Available values can be found at [Timezones Documentation](https://www.php.net/manual/en/timezones.php).  
`--do-not-truncate-url` | In the text output, long URLs are truncated by default to `--url-column-size` so the table does notwrap due to long URLs. With this option, you can turn off the truncation.  
`--show-scheme-and-host` | On text output, show scheme and host also for origin domain URLs.  
`--hide-progress-bar` | Hide progress bar visible in text and JSON output for more compact view.  
`--no-color` | Disable colored output.  
`--force-color` | Force colored output regardless of support detection.  
`--show-inline-criticals` | Show criticals from the analyzer directly in the URL table.  
`--show-inline-warnings` | Show warnings from the analyzer directly in the URL table.  
### Resource filtering
[](https://github.com/janreges/siteone-crawler#resource-filtering)
Parameter | Description  
---|---  
`--disable-all-assets` | Disables crawling of all assets and files and only crawls pages in href attributes.Shortcut for calling all other `--disable-*` flags.  
`--disable-javascript` | Disables JavaScript downloading and removes all JavaScript code from HTML,including `onclick` and other `on*` handlers.  
`--disable-styles` | Disables CSS file downloading and at the same time removes all style definitionsby `<style>` tag or inline by style attributes.  
`--disable-fonts` | Disables font downloading and also removes all font/font-face definitions from CSS.  
`--disable-images` | Disables downloading of all images and replaces found images in HTML with placeholder image only.  
`--disable-files` | Disables downloading of any files (typically downloadable documents) to which various links point.  
`--remove-all-anchor-listeners` | On all links on the page remove any event listeners. Useful on some types of sites with modernJS frameworks that would like to compose content dynamically (React, Svelte, Vue, Angular, etc.).  
### Advanced crawler settings
[](https://github.com/janreges/siteone-crawler#advanced-crawler-settings)
Parameter | Description  
---|---  
`--workers=<int>` | Maximum number of concurrent workers (threads).Crawler will not make more simultaneous requests to the server than this number.Use carefully! A high number of workers can cause a DoS attack. Default is `3`.  
`--max-reqs-per-sec=<val>` | Max requests/s for whole crawler. Be careful not to cause a DoS attack. Default value is `10`.  
`--memory-limit=<size>` | Memory limit in units `M` (Megabytes) or `G` (Gigabytes). Default is `2048M`.  
`--resolve=<host:port:ip>` | Custom DNS resolution in `domain:port:ip` format. Same as [curl --resolve](https://everything.curl.dev/usingcurl/connections/name.html?highlight=resolve#provide-a-custom-ip-address-for-a-name).Can be specified multiple times for multiple domain:port pairs.Example: `--resolve='mydomain.tld:443:127.0.0.1`  
`--allowed-domain-for-external-files=<domain>` | Primarily, the crawler crawls only the URL within the domain for initial URL. This allowsyou to enable loading of file content from another domain as well (e.g. if you want toload assets from a CDN). Can be specified multiple times. Use can use domains with wildcard `*`.  
`--allowed-domain-for-crawling=<domain>` | This option will allow you to crawl all content from other listed domains - typically in the caseof language mutations on other domains. Can be specified multiple times.Use can use domains with wildcard `*` including e.g. `*.siteone.*`.  
`--single-foreign-page` | If crawling of other domains is allowed (using `--allowed-domain-for-crawling`),it ensures that when another domain is not on same second-level domain, only that linked pageand its assets are crawled from that foreign domain.  
`--include-regex=<regex>` | Regular expression compatible with PHP preg_match() for URLs that should be included.Argument can be specified multiple times. Example: `--include-regex='/^\/public\//'`  
`--ignore-regex=<regex>` | Regular expression compatible with PHP preg_match() for URLs that should be ignored.Argument can be specified multiple times.Example: `--ignore-regex='/^.*\/downloads\/.*\.pdf$/i'`  
`--regex-filtering-only-for-pages` | Set if you want filtering by `*-regex` rules apply only to page URLs, but static assets (JS, CSS, images,fonts, documents) have to be loaded regardless of filtering.Useful where you want to filter only /sub-pages/ by `--include-regex='/\/sub-pages\//'`, butassets have to be loaded from any URLs.  
`--analyzer-filter-regex` | Regular expression compatible with PHP preg_match() applied to Analyzer class names for analyzers filtering.Example: `/(content|accessibility)/i` or `/^(?:(?!best|access).)*$/i` for allanalyzers except `BestPracticesAnalyzer` and `AccessibilityAnalyzer`.  
`--accept-encoding=<val>` | Custom `Accept-Encoding` request header. Default is `gzip, deflate, br`.  
`--remove-query-params` | Remove query parameters from found URLs. Useful on websites where a lot of linksare made to the same pages, only with different irrelevant query parameters.  
`--add-random-query-params` | Adds several random query parameters to each URL.With this, it is possible to bypass certain forms of server and CDN caches.  
`--ignore-robots-txt` | Should robots.txt content be ignored? Useful for crawling an otherwise internal/private/unindexed site.  
`--http-cache-dir=<dir>` | Cache dir for HTTP responses. You can disable cache by `--http-cache-dir='off'`.Default values is `tmp/http-client-cache`.  
`--http-cache-compression` | Enable compression for HTTP cache storage. Saves disk space, but uses more CPU.  
`--max-queue-length=<num>` | The maximum length of the waiting URL queue. Increase in case of large websites,but expect higher memory requirements. Default is `9000`.  
`--max-visited-urls=<num>` | The maximum number of the visited URLs. Increase in case of large websites, but expecthigher memory requirements. Default is `10000`.  
`--max-skipped-urls=<num>` | The maximum number of the skipped URLs. Increase in case of large websites, but expecthigher memory requirements. Default is `10000`.  
`--max-url-length=<num>` | The maximum supported URL length in chars. Increase in case of very long URLs, but expecthigher memory requirements. Default is `2083`.  
`--max-non200-responses-per-basename=<num>` | Protection against looping with dynamic non-200 URLs. If a basename (the last part of the URLafter the last slash) has more non-200 responses than this limit, other URLs with same basenamewill be ignored/skipped. Default is `5`.  
### File export settings
[](https://github.com/janreges/siteone-crawler#file-export-settings)
Parameter | Description  
---|---  
`--output-html-report=<file>` | Save HTML report into that file. Set to empty '' to disable HTML report.By default saved into `tmp/%domain%.report.%datetime%.html`.  
`--output-json-file=<file>` | File path for JSON output. Set to empty '' to disable JSON file.By default saved into `tmp/%domain%.output.%datetime%.json`.  
`--output-text-file=<file>` | File path for TXT output. Set to empty '' to disable TXT file.By default saved into `tmp/%domain%.output.%datetime%.txt`.  
### Mailer options
[](https://github.com/janreges/siteone-crawler#mailer-options)
Parameter | Description  
---|---  
`--mail-to=<email>` | Recipients of HTML e-mail reports. Optional but required for mailer activation.You can specify multiple emails separated by comma.  
`--mail-from=<email>` | E-mail sender address. Default values is `siteone-crawler@your-hostname.com`.  
`--mail-from-name=<val>` | E-mail sender name. Default values is `SiteOne Crawler`.  
`--mail-subject-template=<val>` | E-mail subject template. You can use dynamic variables `%domain%`, `%date%` and `%datetime%`.Default values is `Crawler Report for %domain% (%date%)`.  
`--mail-smtp-host=<host>` | SMTP host for sending emails. Default is `localhost`.  
`--mail-smtp-port=<port>` | SMTP port for sending emails. Default is `25`.  
`--mail-smtp-user=<user>` | SMTP user, if your SMTP server requires authentication.  
`--mail-smtp-pass=<pass>` | SMTP password, if your SMTP server requires authentication.  
### Upload options
[](https://github.com/janreges/siteone-crawler#upload-options)
Parameter | Description  
---|---  
`--upload` | Enable HTML report upload to `--upload-to`.  
`--upload-to=<url>` | URL of the endpoint where to send the HTML report. Default value is `https://crawler.siteone.io/up`.  
`--upload-retention=<val>` | How long should the HTML report be kept in the online version?Values: 1h / 4h / 12h / 24h / 3d / 7d / 30d / 365d / forever.Default value is `30d`.  
`--upload-password=<val>` | Optional password, which must be entered (the user will be 'crawler')to display the online HTML report.  
`--upload-timeout=<int>` | Upload timeout in seconds. Default value is `3600`.  
### Offline exporter options
[](https://github.com/janreges/siteone-crawler#offline-exporter-options)
Parameter | Description  
---|---  
`--offline-export-dir=<dir>` | Path to directory where to save the offline version of the website. If target directorydoes not exist, crawler will try to create it (requires sufficient rights).  
`--offline-export-store-only-url-regex=<regex>` | For debug - when filled it will activate debug mode and store only URLswhich match one of these PCRE regexes. Can be specified multiple times.  
`--offline-export-remove-unwanted-code=<1/0>` | Remove unwanted code for offline mode? Typically, JS of the analytics, social networks,cookie consent, cross origins, etc. Default values is `1`.  
`--offline-export-no-auto-redirect-html` | Disables the automatic creation of redirect HTML files for each subfolder that containsan `index.html`. This solves situations for URLs where sometimes the URL ends with a slash,sometimes it doesn't.  
`--replace-content=<val>` | Replace content in HTML/JS/CSS with `foo -> bar` or regexp in PREG format,e.g. `/card[0-9]/i -> card`. Can be specified multiple times.  
`--replace-query-string=<val>` | Instead of using a short hash instead of a query string in the filename, just replace some characters.You can use simple format `foo -> bar` or regexp in PREG format, e.g. `'/([a-z]+)=([^&]*)(&  
`--ignore-store-file-error` | Enable this option to ignore any file storing errors.The export process will continue.  
### Markdown exporter options
[](https://github.com/janreges/siteone-crawler#markdown-exporter-options)
Parameter | Description  
---|---  
`--markdown-export-dir=<dir>` | Path to directory where to save the markdown version of the website.Directory will be created if it doesn't exist.  
`--markdown-move-content-before-h1-to-end` | Move all content before the main H1 heading (typically the header with the menu) to the end of the markdown.  
`--markdown-disable-images` | Do not export and show images in markdown files.Images are enabled by default.  
`--markdown-disable-files` | Do not export and link files other than HTML/CSS/JS/fonts/images - eg. PDF, ZIP, etc.These files are enabled by default.  
`--markdown-exclude-selector=<val>` | Exclude some page content (DOM elements) from markdown export defined by CSS selectors like 'header', '.header', '#header', etc.Can be specified multiple times.  
`--markdown-replace-content=<val>` | Replace text content with `foo -> bar` or regexp in PREG format: `/card[0-9]/i -> card`.Can be specified multiple times.  
`--markdown-replace-query-string=<val>` | Instead of using a short hash instead of a query string in the filename, just replace some characters.You can use simple format 'foo -> bar' or regexp in PREG format, e.g.`'/([a-z]+)=([^&]*)(&  
`--markdown-export-store-only-url-regex=<regex>` | For debug - when filled it will activate debug mode and store only URLs which match one of thesePCRE regexes.Can be specified multiple times.  
`--markdown-ignore-store-file-error` | Ignores any file storing errors. The export process will continue.  
### Sitemap options
[](https://github.com/janreges/siteone-crawler#sitemap-options)
Parameter | Description  
---|---  
`--sitemap-xml-file=<file>` | File path where generated XML Sitemap will be saved.Extension `.xml` is automatically added if not specified.  
`--sitemap-txt-file=<file>` | File path where generated TXT Sitemap will be saved.Extension `.txt` is automatically added if not specified.  
`--sitemap-base-priority=<num>` | Base priority for XML sitemap. Default values is `0.5`.  
`--sitemap-priority-increase=<num>` | Priority increase value based on slashes count in the URL. Default values is `0.1`.  
### Expert options
[](https://github.com/janreges/siteone-crawler#expert-options)
Parameter | Description  
---|---  
`--debug` | Activate debug mode.  
`--debug-log-file=<file>` | Log file where to save debug messages. When `--debug` is not set and `--debug-log-file` is set, logging will be active without visible output.  
`--debug-url-regex=<regex>` | Regex for URL(s) to debug. When crawled URL is matched, parsing, URL replacing,and other actions are printed to output. Can be specified multiple times.  
`--result-storage=<val>` | Result storage type for content and headers. Values: `memory` or `file`.Use `file` for large websites. Default values is `memory`.  
`--result-storage-dir=<dir>` | Directory for `--result-storage=file`. Default values is `tmp/result-storage`.  
`--result-storage-compression` | Enable compression for results storage. Saves disk space, but uses more CPU.  
`--http-cache-dir=<dir>` | Cache dir for HTTP responses. You can disable cache by `--http-cache-dir='off'`.Default values is `tmp/http-client-cache`.  
`--http-cache-compression` | Enable compression for HTTP cache storage.Saves disk space, but uses more CPU.  
`--websocket-server=<host:port>` | Start crawler with websocket server on given host:port, e.g. `0.0.0.0:8000`.To connected clients will be sent this message after each URL is crawled:`{"type":"urlResult","url":"...","statusCode":200,"size":4528,"execTime":0.823}`.  
`--console-width=<int>` | Enforce a fixed console width, disabling automatic detection.  
### Fastest URL analyzer
[](https://github.com/janreges/siteone-crawler#fastest-url-analyzer)
Parameter | Description  
---|---  
`--fastest-urls-top-limit=<int>` | Number of URLs in TOP fastest list. Default is `20`.  
`--fastest-urls-max-time=<val>` | Maximum response time for an URL to be considered fast. Default is `1`.  
### SEO and OpenGraph analyzer
[](https://github.com/janreges/siteone-crawler#seo-and-opengraph-analyzer)
Parameter | Description  
---|---  
`--max-heading-level=<int>` | Max heading level from 1 to 6 for analysis. Default is `3`.  
### Slowest URL analyzer
[](https://github.com/janreges/siteone-crawler#slowest-url-analyzer)
Parameter | Description  
---|---  
`--slowest-urls-top-limit=<int>` | Number of URLs in TOP slowest list. Default is `20`.  
`--slowest-urls-min-time=<val>` | Minimum response time threshold for slow URLs. Default is `0.01`.  
`--slowest-urls-max-time=<val>` | Maximum response time for an URL to be considered very slow.Default is `3`.  
## Roadmap
[](https://github.com/janreges/siteone-crawler#roadmap)
  * Well tested Docker images for easy usage in CI/CD pipelines on hub.docker.com (for all platforms).
  * Better static assets processing - now are assets processed immediately, same as other URLs. This can cause problems with large websites. We will implement a better solution with a separate queue for static assets and separate visualization in the output.
  * Support for configurable thresholds for response times, status codes, etc. to exit with a non-zero code.
  * Support for secure SMTP.


If you have any suggestions or feature requests, please open an issue on GitHub. We'd love to hear from you!
Your contributions with realized improvements, bug fixes, and new features are welcome. Please open a pull request :-)
## Motivation to create this tool
[](https://github.com/janreges/siteone-crawler#motivation-to-create-this-tool)
If you are interested in the author's motivation for creating this tool, read it on [the project website](https://crawler.siteone.io/introduction/motivation/).
## Disclaimer
[](https://github.com/janreges/siteone-crawler#disclaimer)
Please use responsibly and ensure that you have the necessary permissions when crawling websites. Some sites may have rules against automated access detailed in their robots.txt.
**The author is not responsible for any consequences caused by inappropriate use or deliberate misuse of this tool.**
## License
[](https://github.com/janreges/siteone-crawler#license)
This work is licensed under a [![License: MIT](https://camo.githubusercontent.com/6cd0120cc4c5ac11d28b2c60f76033b52db98dac641de3b2644bb054b449d60c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667)](https://opensource.org/licenses/MIT)
## About
SiteOne Crawler is a cross-platform website crawler and analyzer for SEO, security, accessibility, and performance optimization—ideal for developers, DevOps, QA engineers, and consultants. Supports Windows, macOS, and Linux (x64 and arm64). 
[crawler.siteone.io/](https://crawler.siteone.io/ "https://crawler.siteone.io/")
### Topics
[ testing ](https://github.com/topics/testing "Topic: testing") [ security ](https://github.com/topics/security "Topic: security") [ website ](https://github.com/topics/website "Topic: website") [ qa ](https://github.com/topics/qa "Topic: qa") [ crawler ](https://github.com/topics/crawler "Topic: crawler") [ performance ](https://github.com/topics/performance "Topic: performance") [ seo ](https://github.com/topics/seo "Topic: seo") [ crawling ](https://github.com/topics/crawling "Topic: crawling") [ analyzer ](https://github.com/topics/analyzer "Topic: analyzer") [ stress-testing ](https://github.com/topics/stress-testing "Topic: stress-testing") [ swoole ](https://github.com/topics/swoole "Topic: swoole") [ seotools ](https://github.com/topics/seotools "Topic: seotools") [ quality-assessment ](https://github.com/topics/quality-assessment "Topic: quality-assessment")
### Resources
[ Readme ](https://github.com/janreges/siteone-crawler#readme-ov-file)
### License
[ MIT license ](https://github.com/janreges/siteone-crawler#MIT-1-ov-file)
[ Activity](https://github.com/janreges/siteone-crawler/activity)
### Stars
[ **453** stars](https://github.com/janreges/siteone-crawler/stargazers)
### Watchers
[ **4** watching](https://github.com/janreges/siteone-crawler/watchers)
### Forks
[ **34** forks](https://github.com/janreges/siteone-crawler/forks)
[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fjanreges%2Fsiteone-crawler&report=janreges+%28user%29)
##  [Releases 6](https://github.com/janreges/siteone-crawler/releases)
[ v1.0.8 Latest  Aug 24, 2024 ](https://github.com/janreges/siteone-crawler/releases/tag/v1.0.8)
[+ 5 releases](https://github.com/janreges/siteone-crawler/releases)
##  [Packages 0](https://github.com/users/janreges/packages?repo_name=siteone-crawler)
No packages published 
##  [Contributors 3](https://github.com/janreges/siteone-crawler/graphs/contributors)
## Languages
  * [ PHP 96.5% ](https://github.com/janreges/siteone-crawler/search?l=php)
  * [ HTML 3.5% ](https://github.com/janreges/siteone-crawler/search?l=html)


## Footer
[ ](https://github.com "GitHub") © 2025 GitHub, Inc. 
### Footer navigation
  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
  * [Security](https://github.com/security)
  * [Status](https://www.githubstatus.com/)
  * [Docs](https://docs.github.com/)
  * [Contact](https://support.github.com?tags=dotcom-footer)
  * Manage cookies 
  * Do not share my personal information 


You can’t perform that action at this time. 
