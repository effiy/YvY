# 原始URL: https://github.com/Kedreamix/Linly-Dubbing

# 抓取时间: 2025-03-30 21:14:36

[Skip to content](https://github.com/Kedreamix/Linly-Dubbing#start-of-content)
## Navigation Menu
Toggle navigation
[ ](https://github.com/)
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FKedreamix%2FLinly-Dubbing)
  * Product 
    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)
    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)
    * [ Actions Automate any workflow  ](https://github.com/features/actions)
    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)
    * [ Issues Plan and track work  ](https://github.com/features/issues)
    * [ Code Review Manage code changes  ](https://github.com/features/code-review)
    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)
    * [ Code Search Find more, search less  ](https://github.com/features/code-search)
Explore
    * [ All features ](https://github.com/features)
    * [ Documentation ](https://docs.github.com)
    * [ GitHub Skills ](https://skills.github.com)
    * [ Blog ](https://github.blog)
  * Solutions 
By company size
    * [ Enterprises ](https://github.com/enterprise)
    * [ Small and medium teams ](https://github.com/team)
    * [ Startups ](https://github.com/enterprise/startups)
    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)
By use case
    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)
    * [ DevOps ](https://github.com/solutions/use-case/devops)
    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)
    * [ View all use cases ](https://github.com/solutions/use-case)
By industry
    * [ Healthcare ](https://github.com/solutions/industry/healthcare)
    * [ Financial services ](https://github.com/solutions/industry/financial-services)
    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)
    * [ Government ](https://github.com/solutions/industry/government)
    * [ View all industries ](https://github.com/solutions/industry)
[ View all solutions ](https://github.com/solutions)
  * Resources 
Topics
    * [ AI ](https://github.com/resources/articles/ai)
    * [ DevOps ](https://github.com/resources/articles/devops)
    * [ Security ](https://github.com/resources/articles/security)
    * [ Software Development ](https://github.com/resources/articles/software-development)
    * [ View all ](https://github.com/resources/articles)
Explore
    * [ Learning Pathways ](https://resources.github.com/learn/pathways)
    * [ Events & Webinars ](https://resources.github.com)
    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)
    * [ Customer Stories ](https://github.com/customer-stories)
    * [ Partners ](https://partner.github.com)
    * [ Executive Insights ](https://github.com/solutions/executive-insights)
  * Open Source 
    * [ GitHub Sponsors Fund open source developers  ](https://github.com/sponsors)
    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)
Repositories
    * [ Topics ](https://github.com/topics)
    * [ Trending ](https://github.com/trending)
    * [ Collections ](https://github.com/collections)
  * Enterprise 
    * [ Enterprise platform AI-powered developer platform  ](https://github.com/enterprise)
Available add-ons
    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)
    * [ Copilot for business Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)
    * [ Premium Support Enterprise-grade 24/7 support  ](https://github.com/premium-support)
  * [Pricing](https://github.com/pricing)


Search or jump to...
# Search code, repositories, users, issues, pull requests...
Search 
Clear
[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)
#  Provide feedback 
We read every piece of feedback, and take your input very seriously.
Include my email address so I can be contacted
Cancel  Submit feedback 
#  Saved searches 
## Use saved searches to filter your results more quickly
Name
Query
To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). 
Cancel  Create saved search 
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FKedreamix%2FLinly-Dubbing)
[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=Kedreamix%2FLinly-Dubbing) Reseting focus
You signed in with another tab or window. [Reload](https://github.com/Kedreamix/Linly-Dubbing) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/Kedreamix/Linly-Dubbing) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/Kedreamix/Linly-Dubbing) to refresh your session. Dismiss alert
{{ message }}
[ Kedreamix ](https://github.com/Kedreamix) / **[Linly-Dubbing](https://github.com/Kedreamix/Linly-Dubbing) ** Public
  * [ Notifications ](https://github.com/login?return_to=%2FKedreamix%2FLinly-Dubbing) You must be signed in to change notification settings
  * [ Fork 227 ](https://github.com/login?return_to=%2FKedreamix%2FLinly-Dubbing)
  * [ Star  2.3k ](https://github.com/login?return_to=%2FKedreamix%2FLinly-Dubbing)


智能视频多语言AI配音/翻译工具 - Linly-Dubbing — “AI赋能，语言无界” 
### License
[ Apache-2.0 license ](https://github.com/Kedreamix/Linly-Dubbing/blob/main/LICENSE)
[ 2.3k stars ](https://github.com/Kedreamix/Linly-Dubbing/stargazers) [ 227 forks ](https://github.com/Kedreamix/Linly-Dubbing/forks) [ Branches ](https://github.com/Kedreamix/Linly-Dubbing/branches) [ Tags ](https://github.com/Kedreamix/Linly-Dubbing/tags) [ Activity ](https://github.com/Kedreamix/Linly-Dubbing/activity)
[ Star  ](https://github.com/login?return_to=%2FKedreamix%2FLinly-Dubbing)
[ Notifications ](https://github.com/login?return_to=%2FKedreamix%2FLinly-Dubbing) You must be signed in to change notification settings
  * [ Code ](https://github.com/Kedreamix/Linly-Dubbing)
  * [ Issues 27 ](https://github.com/Kedreamix/Linly-Dubbing/issues)
  * [ Pull requests 1 ](https://github.com/Kedreamix/Linly-Dubbing/pulls)
  * [ Actions ](https://github.com/Kedreamix/Linly-Dubbing/actions)
  * [ Projects 0 ](https://github.com/Kedreamix/Linly-Dubbing/projects)
  * [ Security ](https://github.com/Kedreamix/Linly-Dubbing/security)
  * [ Insights ](https://github.com/Kedreamix/Linly-Dubbing/pulse)


Additional navigation options
  * [ Code  ](https://github.com/Kedreamix/Linly-Dubbing)
  * [ Issues  ](https://github.com/Kedreamix/Linly-Dubbing/issues)
  * [ Pull requests  ](https://github.com/Kedreamix/Linly-Dubbing/pulls)
  * [ Actions  ](https://github.com/Kedreamix/Linly-Dubbing/actions)
  * [ Projects  ](https://github.com/Kedreamix/Linly-Dubbing/projects)
  * [ Security  ](https://github.com/Kedreamix/Linly-Dubbing/security)
  * [ Insights  ](https://github.com/Kedreamix/Linly-Dubbing/pulse)


# Kedreamix/Linly-Dubbing
main
[Branches](https://github.com/Kedreamix/Linly-Dubbing/branches)[Tags](https://github.com/Kedreamix/Linly-Dubbing/tags)
[](https://github.com/Kedreamix/Linly-Dubbing/branches)[](https://github.com/Kedreamix/Linly-Dubbing/tags)
Go to file
Code
## Folders and files
Name| Name| Last commit message| Last commit date  
---|---|---|---  
## Latest commit
## History
[59 Commits](https://github.com/Kedreamix/Linly-Dubbing/commits/main/)[](https://github.com/Kedreamix/Linly-Dubbing/commits/main/)  
[CosyVoice @ 6be8d0f](https://github.com/FunAudioLLM/CosyVoice/tree/6be8d0fc367f48c46a671edc16a99b9728038cb7 "CosyVoice")| [CosyVoice @ 6be8d0f](https://github.com/FunAudioLLM/CosyVoice/tree/6be8d0fc367f48c46a671edc16a99b9728038cb7 "CosyVoice")  
[docs](https://github.com/Kedreamix/Linly-Dubbing/tree/main/docs "docs")| [docs](https://github.com/Kedreamix/Linly-Dubbing/tree/main/docs "docs")  
[examples](https://github.com/Kedreamix/Linly-Dubbing/tree/main/examples "examples")| [examples](https://github.com/Kedreamix/Linly-Dubbing/tree/main/examples "examples")  
[font](https://github.com/Kedreamix/Linly-Dubbing/tree/main/font "font")| [font](https://github.com/Kedreamix/Linly-Dubbing/tree/main/font "font")  
[scripts](https://github.com/Kedreamix/Linly-Dubbing/tree/main/scripts "scripts")| [scripts](https://github.com/Kedreamix/Linly-Dubbing/tree/main/scripts "scripts")  
[submodules](https://github.com/Kedreamix/Linly-Dubbing/tree/main/submodules "submodules")| [submodules](https://github.com/Kedreamix/Linly-Dubbing/tree/main/submodules "submodules")  
[tabs](https://github.com/Kedreamix/Linly-Dubbing/tree/main/tabs "tabs")| [tabs](https://github.com/Kedreamix/Linly-Dubbing/tree/main/tabs "tabs")  
[tools](https://github.com/Kedreamix/Linly-Dubbing/tree/main/tools "tools")| [tools](https://github.com/Kedreamix/Linly-Dubbing/tree/main/tools "tools")  
[.gitignore](https://github.com/Kedreamix/Linly-Dubbing/blob/main/.gitignore ".gitignore")| [.gitignore](https://github.com/Kedreamix/Linly-Dubbing/blob/main/.gitignore ".gitignore")  
[.gitmodules](https://github.com/Kedreamix/Linly-Dubbing/blob/main/.gitmodules ".gitmodules")| [.gitmodules](https://github.com/Kedreamix/Linly-Dubbing/blob/main/.gitmodules ".gitmodules")  
[LICENSE](https://github.com/Kedreamix/Linly-Dubbing/blob/main/LICENSE "LICENSE")| [LICENSE](https://github.com/Kedreamix/Linly-Dubbing/blob/main/LICENSE "LICENSE")  
[README.md](https://github.com/Kedreamix/Linly-Dubbing/blob/main/README.md "README.md")| [README.md](https://github.com/Kedreamix/Linly-Dubbing/blob/main/README.md "README.md")  
[README_zh.md](https://github.com/Kedreamix/Linly-Dubbing/blob/main/README_zh.md "README_zh.md")| [README_zh.md](https://github.com/Kedreamix/Linly-Dubbing/blob/main/README_zh.md "README_zh.md")  
[colab_webui.ipynb](https://github.com/Kedreamix/Linly-Dubbing/blob/main/colab_webui.ipynb "colab_webui.ipynb")| [colab_webui.ipynb](https://github.com/Kedreamix/Linly-Dubbing/blob/main/colab_webui.ipynb "colab_webui.ipynb")  
[env.example](https://github.com/Kedreamix/Linly-Dubbing/blob/main/env.example "env.example")| [env.example](https://github.com/Kedreamix/Linly-Dubbing/blob/main/env.example "env.example")  
[gui.py](https://github.com/Kedreamix/Linly-Dubbing/blob/main/gui.py "gui.py")| [gui.py](https://github.com/Kedreamix/Linly-Dubbing/blob/main/gui.py "gui.py")  
[requirements.txt](https://github.com/Kedreamix/Linly-Dubbing/blob/main/requirements.txt "requirements.txt")| [requirements.txt](https://github.com/Kedreamix/Linly-Dubbing/blob/main/requirements.txt "requirements.txt")  
[requirements_module.txt](https://github.com/Kedreamix/Linly-Dubbing/blob/main/requirements_module.txt "requirements_module.txt")| [requirements_module.txt](https://github.com/Kedreamix/Linly-Dubbing/blob/main/requirements_module.txt "requirements_module.txt")  
[ui_components.py](https://github.com/Kedreamix/Linly-Dubbing/blob/main/ui_components.py "ui_components.py")| [ui_components.py](https://github.com/Kedreamix/Linly-Dubbing/blob/main/ui_components.py "ui_components.py")  
[webui.py](https://github.com/Kedreamix/Linly-Dubbing/blob/main/webui.py "webui.py")| [webui.py](https://github.com/Kedreamix/Linly-Dubbing/blob/main/webui.py "webui.py")  
[问题参考汇总.md](https://github.com/Kedreamix/Linly-Dubbing/blob/main/%E9%97%AE%E9%A2%98%E5%8F%82%E8%80%83%E6%B1%87%E6%80%BB.md "问题参考汇总.md")| [问题参考汇总.md](https://github.com/Kedreamix/Linly-Dubbing/blob/main/%E9%97%AE%E9%A2%98%E5%8F%82%E8%80%83%E6%B1%87%E6%80%BB.md "问题参考汇总.md")  
View all files  
## Repository files navigation
  * [README](https://github.com/Kedreamix/Linly-Dubbing)
  * [Apache-2.0 license](https://github.com/Kedreamix/Linly-Dubbing)


# Intelligent Multi-language AI Dubbing/Translation Tool - Linly-Dubbing — "AI Empowerment, Language Without Borders"
[](https://github.com/Kedreamix/Linly-Dubbing#intelligent-multi-language-ai-dubbingtranslation-tool---linly-dubbing--ai-empowerment-language-without-borders)
# Linly-Dubbing WebUI
[](https://github.com/Kedreamix/Linly-Dubbing#linly-dubbing-webui)
[![madewithlove](https://camo.githubusercontent.com/b199fabd947beb75a0113cae47b1dd8d1c8be22cd4802cd24b1c8863a4533e3f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6d6164655f776974682d2545322539442541342d7265643f7374796c653d666f722d7468652d6261646765266c6162656c436f6c6f723d6f72616e6765)](https://github.com/Kedreamix/Linly-Dubbing) [![](https://github.com/Kedreamix/Linly-Dubbing/raw/main/docs/linly_logo.png)](https://github.com/Kedreamix/Linly-Dubbing/blob/main/docs/linly_logo.png)
[![Open In Colab](https://camo.githubusercontent.com/eb4e984a24e09f69a60907bdc1c83468b3c484f1623e59ecfba536034443d62a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436f6c61622d4639414230303f7374796c653d666f722d7468652d6261646765266c6f676f3d676f6f676c65636f6c616226636f6c6f723d353235323532)](https://colab.research.google.com/github/Kedreamix/Linly-Dubbing/blob/main/colab_webui.ipynb) [![Licence](https://camo.githubusercontent.com/51aae4cf4a99a8bea12e41985e76453bd7725b8923ecc959e855bd9e9747a176/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c4943454e53452d4170616368652d7265642e7376673f7374796c653d666f722d7468652d6261646765)](https://github.com/Kedreamix/Linly-Talker/blob/main/LICENSE)
[**English**](https://github.com/Kedreamix/Linly-Dubbing/blob/main/README.md) | [**中文简体**](https://github.com/Kedreamix/Linly-Dubbing/blob/main/README_zh.md)
Table of Contents
  * [Intelligent Multi-language AI Dubbing/Translation Tool - Linly-Dubbing — "AI Empowerment, Language Without Borders"](https://github.com/Kedreamix/Linly-Dubbing#intelligent-multi-language-ai-dubbingtranslation-tool---linly-dubbing--ai-empowerment-language-without-borders)
    * [Introduction](https://github.com/Kedreamix/Linly-Dubbing#introduction)
    * [TO DO LIST](https://github.com/Kedreamix/Linly-Dubbing#to-do-list)
    * [Examples](https://github.com/Kedreamix/Linly-Dubbing#examples)
    * [Installation and Usage Guide](https://github.com/Kedreamix/Linly-Dubbing#installation-and-usage-guide)
      * [Test Environment](https://github.com/Kedreamix/Linly-Dubbing#test-environment)
      * [1. Clone the Repository](https://github.com/Kedreamix/Linly-Dubbing#1-clone-the-repository)
      * [2. Install Dependencies](https://github.com/Kedreamix/Linly-Dubbing#2-install-dependencies)
      * [3. Configure Environment Variables](https://github.com/Kedreamix/Linly-Dubbing#3-configure-environment-variables)
      * [4. Run the Application](https://github.com/Kedreamix/Linly-Dubbing#4-run-the-application)
    * [Detailed Features and Technical Details](https://github.com/Kedreamix/Linly-Dubbing#detailed-features-and-technical-details)
      * [Automatic Video Download](https://github.com/Kedreamix/Linly-Dubbing#automatic-video-download)
      * [Vocal Separation](https://github.com/Kedreamix/Linly-Dubbing#vocal-separation)
        * [Demucs](https://github.com/Kedreamix/Linly-Dubbing#demucs)
        * [UVR5](https://github.com/Kedreamix/Linly-Dubbing#uvr5)
      * [AI Speech Recognition](https://github.com/Kedreamix/Linly-Dubbing#ai-speech-recognition)
        * [WhisperX](https://github.com/Kedreamix/Linly-Dubbing#whisperx)
        * [FunASR](https://github.com/Kedreamix/Linly-Dubbing#funasr)
      * [Large Language Model Translation](https://github.com/Kedreamix/Linly-Dubbing#large-language-model-translation)
        * [OpenAI API](https://github.com/Kedreamix/Linly-Dubbing#openai-api)
        * [Qwen](https://github.com/Kedreamix/Linly-Dubbing#qwen)
        * [Google Translate](https://github.com/Kedreamix/Linly-Dubbing#google-translate)
      * [AI-Powered Speech Synthesis](https://github.com/Kedreamix/Linly-Dubbing#ai-powered-speech-synthesis)
        * [Edge TTS](https://github.com/Kedreamix/Linly-Dubbing#edge-tts)
        * [XTTS](https://github.com/Kedreamix/Linly-Dubbing#xtts)
        * [CosyVoice](https://github.com/Kedreamix/Linly-Dubbing#cosyvoice)
        * [GPT-SoVITS](https://github.com/Kedreamix/Linly-Dubbing#gpt-sovits)
      * [Video Processing](https://github.com/Kedreamix/Linly-Dubbing#video-processing)
      * [Digital Human Lip-Sync Technology](https://github.com/Kedreamix/Linly-Dubbing#digital-human-lip-sync-technology)
    * [License](https://github.com/Kedreamix/Linly-Dubbing#license)
    * [References](https://github.com/Kedreamix/Linly-Dubbing#references)
    * [Star History](https://github.com/Kedreamix/Linly-Dubbing#star-history)


## Introduction
[](https://github.com/Kedreamix/Linly-Dubbing#introduction)
`Linly-Dubbing` is an intelligent multi-language AI dubbing and translation tool inspired by [`YouDub-webui`](https://github.com/liuzhao1225/YouDub-webui) and further extended and optimized. We aim to offer diverse and high-quality dubbing options by integrating [`Linly-Talker`](https://github.com/Kedreamix/Linly-Talker)’s digital human lip-sync technology, creating a more natural multi-language video experience.
Leveraging cutting-edge AI technologies, `Linly-Dubbing` sets new standards in naturalness and accuracy for multi-language dubbing, making it ideal for international education, global content localization, and more. It helps teams extend their reach and share high-quality content worldwide.
Key features include:
  * **Multi-language Support** : Offers dubbing and subtitle translation in Chinese and many other languages to meet global needs.
  * **AI Speech Recognition** : Employs advanced AI for precise speech-to-text conversion and speaker recognition.
  * **Large Language Model Translation** : Uses leading language models like GPT for fast and accurate translations, ensuring professional quality.
  * **AI Voice Cloning** : Utilizes cutting-edge voice cloning to generate speech closely matching the original video's tone and emotion.
  * **Digital Human Lip-Sync Technology** : Synchronizes dubbing with video visuals, enhancing realism and interactivity.
  * **Flexible Upload and Translation** : Users can upload videos, choose translation languages, and standards, ensuring personalization and flexibility.
  * **Regular Updates** : Continuously introduces the latest models to stay at the forefront of dubbing and translation technology.


Our mission is to provide seamless, high-quality multi-language dubbing and translation services, empowering content creators and businesses to thrive in global markets.
## TO DO LIST
[](https://github.com/Kedreamix/Linly-Dubbing#to-do-list)
  * Implement basic AI dubbing and smart translation features.
  * Integrate CosyVoice’s AI voice cloning for high-quality audio translation.
  * Add FunASR AI speech recognition algorithm with optimized Chinese support.
  * Utilize Qwen large language model for multi-language translation.
  * Develop Linly-Dubbing WebUI for easy one-click video generation with customizable parameters.
  * Integrate UVR5 for voice/accompaniment separation and reverb removal, referencing GPTSoVITS.
  * Improve voice cloning naturalness using GPTSoVITS for fine-tuning.
  * Implement and optimize digital human lip-sync technology for better dubbing and visual coherence.


## Examples
[](https://github.com/Kedreamix/Linly-Dubbing#examples)
Original Video | Linly-Dubbing  
---|---  
original_video.mp4 |  linly_dubbing.mp4  
## Installation and Usage Guide
[](https://github.com/Kedreamix/Linly-Dubbing#installation-and-usage-guide)
### Test Environment
[](https://github.com/Kedreamix/Linly-Dubbing#test-environment)
This guide applies to the following test environments:
  * Python 3.10, PyTorch 2.3.1, CUDA 12.1
  * Python 3.10, PyTorch 2.3.1, CUDA 11.8


Follow the steps below to install and configure `Linly-Dubbing`.
Note
A Colab script is also available for an online experience: [Linly-Dubbing Colab](https://colab.research.google.com/github/Kedreamix/Linly-Dubbing/blob/main/colab_webui.ipynb).
### 1. Clone the Repository
[](https://github.com/Kedreamix/Linly-Dubbing#1-clone-the-repository)
First, clone the `Linly-Dubbing` repository to your local machine and initialize submodules.
```
# Clone the project to your local machine
git clone https://github.com/Kedreamix/Linly-Dubbing.git --depth 1
# Navigate to the project directory
cd Linly-Dubbing
# Initialize and update submodules like CosyVoice
git submodule update --init --recursive
```

### 2. Install Dependencies
[](https://github.com/Kedreamix/Linly-Dubbing#2-install-dependencies)
Before proceeding, please create a new Python environment and install the required dependencies.
```
# Create a conda environment named 'linly_dubbing' and specify Python version 3.10
conda create -n linly_dubbing python=3.10 -y
# Activate the newly created environment
conda activate linly_dubbing
# Navigate to the project directory
cd Linly-Dubbing/
# Install the ffmpeg tool
# Install ffmpeg using conda
conda install ffmpeg==7.0.2 -c conda-forge
# Install ffmpeg using a domestic mirror
conda install ffmpeg==7.0.2 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/
# Upgrade pip to the latest version
python -m pip install --upgrade pip
# Change the PyPI source to speed up package downloads
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
```

Depending on your CUDA version, install PyTorch and related libraries using the following commands:
```
# For CUDA 11.8
pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu118
# For CUDA 12.1
pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu121
```

If you prefer to install PyTorch via conda, you can use the following commands:
```
# For CUDA 11.8
conda install pytorch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 pytorch-cuda=11.8 -c pytorch -c nvidia
# For CUDA 12.1
conda install pytorch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 pytorch-cuda=12.1 -c pytorch -c nvidia
```

Note
The installation process is very slow.
Next, install the remaining project dependencies:
```
# Install the required Python packages for the project
# pynini is required by WeTextProcessing, so use conda to install it as it works across all platforms.
conda install -y pynini==2.1.5 -c conda-forge
# -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/
pip install -r requirements.txt
# Install dependencies for submodules
pip install -r requirements_module.txt
```

Tip
If you encounter an error during installation that says "Could not load library libcudnn_ops_infer.so.8," follow these steps to fix it:
```
# Set LD_LIBRARY_PATH to include the correct cuDNN library path
export LD_LIBRARY_PATH=`python3 -c 'import os; import torch; print(os.path.dirname(os.path.dirname(torch.__file__)) +"/nvidia/cudnn/lib")'`:$LD_LIBRARY_PATH
```

### 3. Configure Environment Variables
[](https://github.com/Kedreamix/Linly-Dubbing#3-configure-environment-variables)
Before running the program, you need to configure the necessary environment variables. In the root directory of the project, create a `.env` file by renaming `env.example` and filling in the following variables:
  * `OPENAI_API_KEY`: Your OpenAI API key, usually formatted as `sk-xxx`.
  * `MODEL_NAME`: The name of the model you are using, such as `gpt-4` or `gpt-3.5-turbo`.
  * `OPENAI_API_BASE`: If you are using a self-hosted OpenAI model, provide the corresponding API base URL here.
  * `HF_TOKEN`: Your Hugging Face API token, used to access and download models.
  * `HF_ENDPOINT`: A custom Hugging Face endpoint, which can be specified if you encounter issues with model downloading.
  * `APPID` and `ACCESS_TOKEN`: Credentials for using the Bytedance TTS engine.
  * `BAIDU_API_KEY` and `BAIDU_SECRET_KEY`: Used for Baidu's Ernie Bot API.


Note
In most cases, you only need to configure `MODEL_NAME` and `HF_TOKEN`.
By default, `MODEL_NAME` is set to `Qwen/Qwen1.5-4B-Chat`, so you do not need to configure the `OPENAI_API_KEY`.
Tip
Since the performance of large models can be limited under normal circumstances, it is recommended to use larger models or better APIs. I personally recommend choosing OpenAI's API. If cost is a concern, you can try Baidu's Ernie Bot API, which offers free API access. Simply apply for the API and add it to your environment variables: <https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application/v1>.
You can obtain your `HF_TOKEN` from [Hugging Face](https://huggingface.co/settings/tokens). If you wish to use the **speaker separation feature** , make sure to request access to [pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1). Otherwise, you can opt not to enable this feature.
### 4. Run the Application
[](https://github.com/Kedreamix/Linly-Dubbing#4-run-the-application)
Before launching the application, run the following commands to automatically download the required models (including Qwen, XTTSv2, and faster-whisper-large-v3):
```
# For Linux
bash scripts/download_models.sh
# For Windows
python scripts/modelscope_download.py
# Download the wav2vec2_fairseq_base_ls960_asr_ls960.pth file and place it in the models/ASR/whisper folder
wget -nc https://download.pytorch.org/torchaudio/models/wav2vec2_fairseq_base_ls960_asr_ls960.pth \
  -O models/ASR/whisper/wav2vec2_fairseq_base_ls960_asr_ls960.pth
```

[![Download models](https://github.com/Kedreamix/Linly-Dubbing/raw/main/docs/download.png)](https://github.com/Kedreamix/Linly-Dubbing/blob/main/docs/download.png)
Once the download is complete, launch the WebUI interface using the following command:
```
python webui.py
```

After starting, you will see an interface like the one below. You can open <http://127.0.0.1:6006> to explore the application:
[![Linly-Dubbing](https://github.com/Kedreamix/Linly-Dubbing/raw/main/docs/webui.png)](https://github.com/Kedreamix/Linly-Dubbing/blob/main/docs/webui.png)
## Detailed Features and Technical Details
[](https://github.com/Kedreamix/Linly-Dubbing#detailed-features-and-technical-details)
### Automatic Video Download
[](https://github.com/Kedreamix/Linly-Dubbing#automatic-video-download)
**yt-dlp** is a powerful open-source command-line tool designed for downloading video and audio from YouTube and other websites. This tool offers a wide range of parameter options, allowing users to customize download behavior to their needs. Whether choosing specific formats, resolutions, or extracting audio, yt-dlp provides flexible solutions. It also supports extensive post-processing features, such as automatically adding metadata and renaming files. For more details on parameters and usage, refer to the [yt-dlp official repository](https://github.com/yt-dlp/yt-dlp).
### Vocal Separation
[](https://github.com/Kedreamix/Linly-Dubbing#vocal-separation)
#### Demucs
[](https://github.com/Kedreamix/Linly-Dubbing#demucs)
**Demucs** is an advanced sound separation model developed by the Facebook research team, designed to separate different sound sources from mixed audio. Although its architecture is simple, Demucs is powerful enough to isolate instruments, voices, and background noise, making it easier for users to perform post-processing and editing. Its user-friendly design has made it a preferred tool for many audio processing applications, including music production and post-production in films. More information can be found on the [Demucs project page](https://github.com/facebookresearch/demucs).
#### UVR5
[](https://github.com/Kedreamix/Linly-Dubbing#uvr5)
**UVR5 (Ultimate Vocal Remover)** is one of the best tools for vocal and accompaniment separation. It excels in generating high-quality accompaniments and vocal extractions, outperforming tools like RX9, RipX, and SpectraLayers 9. The extracted accompaniments are nearly indistinguishable from the original stereo tracks, and UVR5 is both open-source and free. Find the source code at: <https://github.com/Anjok07/ultimatevocalremovergui>.
WebUI reference: <https://github.com/RVC-Boss/GPT-SoVITS/tree/main/tools/uvr5>
Model weights reference: <https://huggingface.co/lj1995/VoiceConversionWebUI/tree/main/uvr5_weights>
### AI Speech Recognition
[](https://github.com/Kedreamix/Linly-Dubbing#ai-speech-recognition)
#### WhisperX
[](https://github.com/Kedreamix/Linly-Dubbing#whisperx)
**WhisperX** is an extension of OpenAI's Whisper speech recognition system, specifically designed for generating and aligning subtitles for videos. Unlike traditional speech recognition systems, WhisperX not only accurately transcribes spoken content into text but also aligns it with video frames to generate timestamped subtitle files. This precise alignment makes video editing and subtitle generation more efficient and intuitive. WhisperX also supports multi-speaker recognition, providing detailed speaker information for richer, easier-to-understand subtitles.
#### FunASR
[](https://github.com/Kedreamix/Linly-Dubbing#funasr)
**FunASR** is a comprehensive speech recognition toolkit offering a wide range of speech processing features, including Automatic Speech Recognition (ASR), Voice Activity Detection (VAD), punctuation restoration, language modeling, speaker verification, speaker separation, and multi-speaker dialogue recognition. FunASR is particularly optimized for Chinese speech and offers pre-trained models with easy fine-tuning interfaces. It’s a significant tool in the field of speech recognition, widely used in voice assistants, automatic subtitle generation, and more. For more information, visit the [FunASR project](https://github.com/alibaba-damo-academy/FunASR).
### Large Language Model Translation
[](https://github.com/Kedreamix/Linly-Dubbing#large-language-model-translation)
#### OpenAI API
[](https://github.com/Kedreamix/Linly-Dubbing#openai-api)
`Linly-Dubbing` uses OpenAI's large language models, such as GPT-4 and GPT-3.5-turbo, to perform high-quality translations via API. OpenAI's models are renowned for their natural language understanding and high-precision text generation capabilities, commonly used in tasks like dialogue generation and text analysis. You can find more details about the models and usage in the [OpenAI official documentation](https://platform.openai.com/docs/models).
#### Qwen
[](https://github.com/Kedreamix/Linly-Dubbing#qwen)
**Qwen** is a localized large language model that supports multi-language translation. Although its performance may not match OpenAI's top models, its open-source nature and local execution make it a cost-effective option. Qwen is capable of handling text translations across various languages and serves as a powerful open-source alternative. More details can be found on the [Qwen project page](https://github.com/QwenLM/Qwen).
#### Google Translate
[](https://github.com/Kedreamix/Linly-Dubbing#google-translate)
As a supplement to the translation features, `Linly-Dubbing` also integrates [Google Translate](https://py-googletrans.readthedocs.io/en/latest/). Google Translate offers broad language support and good translation quality, making it suitable for quickly obtaining approximate translations.
### AI-Powered Speech Synthesis
[](https://github.com/Kedreamix/Linly-Dubbing#ai-powered-speech-synthesis)
#### Edge TTS
[](https://github.com/Kedreamix/Linly-Dubbing#edge-tts)
**Edge TTS** is a high-quality text-to-speech conversion service provided by Microsoft. It supports multiple languages and voice styles, capable of generating natural and fluent voice output. With Edge TTS, `Linly-Dubbing` can generate high-quality speech from text, making content more lively and understandable. For more information, refer to the [Edge TTS official documentation](https://github.com/rany2/edge-tts).
#### XTTS
[](https://github.com/Kedreamix/Linly-Dubbing#xtts)
**Coqui XTTS** is an advanced deep learning text-to-speech toolkit focused on voice cloning and multi-language speech synthesis. XTTS can achieve voice cloning using brief audio snippets and generate realistic speech output. It offers a variety of pre-trained models and development tools, supporting training and fine-tuning of new models. Users can explore XTTS's capabilities online at [Hugging Face](https://huggingface.co/spaces/coqui/xtts) or visit the [official GitHub repository](https://github.com/coqui-ai/TTS) for more technical details.
  * Try XTTS online: [Hugging Face](https://huggingface.co/spaces/coqui/xtts)
  * Official GitHub repository: [Coqui TTS](https://github.com/coqui-ai/TTS)


#### CosyVoice
[](https://github.com/Kedreamix/Linly-Dubbing#cosyvoice)
**CosyVoice** is a multi-language speech understanding and synthesis model developed by Alibaba's Tongyi Lab, supporting Chinese, English, Japanese, Cantonese, Korean, and more. CosyVoice is trained on over 150,000 hours of voice data and enables high-quality speech synthesis and cross-lingual voice cloning. It excels at generating natural and coherent speech across languages, with support for one-shot voice cloning, needing only 3 to 10 seconds of original audio to generate a similar voice. For more information and model details, visit the [CosyVoice project](https://github.com/FunAudioLLM/CosyVoice).
Main features and characteristics:
  1. **Multi-language support** : Handles speech synthesis tasks in various languages.
  2. **Multi-style speech synthesis** : Controls the emotion and tone of speech through commands.
  3. **Streaming inference support** : Future plans include real-time streaming inference support.


#### GPT-SoVITS
[](https://github.com/Kedreamix/Linly-Dubbing#gpt-sovits)
Thanks to the contributions of the open-source community, AI speech synthesis also benefits from the open-source voice cloning model `GPT-SoVITS`. **GPT** is a transformer-based natural language processing model with strong text generation capabilities, while **SoVITS** is a deep learning-based voice conversion technology capable of converting one person's voice into another’s. By combining these two technologies, **GPT-SoVITS** can generate highly realistic speech that matches the given text content.
The project can be found at <https://github.com/RVC-Boss/GPT-SoVITS>. Key features include:
  1. **Zero-shot Text-to-Speech (TTS):** Input a 5-second voice sample to experience instant text-to-speech conversion.
  2. **Few-shot TTS:** Fine-tune the model with just 1 minute of training data to improve voice similarity and realism.
  3. **Cross-lingual support:** Inference across languages different from the training dataset, currently supporting English, Japanese, and Chinese.
  4. **WebUI tools:** Integrated tools include voice accompaniment separation, automatic dataset splitting, Chinese automatic speech recognition (ASR), and text annotation to help beginners create training datasets and GPT/SoVITS models.


### Video Processing
[](https://github.com/Kedreamix/Linly-Dubbing#video-processing)
In terms of video processing, `Linly-Dubbing` provides robust functionality support. Users can easily add subtitles, insert background music, adjust background music volume, and modify overall playback speed. With these features, users can customize video content to make it more engaging and personalized.
### Digital Human Lip-Sync Technology
[](https://github.com/Kedreamix/Linly-Dubbing#digital-human-lip-sync-technology)
Inspired by `Linly-Talker`, this project focuses on digital human lip-sync technology. By combining advanced computer vision and speech recognition technologies, `Linly-Talker` allows digital characters' lip movements to match voiceovers precisely, achieving highly natural synchronization. This technology is not only applicable to animated characters but can also be used in scenarios such as virtual presenters or educators in instructional videos. `Linly-Talker` enhances digital character performance with accurate lip-sync and vivid facial expressions, providing a more immersive experience for the audience. This advanced digital human lip-sync technology significantly improves the professionalism and viewing experience of video content. For more information, refer to <https://github.com/Kedreamix/Linly-Talker>.
## License
[](https://github.com/Kedreamix/Linly-Dubbing#license)
Caution
When using this tool, please comply with relevant laws, including copyright, data protection, and privacy laws. Do not use this tool without permission from the original author and/or rights holder.
`Linly-Dubbing` follows the Apache License 2.0. When using this tool, please comply with relevant laws, including copyright, data protection, and privacy laws. Do not use this tool without permission from the original author and/or rights holder.
## References
[](https://github.com/Kedreamix/Linly-Dubbing#references)
In developing this project, I referenced and drew inspiration from several outstanding open-source projects and related resources. Special thanks to the developers and contributors of these projects and the open-source community. Below are the main projects we referenced:
  * [YouDub-webui](https://github.com/liuzhao1225/): Provides a feature-rich web interface for downloading and processing YouTube videos, from which we drew much inspiration and technical implementation details.
  * [Coqui TTS](https://github.com/coqui-ai/TTS)
  * [Qwen](https://github.com/QwenLM/Qwen)
  * [FunASR](https://github.com/alibaba-damo-academy/FunASR)
  * [CosyVoice](https://github.com/FunAudioLLM/CosyVoice)
  * [Linly-Talker](https://github.com/Kedreamix/Linly-Talker)


## Star History
[](https://github.com/Kedreamix/Linly-Dubbing#star-history)
[![Star History Chart](https://camo.githubusercontent.com/73e6f579d13604888ad232a93e83aa63db8be9edfc77f1c367eafe26b6ae8014/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d4b65647265616d69782f4c696e6c792d44756262696e6726747970653d44617465)](https://camo.githubusercontent.com/73e6f579d13604888ad232a93e83aa63db8be9edfc77f1c367eafe26b6ae8014/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d4b65647265616d69782f4c696e6c792d44756262696e6726747970653d44617465)
## About
智能视频多语言AI配音/翻译工具 - Linly-Dubbing — “AI赋能，语言无界” 
### Resources
[ Readme ](https://github.com/Kedreamix/Linly-Dubbing#readme-ov-file)
### License
[ Apache-2.0 license ](https://github.com/Kedreamix/Linly-Dubbing#Apache-2.0-1-ov-file)
[ Activity](https://github.com/Kedreamix/Linly-Dubbing/activity)
### Stars
[ **2.3k** stars](https://github.com/Kedreamix/Linly-Dubbing/stargazers)
### Watchers
[ **16** watching](https://github.com/Kedreamix/Linly-Dubbing/watchers)
### Forks
[ **227** forks](https://github.com/Kedreamix/Linly-Dubbing/forks)
[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FKedreamix%2FLinly-Dubbing&report=Kedreamix+%28user%29)
##  [Releases](https://github.com/Kedreamix/Linly-Dubbing/releases)
No releases published
##  [Packages 0](https://github.com/users/Kedreamix/packages?repo_name=Linly-Dubbing)
No packages published 
## Languages
  * [ Jupyter Notebook 69.4% ](https://github.com/Kedreamix/Linly-Dubbing/search?l=jupyter-notebook)
  * [ Python 30.5% ](https://github.com/Kedreamix/Linly-Dubbing/search?l=python)
  * [ HTML 0.1% ](https://github.com/Kedreamix/Linly-Dubbing/search?l=html)
  * [ Shell 0.0% ](https://github.com/Kedreamix/Linly-Dubbing/search?l=shell)
  * [ Makefile 0.0% ](https://github.com/Kedreamix/Linly-Dubbing/search?l=makefile)
  * [ Cython 0.0% ](https://github.com/Kedreamix/Linly-Dubbing/search?l=cython)


## Footer
[ ](https://github.com "GitHub") © 2025 GitHub, Inc. 
### Footer navigation
  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
  * [Security](https://github.com/security)
  * [Status](https://www.githubstatus.com/)
  * [Docs](https://docs.github.com/)
  * [Contact](https://support.github.com?tags=dotcom-footer)
  * Manage cookies 
  * Do not share my personal information 


You can’t perform that action at this time. 
