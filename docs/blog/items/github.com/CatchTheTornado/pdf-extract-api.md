# 原始URL: https://github.com/CatchTheTornado/pdf-extract-api

# 抓取时间: 2025-03-30 21:13:33

[Skip to content](https://github.com/CatchTheTornado/pdf-extract-api#start-of-content)
## Navigation Menu
Toggle navigation
[ ](https://github.com/)
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FCatchTheTornado%2Ftext-extract-api)
  * Product 
    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)
    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)
    * [ Actions Automate any workflow  ](https://github.com/features/actions)
    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)
    * [ Issues Plan and track work  ](https://github.com/features/issues)
    * [ Code Review Manage code changes  ](https://github.com/features/code-review)
    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)
    * [ Code Search Find more, search less  ](https://github.com/features/code-search)
Explore
    * [ All features ](https://github.com/features)
    * [ Documentation ](https://docs.github.com)
    * [ GitHub Skills ](https://skills.github.com)
    * [ Blog ](https://github.blog)
  * Solutions 
By company size
    * [ Enterprises ](https://github.com/enterprise)
    * [ Small and medium teams ](https://github.com/team)
    * [ Startups ](https://github.com/enterprise/startups)
    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)
By use case
    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)
    * [ DevOps ](https://github.com/solutions/use-case/devops)
    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)
    * [ View all use cases ](https://github.com/solutions/use-case)
By industry
    * [ Healthcare ](https://github.com/solutions/industry/healthcare)
    * [ Financial services ](https://github.com/solutions/industry/financial-services)
    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)
    * [ Government ](https://github.com/solutions/industry/government)
    * [ View all industries ](https://github.com/solutions/industry)
[ View all solutions ](https://github.com/solutions)
  * Resources 
Topics
    * [ AI ](https://github.com/resources/articles/ai)
    * [ DevOps ](https://github.com/resources/articles/devops)
    * [ Security ](https://github.com/resources/articles/security)
    * [ Software Development ](https://github.com/resources/articles/software-development)
    * [ View all ](https://github.com/resources/articles)
Explore
    * [ Learning Pathways ](https://resources.github.com/learn/pathways)
    * [ Events & Webinars ](https://resources.github.com)
    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)
    * [ Customer Stories ](https://github.com/customer-stories)
    * [ Partners ](https://partner.github.com)
    * [ Executive Insights ](https://github.com/solutions/executive-insights)
  * Open Source 
    * [ GitHub Sponsors Fund open source developers  ](https://github.com/sponsors)
    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)
Repositories
    * [ Topics ](https://github.com/topics)
    * [ Trending ](https://github.com/trending)
    * [ Collections ](https://github.com/collections)
  * Enterprise 
    * [ Enterprise platform AI-powered developer platform  ](https://github.com/enterprise)
Available add-ons
    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)
    * [ Copilot for business Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)
    * [ Premium Support Enterprise-grade 24/7 support  ](https://github.com/premium-support)
  * [Pricing](https://github.com/pricing)


Search or jump to...
# Search code, repositories, users, issues, pull requests...
Search 
Clear
[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)
#  Provide feedback 
We read every piece of feedback, and take your input very seriously.
Include my email address so I can be contacted
Cancel  Submit feedback 
#  Saved searches 
## Use saved searches to filter your results more quickly
Name
Query
To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). 
Cancel  Create saved search 
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FCatchTheTornado%2Ftext-extract-api)
[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=CatchTheTornado%2Ftext-extract-api) Reseting focus
You signed in with another tab or window. [Reload](https://github.com/CatchTheTornado/pdf-extract-api) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/CatchTheTornado/pdf-extract-api) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/CatchTheTornado/pdf-extract-api) to refresh your session. Dismiss alert
{{ message }}
[ CatchTheTornado ](https://github.com/CatchTheTornado) / **[text-extract-api](https://github.com/CatchTheTornado/text-extract-api) ** Public
  * [ Notifications ](https://github.com/login?return_to=%2FCatchTheTornado%2Ftext-extract-api) You must be signed in to change notification settings
  * [ Fork 200 ](https://github.com/login?return_to=%2FCatchTheTornado%2Ftext-extract-api)
  * [ Star  2.5k ](https://github.com/login?return_to=%2FCatchTheTornado%2Ftext-extract-api)


Document (PDF, Word, PPTX ...) extraction and parse API using state of the art modern OCRs + Ollama supported models. Anonymize documents. Remove PII. Convert any document or picture to structured JSON or Markdown 
[demo.doctractor.com](https://demo.doctractor.com "https://demo.doctractor.com")
### License
[ MIT license ](https://github.com/CatchTheTornado/text-extract-api/blob/main/LICENSE)
[ 2.5k stars ](https://github.com/CatchTheTornado/text-extract-api/stargazers) [ 200 forks ](https://github.com/CatchTheTornado/text-extract-api/forks) [ Branches ](https://github.com/CatchTheTornado/text-extract-api/branches) [ Tags ](https://github.com/CatchTheTornado/text-extract-api/tags) [ Activity ](https://github.com/CatchTheTornado/text-extract-api/activity)
[ Star  ](https://github.com/login?return_to=%2FCatchTheTornado%2Ftext-extract-api)
[ Notifications ](https://github.com/login?return_to=%2FCatchTheTornado%2Ftext-extract-api) You must be signed in to change notification settings
  * [ Code ](https://github.com/CatchTheTornado/text-extract-api)
  * [ Issues 43 ](https://github.com/CatchTheTornado/text-extract-api/issues)
  * [ Pull requests 1 ](https://github.com/CatchTheTornado/text-extract-api/pulls)
  * [ Discussions ](https://github.com/CatchTheTornado/text-extract-api/discussions)
  * [ Actions ](https://github.com/CatchTheTornado/text-extract-api/actions)
  * [ Projects 0 ](https://github.com/CatchTheTornado/text-extract-api/projects)
  * [ Security ](https://github.com/CatchTheTornado/text-extract-api/security)
  * [ Insights ](https://github.com/CatchTheTornado/text-extract-api/pulse)


Additional navigation options
  * [ Code  ](https://github.com/CatchTheTornado/text-extract-api)
  * [ Issues  ](https://github.com/CatchTheTornado/text-extract-api/issues)
  * [ Pull requests  ](https://github.com/CatchTheTornado/text-extract-api/pulls)
  * [ Discussions  ](https://github.com/CatchTheTornado/text-extract-api/discussions)
  * [ Actions  ](https://github.com/CatchTheTornado/text-extract-api/actions)
  * [ Projects  ](https://github.com/CatchTheTornado/text-extract-api/projects)
  * [ Security  ](https://github.com/CatchTheTornado/text-extract-api/security)
  * [ Insights  ](https://github.com/CatchTheTornado/text-extract-api/pulse)


# CatchTheTornado/text-extract-api
main
[Branches](https://github.com/CatchTheTornado/text-extract-api/branches)[Tags](https://github.com/CatchTheTornado/text-extract-api/tags)
[](https://github.com/CatchTheTornado/text-extract-api/branches)[](https://github.com/CatchTheTornado/text-extract-api/tags)
Go to file
Code
## Folders and files
Name| Name| Last commit message| Last commit date  
---|---|---|---  
## Latest commit
## History
[224 Commits](https://github.com/CatchTheTornado/text-extract-api/commits/main/)[](https://github.com/CatchTheTornado/text-extract-api/commits/main/)  
[.vscode](https://github.com/CatchTheTornado/text-extract-api/tree/main/.vscode ".vscode")| [.vscode](https://github.com/CatchTheTornado/text-extract-api/tree/main/.vscode ".vscode")  
[client](https://github.com/CatchTheTornado/text-extract-api/tree/main/client "client")| [client](https://github.com/CatchTheTornado/text-extract-api/tree/main/client "client")  
[config](https://github.com/CatchTheTornado/text-extract-api/tree/main/config "config")| [config](https://github.com/CatchTheTornado/text-extract-api/tree/main/config "config")  
[examples](https://github.com/CatchTheTornado/text-extract-api/tree/main/examples "examples")| [examples](https://github.com/CatchTheTornado/text-extract-api/tree/main/examples "examples")  
[logs](https://github.com/CatchTheTornado/text-extract-api/tree/main/logs "logs")| [logs](https://github.com/CatchTheTornado/text-extract-api/tree/main/logs "logs")  
[screenshots](https://github.com/CatchTheTornado/text-extract-api/tree/main/screenshots "screenshots")| [screenshots](https://github.com/CatchTheTornado/text-extract-api/tree/main/screenshots "screenshots")  
[scripts](https://github.com/CatchTheTornado/text-extract-api/tree/main/scripts "scripts")| [scripts](https://github.com/CatchTheTornado/text-extract-api/tree/main/scripts "scripts")  
[storage_profiles](https://github.com/CatchTheTornado/text-extract-api/tree/main/storage_profiles "storage_profiles")| [storage_profiles](https://github.com/CatchTheTornado/text-extract-api/tree/main/storage_profiles "storage_profiles")  
[tests/text_extract_api/files/converters](https://github.com/CatchTheTornado/text-extract-api/tree/main/tests/text_extract_api/files/converters "This path skips through empty directories")| [tests/text_extract_api/files/converters](https://github.com/CatchTheTornado/text-extract-api/tree/main/tests/text_extract_api/files/converters "This path skips through empty directories")  
[text_extract_api](https://github.com/CatchTheTornado/text-extract-api/tree/main/text_extract_api "text_extract_api")| [text_extract_api](https://github.com/CatchTheTornado/text-extract-api/tree/main/text_extract_api "text_extract_api")  
[.dockerignore](https://github.com/CatchTheTornado/text-extract-api/blob/main/.dockerignore ".dockerignore")| [.dockerignore](https://github.com/CatchTheTornado/text-extract-api/blob/main/.dockerignore ".dockerignore")  
[.env.example](https://github.com/CatchTheTornado/text-extract-api/blob/main/.env.example ".env.example")| [.env.example](https://github.com/CatchTheTornado/text-extract-api/blob/main/.env.example ".env.example")  
[.env.localhost.example](https://github.com/CatchTheTornado/text-extract-api/blob/main/.env.localhost.example ".env.localhost.example")| [.env.localhost.example](https://github.com/CatchTheTornado/text-extract-api/blob/main/.env.localhost.example ".env.localhost.example")  
[.gitignore](https://github.com/CatchTheTornado/text-extract-api/blob/main/.gitignore ".gitignore")| [.gitignore](https://github.com/CatchTheTornado/text-extract-api/blob/main/.gitignore ".gitignore")  
[LICENSE](https://github.com/CatchTheTornado/text-extract-api/blob/main/LICENSE "LICENSE")| [LICENSE](https://github.com/CatchTheTornado/text-extract-api/blob/main/LICENSE "LICENSE")  
[Makefile](https://github.com/CatchTheTornado/text-extract-api/blob/main/Makefile "Makefile")| [Makefile](https://github.com/CatchTheTornado/text-extract-api/blob/main/Makefile "Makefile")  
[README.md](https://github.com/CatchTheTornado/text-extract-api/blob/main/README.md "README.md")| [README.md](https://github.com/CatchTheTornado/text-extract-api/blob/main/README.md "README.md")  
[dev.Dockerfile](https://github.com/CatchTheTornado/text-extract-api/blob/main/dev.Dockerfile "dev.Dockerfile")| [dev.Dockerfile](https://github.com/CatchTheTornado/text-extract-api/blob/main/dev.Dockerfile "dev.Dockerfile")  
[dev.gpu.Dockerfile](https://github.com/CatchTheTornado/text-extract-api/blob/main/dev.gpu.Dockerfile "dev.gpu.Dockerfile")| [dev.gpu.Dockerfile](https://github.com/CatchTheTornado/text-extract-api/blob/main/dev.gpu.Dockerfile "dev.gpu.Dockerfile")  
[docker-compose.gpu.yml](https://github.com/CatchTheTornado/text-extract-api/blob/main/docker-compose.gpu.yml "docker-compose.gpu.yml")| [docker-compose.gpu.yml](https://github.com/CatchTheTornado/text-extract-api/blob/main/docker-compose.gpu.yml "docker-compose.gpu.yml")  
[docker-compose.yml](https://github.com/CatchTheTornado/text-extract-api/blob/main/docker-compose.yml "docker-compose.yml")| [docker-compose.yml](https://github.com/CatchTheTornado/text-extract-api/blob/main/docker-compose.yml "docker-compose.yml")  
[ocr-hero.webp](https://github.com/CatchTheTornado/text-extract-api/blob/main/ocr-hero.webp "ocr-hero.webp")| [ocr-hero.webp](https://github.com/CatchTheTornado/text-extract-api/blob/main/ocr-hero.webp "ocr-hero.webp")  
[pyproject.toml](https://github.com/CatchTheTornado/text-extract-api/blob/main/pyproject.toml "pyproject.toml")| [pyproject.toml](https://github.com/CatchTheTornado/text-extract-api/blob/main/pyproject.toml "pyproject.toml")  
[run.sh](https://github.com/CatchTheTornado/text-extract-api/blob/main/run.sh "run.sh")| [run.sh](https://github.com/CatchTheTornado/text-extract-api/blob/main/run.sh "run.sh")  
View all files  
## Repository files navigation
  * [README](https://github.com/CatchTheTornado/pdf-extract-api)
  * [MIT license](https://github.com/CatchTheTornado/pdf-extract-api)


# text-extract-api
[](https://github.com/CatchTheTornado/pdf-extract-api#text-extract-api)
Convert any image, PDF or Office document to Markdown _text_ or JSON structured document with super-high accuracy, including tabular data, numbers or math formulas.
The API is built with FastAPI and uses Celery for asynchronous task processing. Redis is used for caching OCR results.
[![hero doc extract](https://github.com/CatchTheTornado/text-extract-api/raw/main/ocr-hero.webp)](https://github.com/CatchTheTornado/text-extract-api/blob/main/ocr-hero.webp)
## Features:
[](https://github.com/CatchTheTornado/pdf-extract-api#features)
  * **No Cloud/external dependencies** all you need: PyTorch based OCR (EasyOCR) + Ollama are shipped and configured via `docker-compose` no data is sent outside your dev/server environment,
  * **PDF/Office to Markdown** conversion with very high accuracy using different OCR strategies including [llama3.2-vision](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/), [easyOCR](https://github.com/JaidedAI/EasyOCR), [minicpm-v](https://github.com/OpenBMB/MiniCPM-o?tab=readme-ov-file#minicpm-v-26), remote URL strategies including [marker-pdf](https://github.com/VikParuchuri/marker)
  * **PDF/Office to JSON** conversion using Ollama supported models (eg. LLama 3.1)
  * **LLM Improving OCR results** LLama is pretty good with fixing spelling and text issues in the OCR text
  * **Removing PII** This tool can be used for removing Personally Identifiable Information out of document - see `examples`
  * **Distributed queue processing** using [Celery](https://docs.celeryq.dev/en/stable/getting-started/introduction.html)
  * **Caching** using Redis - the OCR results can be easily cached prior to LLM processing,
  * **Storage Strategies** switchable storage strategies (Google Drive, Local File System ...)
  * **CLI tool** for sending tasks and processing results


## Screenshots
[](https://github.com/CatchTheTornado/pdf-extract-api#screenshots)
Converting MRI report to Markdown + JSON.
```
python client/cli.py ocr_upload --file examples/example-mri.pdf --prompt_file examples/example-mri-2-json-prompt.txt
```

Before running the example see [getting started](https://github.com/CatchTheTornado/pdf-extract-api#getting-started)
[![Converting MRI report to Markdown](https://github.com/CatchTheTornado/text-extract-api/raw/main/screenshots/example-1.png)](https://github.com/CatchTheTornado/text-extract-api/blob/main/screenshots/example-1.png)
Converting Invoice to JSON and remove PII
```
python client/cli.py ocr_upload --file examples/example-invoice.pdf --prompt_file examples/example-invoice-remove-pii.txt 
```

Before running the example see [getting started](https://github.com/CatchTheTornado/pdf-extract-api#getting-started)
[![Converting Invoice to JSON](https://github.com/CatchTheTornado/text-extract-api/raw/main/screenshots/example-2.png)](https://github.com/CatchTheTornado/text-extract-api/blob/main/screenshots/example-2.png)
## Getting started
[](https://github.com/CatchTheTornado/pdf-extract-api#getting-started)
You might want to run the app directly on your machine for development purposes OR to use for example Apple GPUs (which are not supported by Docker at the moment).
### Prerequisites
[](https://github.com/CatchTheTornado/pdf-extract-api#prerequisites)
To have it up and running please execute the following steps:
[Download and install Ollama](https://ollama.com/download) [Download and install Docker](https://www.docker.com/products/docker-desktop/)
> ### Setting Up Ollama on a Remote Host
> [](https://github.com/CatchTheTornado/pdf-extract-api#setting-up-ollama-on-a-remote-host)
> To connect to an external Ollama instance, set the environment variable: `OLLAMA_HOST=http://address:port`, e.g.:
> ```
OLLAMA_HOST=http(s)://127.0.0.1:5000
```

> If you want to disable the local Ollama model, use env `DISABLE_LOCAL_OLLAMA=1`, e.g.
> ```
DISABLE_LOCAL_OLLAMA=1 make install
```

> **Note** : When local Ollama is disabled, ensure the required model is downloaded on the external instance.
> Currently, the `DISABLE_LOCAL_OLLAMA` variable cannot be used to disable Ollama in Docker. As a workaround, remove the `ollama` service from `docker-compose.yml` or `docker-compose.gpu.yml`.
> Support for using the variable in Docker environments will be added in a future release.
### Clone the Repository
[](https://github.com/CatchTheTornado/pdf-extract-api#clone-the-repository)
First, clone the repository and change current directory to it:
```
git clone https://github.com/CatchTheTornado/text-extract-api.git
cd text-extract-api
```

### Setup with `Makefile`
[](https://github.com/CatchTheTornado/pdf-extract-api#setup-with-makefile)
Be default application create [virtual python env](https://docs.python.org/3/library/venv.html): `.venv`. You can disable this functionality on local setup by adding `DISABLE_VENV=1` before running script:
```
DISABLE_VENV=1 make install 
```

```
DISABLE_VENV=1 make run 
```

### Manual setup
[](https://github.com/CatchTheTornado/pdf-extract-api#manual-setup)
Configure environment variables:
```
cp .env.localhost.example .env.localhost
```

You might want to just use the defaults - should be fine. After ENV variables are set, just execute:
```
python3 -m venv .venv
source .venv/bin/activate
pip install -e .
chmod +x run.sh
run.sh
```

This command will install all the dependencies - including Redis (via Docker, so it is not entirely docker free method of running `text-extract-api` anyways :)
(MAC) - Dependencies
```
brew update && brew install libmagic poppler pkg-config ghostscript ffmpeg automake autoconf

```

(Mac) - You need to startup the celery worker
```
source .venv/bin/activate && celery -A text_extract_api.celery_app worker --loglevel=info --pool=solo

```

Then you're good to go with running some CLI commands like:
```
python client/cli.py ocr_upload --file examples/example-mri.pdf --ocr_cache --prompt_file=examples/example-mri-remove-pii.txt
```

### Scaling the parallell processing
[](https://github.com/CatchTheTornado/pdf-extract-api#scaling-the-parallell-processing)
To have multiple tasks running at once - for concurrent processing please run the following command to start single worker process:
```
celery -A text_extract_api.tasks worker --loglevel=info --pool=solo & # to scale by concurrent processing please run this line as many times as many concurrent processess you want to have running
```

## Online demo
[](https://github.com/CatchTheTornado/pdf-extract-api#online-demo)
To try out the application with our hosted version you can skip the Getting started and try out the CLI tool against our cloud:
Open in the browser: [demo.doctractor.com](https://demo.doctractor.com/)
... or run n the terminal:
```
python3 -m venv .venv
source .venv/bin/activate
pip install -e .
export OCR_UPLOAD_URL=https://doctractor:Aekie2ao@api.doctractor.com/ocr/upload
export RESULT_URL=https://doctractor:Aekie2ao@api.doctractor.com/ocr/result/
python client/cli.py ocr_upload --file examples/example-mri.pdf --ocr_cache --prompt_file=examples/example-mri-remove-pii.txt
```

[Demo Source code](https://github.com/CatchTheTornado/text-extract-api-demo)
**Note:** In the free demo we don't guarantee any processing times. The API is Open so please do **not send any secret documents neither any documents containing personal information** , If you do - you're doing it on your own risk and responsiblity.
[![Demo screenshot](https://github.com/CatchTheTornado/text-extract-api/raw/main/screenshots/demo.png)](https://github.com/CatchTheTornado/text-extract-api/blob/main/screenshots/demo.png)
## Join us on Discord
[](https://github.com/CatchTheTornado/pdf-extract-api#join-us-on-discord)
In case of any questions, help requests or just feedback - please [join us on Discord](https://discord.gg/NJzu47Ye3a)!
## Text extract strategies
[](https://github.com/CatchTheTornado/pdf-extract-api#text-extract-strategies)
### `easyocr`
[](https://github.com/CatchTheTornado/pdf-extract-api#easyocr)
Easy OCR is available on Apache based license. It's general purpose OCR with support for more than 30 languages, probably with the best performance for English.
Enabled by default. Please do use the `strategy=easyocr` CLI and URL parameters to use it.
### `minicpm-v`
[](https://github.com/CatchTheTornado/pdf-extract-api#minicpm-v)
MiniCPM-V is an Apache based licensed OCR strategy.
The usage of MiniCPM-o/V model weights must strictly follow [MiniCPM Model License.md](https://github.com/OpenBMB/MiniCPM/blob/main/MiniCPM%20Model%20License.md).
The models and weights of MiniCPM are completely free for academic research. After filling out a ["questionnaire"](https://modelbest.feishu.cn/share/base/form/shrcnpV5ZT9EJ6xYjh3Kx0J6v8g) for registration, are also available for free commercial use.
Enabled by default. Please do use the `strategy=minicpm_v` CLI and URL parameters to use it.
⚠️ **Remember to pull the model in Ollama first**  
---  
You need to pull the model in Ollama - use the command:  
`python client/cli.py llm_pull --model minicpm-v`  
Or, if you have Ollama locally: `ollama pull minicpm-v`  
### `llama_vision`
[](https://github.com/CatchTheTornado/pdf-extract-api#llama_vision)
LLama 3.2 Vision Strategy is licensed on [Meta Community License Agreement](https://ollama.com/library/llama3.2-vision/blobs/0b4284c1f870). Works great for many languages, although due to the number of parameters (90b) this model is probably **the slowest** one.
Enabled by default. Please do use the `strategy=llama_vision` CLI and URL parameters to use it. It's by the way the default strategy
### `remote`
[](https://github.com/CatchTheTornado/pdf-extract-api#remote)
Some OCR's - like [Marker, state of the art PDF OCR](https://github.com/VikParuchuri/marker) - works really great for more than 50 languages, including great accuracy for Polish and other languages - let's say that are "diffult" to read for standard OCR.
The `marker-pdf` is however licensed on GPL3 license and **therefore it's not included** by default in this application (as we're bound to MIT).
The weights for the models are licensed cc-by-nc-sa-4.0, but I will waive that for any organization under $5M USD in gross revenue in the most recent 12-month period AND under $5M in lifetime VC/angel funding raised. You also must not be competitive with the Datalab API. If you want to remove the GPL license requirements (dual-license) and/or use the weights commercially over the revenue limit, check out the options here.
To have it up and running you can execute the following steps:
```
mkdir marker-distribution # this should be outside of the `text-extract-api` folder!
cd marker-distribution
pip install marker-pdf
pip install -U uvicorn fastapi python-multipart
marker_server --port 8002
```

Set the Remote API Url:
**Note: *** you might run `marker_server` on different port or server - then just make sure you export a proper env setting beffore starting off `text-extract-api` server:
```
export REMOTE_API_URL=http://localhost:8002/marker/upload
```

**Note: *** the URL might be also set via `/config/strategies.yaml` file
Run the `text-extract-api`:
```
make run
```

Please do use the `strategy=remote` CLI and URL parameters to use it. For example:
```
curl -X POST -H "Content-Type: multipart/form-data" -F "file=@examples/example-mri.pdf" -F "strategy=remote" -F "ocr_cache=true" -F "prompt=" -F "model=" "http://localhost:8000/ocr/upload" 
```

We are connecting to remote OCR via it's API to not share the same license (GPL3) by having it all linked on the source code level.
## Getting started with Docker
[](https://github.com/CatchTheTornado/pdf-extract-api#getting-started-with-docker)
### Prerequisites
[](https://github.com/CatchTheTornado/pdf-extract-api#prerequisites-1)
  * Docker
  * Docker Compose


### Clone the Repository
[](https://github.com/CatchTheTornado/pdf-extract-api#clone-the-repository-1)
```
git clone https://github.com/CatchTheTornado/text-extract-api.git
cd text-extract-api
```

### Using `Makefile`
[](https://github.com/CatchTheTornado/pdf-extract-api#using-makefile)
You can use the `make install` and `make run` commands to set up the Docker environment for `text-extract-api`. You can find the manual steps required to do so described below.
### Manual setup
[](https://github.com/CatchTheTornado/pdf-extract-api#manual-setup-1)
Create `.env` file in the root directory and set the necessary environment variables. You can use the `.env.example` file as a template:
```
# defaults for docker instances
cp .env.example .env
```

or
```
# defaults for local run
cp .env.example.localhost .env
```

Then modify the variables inside the file:
```
#APP_ENV=production # sets the app into prod mode, otherwise dev mode with auto-reload on code changes
REDIS_CACHE_URL=redis://localhost:6379/1
STORAGE_PROFILE_PATH=./storage_profiles
LLAMA_VISION_PROMPT="You are OCR. Convert image to markdown."
# CLI settings
OCR_URL=http://localhost:8000/ocr/upload
OCR_UPLOAD_URL=http://localhost:8000/ocr/upload
OCR_REQUEST_URL=http://localhost:8000/ocr/request
RESULT_URL=http://localhost:8000/ocr/result/
CLEAR_CACHE_URL=http://localhost:8000/ocr/clear_cache
LLM_PULL_API_URL=http://localhost:8000/llm_pull
LLM_GENERATE_API_URL=http://localhost:8000/llm_generate
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0
OLLAMA_HOST=http://localhost:11434
APP_ENV=development # Default to development mode
```

**Note:** In order to properly save the output files, you might need to modify `storage_profiles/default.yaml` to change the default storage path according to the volumes path defined in the `docker-compose.yml`
### Build and Run the Docker Containers
[](https://github.com/CatchTheTornado/pdf-extract-api#build-and-run-the-docker-containers)
Build and run the Docker containers using Docker Compose:
```
docker-compose up --build
```

... for GPU support run:
```
docker-compose -f docker-compose.gpu.yml -p text-extract-api-gpu up --build
```

**Note:** While on Mac - Docker does not support Apple GPUs. In this case you might want to run the application natively without the Docker Compose please check [how to run it natively with GPU support](https://github.com/CatchTheTornado/pdf-extract-api#getting-started)
This will start the following services:
  * **FastAPI App** : Runs the FastAPI application.
  * **Celery Worker** : Processes asynchronous OCR tasks.
  * **Redis** : Caches OCR results.
  * **Ollama** : Runs the Ollama model.


## Cloud - paid edition
[](https://github.com/CatchTheTornado/pdf-extract-api#cloud---paid-edition)
If the on-prem is too much hassle ask us about the hosted/cloud edition of text-extract-api, we can setup it you, billed just for the usage.
## CLI tool
[](https://github.com/CatchTheTornado/pdf-extract-api#cli-tool)
**Note** : While on Mac, you may need to create a virtual Python environment first:
```
python3 -m venv .venv
source .venv/bin/activate
# now you've got access to `python` and `pip` within your virutal env.
pip install -e . # install main project requirements
```

The project includes a CLI for interacting with the API. To make it work, first run:
```
cd client
pip install -e .
```

### Pull the LLama3.1 and LLama3.2-vision models
[](https://github.com/CatchTheTornado/pdf-extract-api#pull-the-llama31-and-llama32-vision-models)
You might want to test out [different models supported by LLama](https://ollama.com/library)
```
python client/cli.py llm_pull --model llama3.1
python client/cli.py llm_pull --model llama3.2-vision
```

These models are required for most features supported by `text-extract-api`.
### Upload a File for OCR (converting to Markdown)
[](https://github.com/CatchTheTornado/pdf-extract-api#upload-a-file-for-ocr-converting-to-markdown)
```
python client/cli.py ocr_upload --file examples/example-mri.pdf --ocr_cache
```

or alternatively
```
python client/cli.py ocr_request --file examples/example-mri.pdf --ocr_cache
```

The difference is just that the first call uses `ocr/upload` - multipart form data upload, and the second one is a request to `ocr/request` sending the file via base64 encoded JSON property - probable a better suit for smaller files.
### Upload a File for OCR (processing by LLM)
[](https://github.com/CatchTheTornado/pdf-extract-api#upload-a-file-for-ocr-processing-by-llm)
**Important note:** To use LLM you must first run the **llm_pull** to get the specific model required by your requests.
For example, you must run:
```
python client/cli.py llm_pull --model llama3.1
python client/cli.py llm_pull --model llama3.2-vision
```

and only after to run this specific prompt query:
```
python client/cli.py ocr_upload --file examples/example-mri.pdf --ocr_cache --prompt_file=examples/example-mri-remove-pii.txt --language en
```

**Note:** The language argument is used for the OCR strategy to load the model weights for the selected language. You can specify multiple languages as a list: `en,de,pl` etc.
The `ocr` command can store the results using the `storage_profiles`:
  * **storage_profile** : Used to save the result - the `default` profile (`./storage_profiles/default.yaml`) is used by default; if empty file is not saved
  * **storage_filename** : Outputting filename - relative path of the `root_path` set in the storage profile - by default a relative path to `/storage` folder; can use placeholders for dynamic formatting: `{file_name}`, `{file_extension}`, `{Y}`, `{mm}`, `{dd}` - for date formatting, `{HH}`, `{MM}`, `{SS}` - for time formatting


### Upload a File for OCR (processing by LLM), store result on disk
[](https://github.com/CatchTheTornado/pdf-extract-api#upload-a-file-for-ocr-processing-by-llm-store-result-on-disk)
```
python client/cli.py ocr_upload --file examples/example-mri.pdf --ocr_cache --prompt_file=examples/example-mri-remove-pii.txt --storage_filename "invoices/{Y}/{file_name}-{Y}-{mm}-{dd}.md"
```

### Get OCR Result by Task ID
[](https://github.com/CatchTheTornado/pdf-extract-api#get-ocr-result-by-task-id)
```
python client/cli.py result --task_id {your_task_id_from_upload_step}
```

### List file results archived by `storage_profile`
[](https://github.com/CatchTheTornado/pdf-extract-api#list-file-results-archived-by-storage_profile)
```
python client/cli.py list_files 
```

to use specific (in this case `google drive`) storage profile run:
```
python client/cli.py list_files --storage_profile gdrive
```

### Load file result archived by `storage_profile`
[](https://github.com/CatchTheTornado/pdf-extract-api#load-file-result-archived-by-storage_profile)
```
python client/cli.py load_file --file_name "invoices/2024/example-invoice-2024-10-31-16-33.md"
```

### Delete file result archived by `storage_profile`
[](https://github.com/CatchTheTornado/pdf-extract-api#delete-file-result-archived-by-storage_profile)
```
python client/cli.py delete_file --file_name "invoices/2024/example-invoice-2024-10-31-16-33.md" --storage_profile gdrive
```

or for default profile (local file system):
```
python client/cli.py delete_file --file_name "invoices/2024/example-invoice-2024-10-31-16-33.md" 
```

### Clear OCR Cache
[](https://github.com/CatchTheTornado/pdf-extract-api#clear-ocr-cache)
```
python client/cli.py clear_cache
```

### Test LLama
[](https://github.com/CatchTheTornado/pdf-extract-api#test-llama)
```
python llm_generate --prompt "Your prompt here"
```

## API Clients
[](https://github.com/CatchTheTornado/pdf-extract-api#api-clients)
You might want to use the dedicated API clients to use `text-extract-api`.
### Typescript
[](https://github.com/CatchTheTornado/pdf-extract-api#typescript)
There's a dedicated API client for Typescript - [text-extract-api-client](https://github.com/CatchTheTornado/text-extract-api-client) and the `npm` package by the same name:
```
npm install text-extract-api-client
```

Usage:
```
import { ApiClient, OcrRequest } from 'text-extract-api-client';
const apiClient = new ApiClient('https://api.doctractor.com/', 'doctractor', 'Aekie2ao');
const formData = new FormData();
formData.append('file', fileInput.files[0]);
formData.append('prompt', 'Convert file to JSON and return only JSON'); // if not provided, no LLM transformation will gonna happen - just the OCR
formData.append('strategy', 'llama_vision');
formData.append('model', 'llama3.1');
formData.append('ocr_cache', 'true');
apiClient.uploadFile(formData).then(response => {
  console.log(response);
});
```

## Endpoints
[](https://github.com/CatchTheTornado/pdf-extract-api#endpoints)
### OCR Endpoint via File Upload / multiform data
[](https://github.com/CatchTheTornado/pdf-extract-api#ocr-endpoint-via-file-upload--multiform-data)
  * **URL** : /ocr/upload
  * **Method** : POST
  * **Parameters** : 
    * **file** : PDF, image or Office file to be processed.
    * **strategy** : OCR strategy to use (`llama_vision`, `minicpm_v`, `remote` or `easyocr`). See the [available strategies](https://github.com/CatchTheTornado/pdf-extract-api#text-extract-stratgies)
    * **ocr_cache** : Whether to cache the OCR result (true or false).
    * **prompt** : When provided, will be used for Ollama processing the OCR result
    * **model** : When provided along with the prompt - this model will be used for LLM processing
    * **storage_profile** : Used to save the result - the `default` profile (`./storage_profiles/default.yaml`) is used by default; if empty file is not saved
    * **storage_filename** : Outputting filename - relative path of the `root_path` set in the storage profile - by default a relative path to `/storage` folder; can use placeholders for dynamic formatting: `{file_name}`, `{file_extension}`, `{Y}`, `{mm}`, `{dd}` - for date formatting, `{HH}`, `{MM}`, `{SS}` - for time formatting
    * **language** : One or many (`en` or `en,pl,de`) language codes for the OCR to load the language weights


Example:
```
curl -X POST -H "Content-Type: multipart/form-data" -F "file=@examples/example-mri.pdf" -F "strategy=easyocr" -F "ocr_cache=true" -F "prompt=" -F "model=" "http://localhost:8000/ocr/upload" 
```

### OCR Endpoint via JSON request
[](https://github.com/CatchTheTornado/pdf-extract-api#ocr-endpoint-via-json-request)
  * **URL** : /ocr/request
  * **Method** : POST
  * **Parameters** (JSON body): 
    * **file** : Base64 encoded PDF file content.
    * **strategy** : OCR strategy to use (`llama_vision`, `minicpm_v`, `remote` or `easyocr`). See the [available strategies](https://github.com/CatchTheTornado/pdf-extract-api#text-extract-stratgies)
    * **ocr_cache** : Whether to cache the OCR result (true or false).
    * **prompt** : When provided, will be used for Ollama processing the OCR result.
    * **model** : When provided along with the prompt - this model will be used for LLM processing.
    * **storage_profile** : Used to save the result - the `default` profile (`/storage_profiles/default.yaml`) is used by default; if empty file is not saved.
    * **storage_filename** : Outputting filename - relative path of the `root_path` set in the storage profile - by default a relative path to `/storage` folder; can use placeholders for dynamic formatting: `{file_name}`, `{file_extension}`, `{Y}`, `{mm}`, `{dd}` - for date formatting, `{HH}`, `{MM}`, `{SS}` - for time formatting.
    * **language** : One or many (`en` or `en,pl,de`) language codes for the OCR to load the language weights


Example:
```
curl -X POST "http://localhost:8000/ocr/request" -H "Content-Type: application/json" -d '{
 "file": "<base64-encoded-file-content>",
 "strategy": "easyocr",
 "ocr_cache": true,
 "prompt": "",
 "model": "llama3.1",
 "storage_profile": "default",
 "storage_filename": "example.md"
}'
```

### OCR Result Endpoint
[](https://github.com/CatchTheTornado/pdf-extract-api#ocr-result-endpoint)
  * **URL** : /ocr/result/{task_id}
  * **Method** : GET
  * **Parameters** : 
    * **task_id** : Task ID returned by the OCR endpoint.


Example:
```
curl -X GET "http://localhost:8000/ocr/result/{task_id}"
```

### Clear OCR Cache Endpoint
[](https://github.com/CatchTheTornado/pdf-extract-api#clear-ocr-cache-endpoint)
  * **URL** : /ocr/clear_cache
  * **Method** : POST


Example:
```
curl -X POST "http://localhost:8000/ocr/clear_cache"
```

### Ollama Pull Endpoint
[](https://github.com/CatchTheTornado/pdf-extract-api#ollama-pull-endpoint)
  * **URL** : /llm/pull
  * **Method** : POST
  * **Parameters** : 
    * **model** : Pull the model you are to use first


Example:
```
curl -X POST "http://localhost:8000/llm/pull" -H "Content-Type: application/json" -d '{"model": "llama3.1"}'
```

### Ollama Endpoint
[](https://github.com/CatchTheTornado/pdf-extract-api#ollama-endpoint)
  * **URL** : /llm/generate
  * **Method** : POST
  * **Parameters** : 
    * **prompt** : Prompt for the Ollama model.
    * **model** : Model you like to query


Example:
```
curl -X POST "http://localhost:8000/llm/generate" -H "Content-Type: application/json" -d '{"prompt": "Your prompt here", "model":"llama3.1"}'
```

### List storage files:
[](https://github.com/CatchTheTornado/pdf-extract-api#list-storage-files)
  * **URL:** /storage/list
  * **Method:** GET
  * **Parameters** : 
    * **storage_profile** : Name of the storage profile to use for listing files (default: `default`).


### Download storage file:
[](https://github.com/CatchTheTornado/pdf-extract-api#download-storage-file)
  * **URL:** /storage/load
  * **Method:** GET
  * **Parameters** : 
    * **file_name** : File name to load from the storage
    * **storage_profile** : Name of the storage profile to use for listing files (default: `default`).


### Delete storage file:
[](https://github.com/CatchTheTornado/pdf-extract-api#delete-storage-file)
  * **URL:** /storage/delete
  * **Method:** DELETE
  * **Parameters** : 
    * **file_name** : File name to load from the storage
    * **storage_profile** : Name of the storage profile to use for listing files (default: `default`).


## Storage profiles
[](https://github.com/CatchTheTornado/pdf-extract-api#storage-profiles)
The tool can automatically save the results using different storage strategies and storage profiles. Storage profiles are set in the `/storage_profiles` by a yaml configuration files.
### Local File System
[](https://github.com/CatchTheTornado/pdf-extract-api#local-file-system)
```
strategy: local_filesystem
settings:
 root_path: /storage # The root path where the files will be stored - mount a proper folder in the docker file to match it
 subfolder_names_format: "" # eg: by_months/{Y}-{mm}/
 create_subfolders: true
```

### Google Drive
[](https://github.com/CatchTheTornado/pdf-extract-api#google-drive)
```
strategy: google_drive
settings:
## how to enable GDrive API: https://developers.google.com/drive/api/quickstart/python?hl=pl
 service_account_file: /storage/client_secret_269403342997-290pbjjlb06nbof78sjaj7qrqeakp3t0.apps.googleusercontent.com.json
 folder_id:
```

Where the `service_account_file` is a `json` file with authorization credentials. Please read on how to enable Google Drive API and prepare this authorization file [here](https://developers.google.com/drive/api/quickstart/python?hl=pl).
Note: Service Account is different account that the one you're using for Google workspace (files will not be visible in the UI)
### Amazon S3 - Cloud Object Storage
[](https://github.com/CatchTheTornado/pdf-extract-api#amazon-s3---cloud-object-storage)
```
strategy: aws_s3
settings:
 bucket_name: ${AWS_S3_BUCKET_NAME}
 region: ${AWS_REGION}
 access_key: ${AWS_ACCESS_KEY_ID}
 secret_access_key: ${AWS_SECRET_ACCESS_KEY}
```

#### Requirements for AWS S3 Access Key
[](https://github.com/CatchTheTornado/pdf-extract-api#requirements-for-aws-s3-access-key)
  1. **Access Key Ownership** The access key must belong to an IAM user or role with permissions for S3 operations.
  2. **IAM Policy Example** The IAM policy attached to the user or role must allow the necessary actions. Below is an example of a policy granting access to an S3 bucket:
```
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:ListBucket",
        "s3:DeleteObject"
      ],
      "Resource": [
        "arn:aws:s3:::your-bucket-name",
        "arn:aws:s3:::your-bucket-name/*"
      ]
    }
  ]
}
```



Next, populate the appropriate `.env` file (e.g., .env, .env.localhost) with the required AWS credentials:
```
AWS_ACCESS_KEY_ID=your-access-key-id
AWS_SECRET_ACCESS_KEY=your-secret-access-key
AWS_REGION=your-region
AWS_S3_BUCKET_NAME=your-bucket-name
```

## License
[](https://github.com/CatchTheTornado/pdf-extract-api#license)
This project is licensed under the MIT License. See the [LICENSE](https://github.com/CatchTheTornado/text-extract-api/blob/main/LICENSE) file for details.
## Contact
[](https://github.com/CatchTheTornado/pdf-extract-api#contact)
In case of any questions please contact us at: info@catchthetornado.com
## About
Document (PDF, Word, PPTX ...) extraction and parse API using state of the art modern OCRs + Ollama supported models. Anonymize documents. Remove PII. Convert any document or picture to structured JSON or Markdown 
[demo.doctractor.com](https://demo.doctractor.com "https://demo.doctractor.com")
### Topics
[ api ](https://github.com/topics/api "Topic: api") [ pdf ](https://github.com/topics/pdf "Topic: pdf") [ json ](https://github.com/topics/json "Topic: json") [ ocr ](https://github.com/topics/ocr "Topic: ocr") [ extract ](https://github.com/topics/extract "Topic: extract") [ anonymization ](https://github.com/topics/anonymization "Topic: anonymization") [ pii ](https://github.com/topics/pii "Topic: pii") [ ocr-python ](https://github.com/topics/ocr-python "Topic: ocr-python") [ llm ](https://github.com/topics/llm "Topic: llm")
### Resources
[ Readme ](https://github.com/CatchTheTornado/pdf-extract-api#readme-ov-file)
### License
[ MIT license ](https://github.com/CatchTheTornado/pdf-extract-api#MIT-1-ov-file)
[ Activity](https://github.com/CatchTheTornado/text-extract-api/activity)
[ Custom properties](https://github.com/CatchTheTornado/text-extract-api/custom-properties)
### Stars
[ **2.5k** stars](https://github.com/CatchTheTornado/text-extract-api/stargazers)
### Watchers
[ **12** watching](https://github.com/CatchTheTornado/text-extract-api/watchers)
### Forks
[ **200** forks](https://github.com/CatchTheTornado/text-extract-api/forks)
[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FCatchTheTornado%2Ftext-extract-api&report=CatchTheTornado+%28user%29)
##  [Releases 2](https://github.com/CatchTheTornado/text-extract-api/releases)
[ v0.2.0 Latest  Jan 18, 2025 ](https://github.com/CatchTheTornado/text-extract-api/releases/tag/v0.2.0)
[+ 1 release](https://github.com/CatchTheTornado/text-extract-api/releases)
##  [Packages 0](https://github.com/orgs/CatchTheTornado/packages?repo_name=text-extract-api)
No packages published 
##  [Contributors 9](https://github.com/CatchTheTornado/text-extract-api/graphs/contributors)
  * [ ![@pkarw](https://avatars.githubusercontent.com/u/211899?s=64&v=4) ](https://github.com/pkarw)
  * [ ![@choinek](https://avatars.githubusercontent.com/u/595356?s=64&v=4) ](https://github.com/choinek)
  * [ ![@justinlevi](https://avatars.githubusercontent.com/u/1117989?s=64&v=4) ](https://github.com/justinlevi)
  * [ ![@janoberst](https://avatars.githubusercontent.com/u/19206?s=64&v=4) ](https://github.com/janoberst)
  * [ ![@nick-lai](https://avatars.githubusercontent.com/u/7104395?s=64&v=4) ](https://github.com/nick-lai)
  * [ ![@tengerye](https://avatars.githubusercontent.com/u/15181821?s=64&v=4) ](https://github.com/tengerye)
  * [ ![@hahouari](https://avatars.githubusercontent.com/u/39862612?s=64&v=4) ](https://github.com/hahouari)
  * [ ![@PasaOpasen](https://avatars.githubusercontent.com/u/45700689?s=64&v=4) ](https://github.com/PasaOpasen)
  * [ ![@martwozniak](https://avatars.githubusercontent.com/u/70341086?s=64&v=4) ](https://github.com/martwozniak)


## Languages
  * [ Python 86.7% ](https://github.com/CatchTheTornado/text-extract-api/search?l=python)
  * [ Makefile 5.6% ](https://github.com/CatchTheTornado/text-extract-api/search?l=makefile)
  * [ Shell 4.6% ](https://github.com/CatchTheTornado/text-extract-api/search?l=shell)
  * [ Dockerfile 3.1% ](https://github.com/CatchTheTornado/text-extract-api/search?l=dockerfile)


## Footer
[ ](https://github.com "GitHub") © 2025 GitHub, Inc. 
### Footer navigation
  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
  * [Security](https://github.com/security)
  * [Status](https://www.githubstatus.com/)
  * [Docs](https://docs.github.com/)
  * [Contact](https://support.github.com?tags=dotcom-footer)
  * Manage cookies 
  * Do not share my personal information 


You can’t perform that action at this time. 
