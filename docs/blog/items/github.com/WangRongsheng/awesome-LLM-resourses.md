# ÂéüÂßãURL: https://github.com/WangRongsheng/awesome-LLM-resourses

# ÊäìÂèñÊó∂Èó¥: 2025-03-30 21:24:42

[Skip to content](https://github.com/WangRongsheng/awesome-LLM-resourses#start-of-content)
## Navigation Menu
Toggle navigation
[ ](https://github.com/)
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FWangRongsheng%2Fawesome-LLM-resourses)
  * Product 
    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)
    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)
    * [ Actions Automate any workflow  ](https://github.com/features/actions)
    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)
    * [ Issues Plan and track work  ](https://github.com/features/issues)
    * [ Code Review Manage code changes  ](https://github.com/features/code-review)
    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)
    * [ Code Search Find more, search less  ](https://github.com/features/code-search)
Explore
    * [ All features ](https://github.com/features)
    * [ Documentation ](https://docs.github.com)
    * [ GitHub Skills ](https://skills.github.com)
    * [ Blog ](https://github.blog)
  * Solutions 
By company size
    * [ Enterprises ](https://github.com/enterprise)
    * [ Small and medium teams ](https://github.com/team)
    * [ Startups ](https://github.com/enterprise/startups)
    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)
By use case
    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)
    * [ DevOps ](https://github.com/solutions/use-case/devops)
    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)
    * [ View all use cases ](https://github.com/solutions/use-case)
By industry
    * [ Healthcare ](https://github.com/solutions/industry/healthcare)
    * [ Financial services ](https://github.com/solutions/industry/financial-services)
    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)
    * [ Government ](https://github.com/solutions/industry/government)
    * [ View all industries ](https://github.com/solutions/industry)
[ View all solutions ](https://github.com/solutions)
  * Resources 
Topics
    * [ AI ](https://github.com/resources/articles/ai)
    * [ DevOps ](https://github.com/resources/articles/devops)
    * [ Security ](https://github.com/resources/articles/security)
    * [ Software Development ](https://github.com/resources/articles/software-development)
    * [ View all ](https://github.com/resources/articles)
Explore
    * [ Learning Pathways ](https://resources.github.com/learn/pathways)
    * [ Events & Webinars ](https://resources.github.com)
    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)
    * [ Customer Stories ](https://github.com/customer-stories)
    * [ Partners ](https://partner.github.com)
    * [ Executive Insights ](https://github.com/solutions/executive-insights)
  * Open Source 
    * [ GitHub Sponsors Fund open source developers  ](https://github.com/sponsors)
    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)
Repositories
    * [ Topics ](https://github.com/topics)
    * [ Trending ](https://github.com/trending)
    * [ Collections ](https://github.com/collections)
  * Enterprise 
    * [ Enterprise platform AI-powered developer platform  ](https://github.com/enterprise)
Available add-ons
    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)
    * [ Copilot for business Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)
    * [ Premium Support Enterprise-grade 24/7 support  ](https://github.com/premium-support)
  * [Pricing](https://github.com/pricing)


Search or jump to...
# Search code, repositories, users, issues, pull requests...
Search 
Clear
[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)
#  Provide feedback 
We read every piece of feedback, and take your input very seriously.
Include my email address so I can be contacted
Cancel  Submit feedback 
#  Saved searches 
## Use saved searches to filter your results more quickly
Name
Query
To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). 
Cancel  Create saved search 
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FWangRongsheng%2Fawesome-LLM-resourses)
[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=WangRongsheng%2Fawesome-LLM-resourses) Reseting focus
You signed in with another tab or window. [Reload](https://github.com/WangRongsheng/awesome-LLM-resourses) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/WangRongsheng/awesome-LLM-resourses) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/WangRongsheng/awesome-LLM-resourses) to refresh your session. Dismiss alert
{{ message }}
[ WangRongsheng ](https://github.com/WangRongsheng) / **[awesome-LLM-resourses](https://github.com/WangRongsheng/awesome-LLM-resourses) ** Public
  * [ Notifications ](https://github.com/login?return_to=%2FWangRongsheng%2Fawesome-LLM-resourses) You must be signed in to change notification settings
  * [ Fork 472 ](https://github.com/login?return_to=%2FWangRongsheng%2Fawesome-LLM-resourses)
  * [ Star  4.5k ](https://github.com/login?return_to=%2FWangRongsheng%2Fawesome-LLM-resourses)


üßë‚ÄçüöÄ ÂÖ®‰∏ñÁïåÊúÄÂ•ΩÁöÑLLMËµÑÊñôÊÄªÁªìÔºàÊï∞ÊçÆÂ§ÑÁêÜ„ÄÅÊ®°ÂûãËÆ≠ÁªÉ„ÄÅÊ®°ÂûãÈÉ®ÁΩ≤„ÄÅo1 Ê®°Âûã„ÄÅMCP„ÄÅÂ∞èËØ≠Ë®ÄÊ®°Âûã„ÄÅËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºâ | Summary of the world's best LLM resources. 
[wangrongsheng.github.io/awesome-LLM-resourses/](https://wangrongsheng.github.io/awesome-LLM-resourses/ "https://wangrongsheng.github.io/awesome-LLM-resourses/")
### License
[ Apache-2.0 license ](https://github.com/WangRongsheng/awesome-LLM-resourses/blob/main/LICENSE)
[ 4.5k stars ](https://github.com/WangRongsheng/awesome-LLM-resourses/stargazers) [ 472 forks ](https://github.com/WangRongsheng/awesome-LLM-resourses/forks) [ Branches ](https://github.com/WangRongsheng/awesome-LLM-resourses/branches) [ Tags ](https://github.com/WangRongsheng/awesome-LLM-resourses/tags) [ Activity ](https://github.com/WangRongsheng/awesome-LLM-resourses/activity)
[ Star  ](https://github.com/login?return_to=%2FWangRongsheng%2Fawesome-LLM-resourses)
[ Notifications ](https://github.com/login?return_to=%2FWangRongsheng%2Fawesome-LLM-resourses) You must be signed in to change notification settings
  * [ Code ](https://github.com/WangRongsheng/awesome-LLM-resourses)
  * [ Issues 0 ](https://github.com/WangRongsheng/awesome-LLM-resourses/issues)
  * [ Pull requests 1 ](https://github.com/WangRongsheng/awesome-LLM-resourses/pulls)
  * [ Actions ](https://github.com/WangRongsheng/awesome-LLM-resourses/actions)
  * [ Security ](https://github.com/WangRongsheng/awesome-LLM-resourses/security)
  * [ Insights ](https://github.com/WangRongsheng/awesome-LLM-resourses/pulse)


Additional navigation options
  * [ Code  ](https://github.com/WangRongsheng/awesome-LLM-resourses)
  * [ Issues  ](https://github.com/WangRongsheng/awesome-LLM-resourses/issues)
  * [ Pull requests  ](https://github.com/WangRongsheng/awesome-LLM-resourses/pulls)
  * [ Actions  ](https://github.com/WangRongsheng/awesome-LLM-resourses/actions)
  * [ Security  ](https://github.com/WangRongsheng/awesome-LLM-resourses/security)
  * [ Insights  ](https://github.com/WangRongsheng/awesome-LLM-resourses/pulse)


# WangRongsheng/awesome-LLM-resourses
main
[Branches](https://github.com/WangRongsheng/awesome-LLM-resourses/branches)[Tags](https://github.com/WangRongsheng/awesome-LLM-resourses/tags)
[](https://github.com/WangRongsheng/awesome-LLM-resourses/branches)[](https://github.com/WangRongsheng/awesome-LLM-resourses/tags)
Go to file
Code
## Folders and files
Name| Name| Last commit message| Last commit date  
---|---|---|---  
## Latest commit
## History
[455 Commits](https://github.com/WangRongsheng/awesome-LLM-resourses/commits/main/)[](https://github.com/WangRongsheng/awesome-LLM-resourses/commits/main/)  
[assets](https://github.com/WangRongsheng/awesome-LLM-resourses/tree/main/assets "assets")| [assets](https://github.com/WangRongsheng/awesome-LLM-resourses/tree/main/assets "assets")  
[docs](https://github.com/WangRongsheng/awesome-LLM-resourses/tree/main/docs "docs")| [docs](https://github.com/WangRongsheng/awesome-LLM-resourses/tree/main/docs "docs")  
[CODE_OF_CONDUCT.md](https://github.com/WangRongsheng/awesome-LLM-resourses/blob/main/CODE_OF_CONDUCT.md "CODE_OF_CONDUCT.md")| [CODE_OF_CONDUCT.md](https://github.com/WangRongsheng/awesome-LLM-resourses/blob/main/CODE_OF_CONDUCT.md "CODE_OF_CONDUCT.md")  
[LICENSE](https://github.com/WangRongsheng/awesome-LLM-resourses/blob/main/LICENSE "LICENSE")| [LICENSE](https://github.com/WangRongsheng/awesome-LLM-resourses/blob/main/LICENSE "LICENSE")  
[README.md](https://github.com/WangRongsheng/awesome-LLM-resourses/blob/main/README.md "README.md")| [README.md](https://github.com/WangRongsheng/awesome-LLM-resourses/blob/main/README.md "README.md")  
[_config.yml](https://github.com/WangRongsheng/awesome-LLM-resourses/blob/main/_config.yml "_config.yml")| [_config.yml](https://github.com/WangRongsheng/awesome-LLM-resourses/blob/main/_config.yml "_config.yml")  
View all files  
## Repository files navigation
  * [README](https://github.com/WangRongsheng/awesome-LLM-resourses)
  * [Code of conduct](https://github.com/WangRongsheng/awesome-LLM-resourses)
  * [Apache-2.0 license](https://github.com/WangRongsheng/awesome-LLM-resourses)


[![](https://github.com/WangRongsheng/awesome-LLM-resourses/raw/main/assets/logo2.png)](https://github.com/WangRongsheng/awesome-LLM-resourses/blob/main/assets/logo2.png)
ÂÖ®‰∏ñÁïåÊúÄÂ•ΩÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãËµÑÊ∫êÊ±áÊÄª ÊåÅÁª≠Êõ¥Êñ∞
[![Flag Counter](https://camo.githubusercontent.com/17b67a80eb85e4965e2381b97c6c12e9574a67096618e13df2ec0726d0c64c73/68747470733a2f2f7331312e666c6167636f756e7465722e636f6d2f636f756e74322f5536596e2f62675f4646464646462f7478745f3030303030302f626f726465725f4343434343432f636f6c756d6e735f322f6d6178666c6167735f31302f766965776572735f302f6c6162656c735f312f7061676576696577735f302f666c6167735f302f70657263656e745f302f)](https://info.flagcounter.com/U6Yn)
Check More Information
[![](https://camo.githubusercontent.com/8693bde04030b1670d5097703441005eba34240c32d1df1eb82a5f0d6716518e/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667)](https://github.com/WangRongsheng/awesome-LLM-resourses) [![](https://camo.githubusercontent.com/e9bcd940ce509c6d768576c19f33b3035565ac93f039e50b20984d76b047e849/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f57616e67526f6e677368656e672f617765736f6d652d4c4c4d2d7265736f75727365732e7376673f7374796c653d736f6369616c)](https://github.com/WangRongsheng/awesome-LLM-resourses) [![](https://camo.githubusercontent.com/214d37895bb6f8e02b5d20838a6c63d0a8a8046f549d4fb14d91be8ed2befabe/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f57616e67526f6e677368656e672f617765736f6d652d4c4c4d2d7265736f75727365732e7376673f7374796c653d736f6369616c)](https://github.com/WangRongsheng/awesome-LLM-resourses) [![](https://camo.githubusercontent.com/265c62858cd9994013f4605fcf19f4fac81c92594b904fe3999104994819e178/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f77617463686572732f57616e67526f6e677368656e672f617765736f6d652d4c4c4d2d7265736f75727365732e7376673f7374796c653d736f6369616c)](https://github.com/WangRongsheng/awesome-LLM-resourses)
[[Âú®Á∫øÈòÖËØª]](https://www.wangrs.site/awesome-LLM-resourses/)
[![](https://camo.githubusercontent.com/2722992d519a722218f896d5f5231d49f337aaff4514e78bd59ac935334e916a/68747470733a2f2f692e696d6775722e636f6d2f77617856496d762e706e67)](https://camo.githubusercontent.com/2722992d519a722218f896d5f5231d49f337aaff4514e78bd59ac935334e916a/68747470733a2f2f692e696d6775722e636f6d2f77617856496d762e706e67)
#### Contents
[](https://github.com/WangRongsheng/awesome-LLM-resourses#contents)
  * [Êï∞ÊçÆ Data](https://github.com/WangRongsheng/awesome-LLM-resourses#%E6%95%B0%E6%8D%AE-Data)
  * [ÂæÆË∞É Fine-Tuning](https://github.com/WangRongsheng/awesome-LLM-resourses#%E5%BE%AE%E8%B0%83-Fine-Tuning)
  * [Êé®ÁêÜ Inference](https://github.com/WangRongsheng/awesome-LLM-resourses#%E6%8E%A8%E7%90%86-Inference)
  * [ËØÑ‰º∞ Evaluation](https://github.com/WangRongsheng/awesome-LLM-resourses#%E8%AF%84%E4%BC%B0-Evaluation)
  * [‰ΩìÈ™å Usage](https://github.com/WangRongsheng/awesome-LLM-resourses#%E4%BD%93%E9%AA%8C-Usage)
  * [Áü•ËØÜÂ∫ì RAG](https://github.com/WangRongsheng/awesome-LLM-resourses#%E7%9F%A5%E8%AF%86%E5%BA%93-RAG)
  * [Êô∫ËÉΩ‰Ωì Agents](https://github.com/WangRongsheng/awesome-LLM-resourses#%E6%99%BA%E8%83%BD%E4%BD%93-Agents)
  * [ÊêúÁ¥¢ Search](https://github.com/WangRongsheng/awesome-LLM-resourses#%E6%90%9C%E7%B4%A2-Search)
  * [‰π¶Á±ç Book](https://github.com/WangRongsheng/awesome-LLM-resourses#%E4%B9%A6%E7%B1%8D-Book)
  * [ËØæÁ®ã Course](https://github.com/WangRongsheng/awesome-LLM-resourses#%E8%AF%BE%E7%A8%8B-Course)
  * [ÊïôÁ®ã Tutorial](https://github.com/WangRongsheng/awesome-LLM-resourses#%E6%95%99%E7%A8%8B-Tutorial)
  * [ËÆ∫Êñá Paper](https://github.com/WangRongsheng/awesome-LLM-resourses#%E8%AE%BA%E6%96%87-Paper)
  * [Á§æÂå∫ Community](https://github.com/WangRongsheng/awesome-LLM-resourses#%E7%A4%BE%E5%8C%BA-Community)
  * [MCP](https://github.com/WangRongsheng/awesome-LLM-resourses#MCP)
  * [Open o1](https://github.com/WangRongsheng/awesome-LLM-resourses#Open-o1)
  * [Small Language Model](https://github.com/WangRongsheng/awesome-LLM-resourses#Small-Language-Model)
  * [Small Vision Language Model](https://github.com/WangRongsheng/awesome-LLM-resourses#Small-Vision-Language-Model)
  * [Tips](https://github.com/WangRongsheng/awesome-LLM-resourses#tips)


[![](https://camo.githubusercontent.com/2722992d519a722218f896d5f5231d49f337aaff4514e78bd59ac935334e916a/68747470733a2f2f692e696d6775722e636f6d2f77617856496d762e706e67)](https://camo.githubusercontent.com/2722992d519a722218f896d5f5231d49f337aaff4514e78bd59ac935334e916a/68747470733a2f2f692e696d6775722e636f6d2f77617856496d762e706e67)
## Êï∞ÊçÆ Data
[](https://github.com/WangRongsheng/awesome-LLM-resourses#Êï∞ÊçÆ-data)
Note
Ê≠§Â§ÑÂëΩÂêç‰∏∫`Êï∞ÊçÆ`Ôºå‰ΩÜËøôÈáåÂπ∂Ê≤°ÊúâÊèê‰æõÂÖ∑‰ΩìÊï∞ÊçÆÈõÜÔºåËÄåÊòØÊèê‰æõ‰∫ÜÂ§ÑÁêÜËé∑ÂèñÂ§ßËßÑÊ®°Êï∞ÊçÆÁöÑÊñπÊ≥ï
  1. [AotoLabel](https://github.com/refuel-ai/autolabel): Label, clean and enrich text datasets with LLMs.
  2. [LabelLLM](https://github.com/opendatalab/LabelLLM): The Open-Source Data Annotation Platform.
  3. [data-juicer](https://github.com/modelscope/data-juicer): A one-stop data processing system to make data higher-quality, juicier, and more digestible for LLMs!
  4. [OmniParser](https://github.com/jf-tech/omniparser): a native Golang ETL streaming parser and transform library for CSV, JSON, XML, EDI, text, etc.
  5. [MinerU](https://github.com/opendatalab/MinerU): MinerU is a one-stop, open-source, high-quality data extraction tool, supports PDF/webpage/e-book extraction.
  6. [PDF-Extract-Kit](https://github.com/opendatalab/PDF-Extract-Kit): A Comprehensive Toolkit for High-Quality PDF Content Extraction.
  7. [Parsera](https://github.com/raznem/parsera): Lightweight library for scraping web-sites with LLMs.
  8. [Sparrow](https://github.com/katanaml/sparrow): Sparrow is an innovative open-source solution for efficient data extraction and processing from various documents and images.
  9. [Docling](https://github.com/DS4SD/docling): Get your documents ready for gen AI.
  10. [GOT-OCR2.0](https://github.com/Ucas-HaoranWei/GOT-OCR2.0): OCR Model.
  11. [LLM Decontaminator](https://github.com/lm-sys/llm-decontaminator): Rethinking Benchmark and Contamination for Language Models with Rephrased Samples.
  12. [DataTrove](https://github.com/huggingface/datatrove): DataTrove is a library to process, filter and deduplicate text data at a very large scale.
  13. [llm-swarm](https://github.com/huggingface/llm-swarm/tree/main/examples/textbooks): Generate large synthetic datasets like [Cosmopedia](https://huggingface.co/datasets/HuggingFaceTB/cosmopedia).
  14. [Distilabel](https://github.com/argilla-io/distilabel): Distilabel is a framework for synthetic data and AI feedback for engineers who need fast, reliable and scalable pipelines based on verified research papers.
  15. [Common-Crawl-Pipeline-Creator](https://huggingface.co/spaces/lhoestq/Common-Crawl-Pipeline-Creator): The Common Crawl Pipeline Creator.
  16. [Tabled](https://github.com/VikParuchuri/tabled): Detect and extract tables to markdown and csv.
  17. [Zerox](https://github.com/getomni-ai/zerox): Zero shot pdf OCR with gpt-4o-mini.
  18. [DocLayout-YOLO](https://github.com/opendatalab/DocLayout-YOLO): Enhancing Document Layout Analysis through Diverse Synthetic Data and Global-to-Local Adaptive Perception.
  19. [TensorZero](https://github.com/tensorzero/tensorzero): make LLMs improve through experience.
  20. [Promptwright](https://github.com/StacklokLabs/promptwright): Generate large synthetic data using a local LLM.
  21. [pdf-extract-api](https://github.com/CatchTheTornado/pdf-extract-api): Document (PDF) extraction and parse API using state of the art modern OCRs + Ollama supported models.
  22. [pdf2htmlEX](https://github.com/pdf2htmlEX/pdf2htmlEX): Convert PDF to HTML without losing text or format.
  23. [Extractous](https://github.com/yobix-ai/extractous): Fast and efficient unstructured data extraction. Written in Rust with bindings for many languages.
  24. [MegaParse](https://github.com/QuivrHQ/MegaParse): File Parser optimised for LLM Ingestion with no loss.
  25. [MarkItDown](https://github.com/microsoft/markitdown): Python tool for converting files and office documents to Markdown.
  26. [datasketch](https://github.com/ekzhu/datasketch): datasketch gives you probabilistic data structures that can process and search very large amount of data super fast, with little loss of accuracy.
  27. [semhash](https://github.com/MinishLab/semhash): lightweight and flexible tool for deduplicating datasets using semantic similarity.
  28. [ReaderLM-v2](https://huggingface.co/jinaai/ReaderLM-v2): a 1.5B parameter language model that converts raw HTML into beautifully formatted markdown or JSON.
  29. [Bespoke Curator](https://github.com/bespokelabsai/curator): Data Curation for Post-Training & Structured Data Extraction.
  30. [LangKit](https://github.com/whylabs/langkit): An open-source toolkit for monitoring Large Language Models (LLMs). Extracts signals from prompts & responses, ensuring safety & security.
  31. [Curator](https://github.com/bespokelabsai/curator): Synthetic Data curation for post-training and structured data extraction.
  32. [olmOCR](https://github.com/allenai/olmocr): A toolkit for training language models to work with PDF documents in the wild.
  33. [Easy Dataset](https://github.com/ConardLi/easy-dataset): A powerful tool for creating fine-tuning datasets for LLM.


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## ÂæÆË∞É Fine-Tuning
[](https://github.com/WangRongsheng/awesome-LLM-resourses#ÂæÆË∞É-fine-tuning)
  1. [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory): Unify Efficient Fine-Tuning of 100+ LLMs.
  2. [360-LLaMA-Factory](https://github.com/Qihoo360/360-LLaMA-Factory): Unify Efficient Fine-Tuning of 100+ LLMs. (add Sequence Parallelism for supporting long context training)
  3. [unsloth](https://github.com/unslothai/unsloth): 2-5X faster 80% less memory LLM finetuning.
  4. [TRL](https://huggingface.co/docs/trl/index): Transformer Reinforcement Learning.
  5. [Firefly](https://github.com/yangjianxin1/Firefly): Firefly: Â§ßÊ®°ÂûãËÆ≠ÁªÉÂ∑•ÂÖ∑ÔºåÊîØÊåÅËÆ≠ÁªÉÊï∞ÂçÅÁßçÂ§ßÊ®°Âûã
  6. [Xtuner](https://github.com/InternLM/xtuner): An efficient, flexible and full-featured toolkit for fine-tuning large models.
  7. [torchtune](https://github.com/pytorch/torchtune): A Native-PyTorch Library for LLM Fine-tuning.
  8. [Swift](https://github.com/modelscope/swift): Use PEFT or Full-parameter to finetune 200+ LLMs or 15+ MLLMs.
  9. [AutoTrain](https://huggingface.co/autotrain): A new way to automatically train, evaluate and deploy state-of-the-art Machine Learning models.
  10. [OpenRLHF](https://github.com/OpenLLMAI/OpenRLHF): An Easy-to-use, Scalable and High-performance RLHF Framework (Support 70B+ full tuning & LoRA & Mixtral & KTO).
  11. [Ludwig](https://github.com/ludwig-ai/ludwig): Low-code framework for building custom LLMs, neural networks, and other AI models.
  12. [mistral-finetune](https://github.com/mistralai/mistral-finetune): A light-weight codebase that enables memory-efficient and performant finetuning of Mistral's models.
  13. [aikit](https://github.com/sozercan/aikit): Fine-tune, build, and deploy open-source LLMs easily!
  14. [H2O-LLMStudio](https://github.com/h2oai/h2o-llmstudio): H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs.
  15. [LitGPT](https://github.com/Lightning-AI/litgpt): Pretrain, finetune, deploy 20+ LLMs on your own data. Uses state-of-the-art techniques: flash attention, FSDP, 4-bit, LoRA, and more.
  16. [LLMBox](https://github.com/RUCAIBox/LLMBox): A comprehensive library for implementing LLMs, including a unified training pipeline and comprehensive model evaluation.
  17. [PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP): Easy-to-use and powerful NLP and LLM library.
  18. [workbench-llamafactory](https://github.com/NVIDIA/workbench-llamafactory): This is an NVIDIA AI Workbench example project that demonstrates an end-to-end model development workflow using Llamafactory.
  19. [OpenRLHF](https://github.com/OpenLLMAI/OpenRLHF): An Easy-to-use, Scalable and High-performance RLHF Framework (70B+ PPO Full Tuning & Iterative DPO & LoRA & Mixtral).
  20. [TinyLLaVA Factory](https://github.com/TinyLLaVA/TinyLLaVA_Factory): A Framework of Small-scale Large Multimodal Models.
  21. [LLM-Foundry](https://github.com/mosaicml/llm-foundry): LLM training code for Databricks foundation models.
  22. [lmms-finetune](https://github.com/zjysteven/lmms-finetune): A unified codebase for finetuning (full, lora) large multimodal models, supporting llava-1.5, qwen-vl, llava-interleave, llava-next-video, phi3-v etc.
  23. [Simplifine](https://github.com/simplifine-llm/Simplifine): Simplifine lets you invoke LLM finetuning with just one line of code using any Hugging Face dataset or model.
  24. [Transformer Lab](https://github.com/transformerlab/transformerlab-app): Open Source Application for Advanced LLM Engineering: interact, train, fine-tune, and evaluate large language models on your own computer.
  25. [Liger-Kernel](https://github.com/linkedin/Liger-Kernel): Efficient Triton Kernels for LLM Training.
  26. [ChatLearn](https://github.com/alibaba/ChatLearn): A flexible and efficient training framework for large-scale alignment.
  27. [nanotron](https://github.com/huggingface/nanotron): Minimalistic large language model 3D-parallelism training.
  28. [Proxy Tuning](https://github.com/alisawuffles/proxy-tuning): Tuning Language Models by Proxy.
  29. [Effective LLM Alignment](https://github.com/VikhrModels/effective_llm_alignment/): Effective LLM Alignment Toolkit.
  30. [Autotrain-advanced](https://github.com/huggingface/autotrain-advanced)
  31. [Meta Lingua](https://github.com/facebookresearch/lingua): a lean, efficient, and easy-to-hack codebase to research LLMs.
  32. [Vision-LLM Alignemnt](https://github.com/NiuTrans/Vision-LLM-Alignment): This repository contains the code for SFT, RLHF, and DPO, designed for vision-based LLMs, including the LLaVA models and the LLaMA-3.2-vision models.
  33. [finetune-Qwen2-VL](https://github.com/zhangfaen/finetune-Qwen2-VL): Quick Start for Fine-tuning or continue pre-train Qwen2-VL Model.
  34. [Online-RLHF](https://github.com/RLHFlow/Online-RLHF): A recipe for online RLHF and online iterative DPO.
  35. [InternEvo](https://github.com/InternLM/InternEvo): an open-sourced lightweight training framework aims to support model pre-training without the need for extensive dependencies.
  36. [veRL](https://github.com/volcengine/verl): Volcano Engine Reinforcement Learning for LLM.
  37. [Axolotl](https://axolotl-ai-cloud.github.io/axolotl/): Axolotl is designed to work with YAML config files that contain everything you need to preprocess a dataset, train or fine-tune a model, run model inference or evaluation, and much more.
  38. [Oumi](https://github.com/oumi-ai/oumi): Everything you need to build state-of-the-art foundation models, end-to-end.
  39. [Kiln](https://github.com/Kiln-AI/Kiln): The easiest tool for fine-tuning LLM models, synthetic data generation, and collaborating on datasets.
  40. [DeepSeek-671B-SFT-Guide](https://github.com/ScienceOne-AI/DeepSeek-671B-SFT-Guide): An open-source solution for full parameter fine-tuning of DeepSeek-V3/R1 671B, including complete code and scripts from training to inference, as well as some practical experiences and conclusions.
  41. [MLX-VLM](https://github.com/Blaizzy/mlx-vlm): MLX-VLM is a package for inference and fine-tuning of Vision Language Models (VLMs) on your Mac using MLX.


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## Êé®ÁêÜ Inference
[](https://github.com/WangRongsheng/awesome-LLM-resourses#Êé®ÁêÜ-inference)
  1. [ollama](https://github.com/ollama/ollama): Get up and running with Llama 3, Mistral, Gemma, and other large language models.
  2. [Open WebUI](https://github.com/open-webui/open-webui): User-friendly WebUI for LLMs (Formerly Ollama WebUI).
  3. [Text Generation WebUI](https://github.com/oobabooga/text-generation-webui): A Gradio web UI for Large Language Models. Supports transformers, GPTQ, AWQ, EXL2, llama.cpp (GGUF), Llama models.
  4. [Xinference](https://github.com/xorbitsai/inference): A powerful and versatile library designed to serve language, speech recognition, and multimodal models.
  5. [LangChain](https://github.com/langchain-ai/langchain): Build context-aware reasoning applications.
  6. [LlamaIndex](https://github.com/run-llama/llama_index): A data framework for your LLM applications.
  7. [lobe-chat](https://github.com/lobehub/lobe-chat): an open-source, modern-design LLMs/AI chat framework. Supports Multi AI Providers, Multi-Modals (Vision/TTS) and plugin system.
  8. [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM): TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs.
  9. [vllm](https://github.com/vllm-project/vllm): A high-throughput and memory-efficient inference and serving engine for LLMs.
  10. [LlamaChat](https://github.com/alexrozanski/LlamaChat): Chat with your favourite LLaMA models in a native macOS app.
  11. [NVIDIA ChatRTX](https://www.nvidia.com/en-us/ai-on-rtx/chatrtx/): ChatRTX is a demo app that lets you personalize a GPT large language model (LLM) connected to your own content‚Äîdocs, notes, or other data.
  12. [LM Studio](https://lmstudio.ai/): Discover, download, and run local LLMs.
  13. [chat-with-mlx](https://github.com/qnguyen3/chat-with-mlx): Chat with your data natively on Apple Silicon using MLX Framework.
  14. [LLM Pricing](https://llmpricecheck.com/): Quickly Find the Perfect Large Language Models (LLM) API for Your Budget! Use Our Free Tool for Instant Access to the Latest Prices from Top Providers.
  15. [Open Interpreter](https://github.com/OpenInterpreter/open-interpreter): A natural language interface for computers.
  16. [Chat-ollama](https://github.com/sugarforever/chat-ollama): An open source chatbot based on LLMs. It supports a wide range of language models, and knowledge base management.
  17. [chat-ui](https://github.com/huggingface/chat-ui): Open source codebase powering the HuggingChat app.
  18. [MemGPT](https://github.com/cpacker/MemGPT): Create LLM agents with long-term memory and custom tools.
  19. [koboldcpp](https://github.com/LostRuins/koboldcpp): A simple one-file way to run various GGML and GGUF models with KoboldAI's UI.
  20. [LLMFarm](https://github.com/guinmoon/LLMFarm): llama and other large language models on iOS and MacOS offline using GGML library.
  21. [enchanted](https://github.com/AugustDev/enchanted): Enchanted is iOS and macOS app for chatting with private self hosted language models such as Llama2, Mistral or Vicuna using Ollama.
  22. [Flowise](https://github.com/FlowiseAI/Flowise): Drag & drop UI to build your customized LLM flow.
  23. [Jan](https://github.com/janhq/jan): Jan is an open source alternative to ChatGPT that runs 100% offline on your computer. Multiple engine support (llama.cpp, TensorRT-LLM).
  24. [LMDeploy](https://github.com/InternLM/lmdeploy): LMDeploy is a toolkit for compressing, deploying, and serving LLMs.
  25. [RouteLLM](https://github.com/lm-sys/RouteLLM): A framework for serving and evaluating LLM routers - save LLM costs without compromising quality!
  26. [MInference](https://github.com/microsoft/MInference): About To speed up Long-context LLMs' inference, approximate and dynamic sparse calculate the attention, which reduces inference latency by up to 10x for pre-filling on an A100 while maintaining accuracy.
  27. [Mem0](https://github.com/mem0ai/mem0): The memory layer for Personalized AI.
  28. [SGLang](https://github.com/sgl-project/sglang): SGLang is yet another fast serving framework for large language models and vision language models.
  29. [AirLLM](https://github.com/lyogavin/airllm): AirLLM optimizes inference memory usage, allowing 70B large language models to run inference on a single 4GB GPU card without quantization, distillation and pruning. And you can run 405B Llama3.1 on 8GB vram now.
  30. [LLMHub](https://github.com/jmather/llmhub): LLMHub is a lightweight management platform designed to streamline the operation and interaction with various language models (LLMs).
  31. [YuanChat](https://github.com/IEIT-Yuan/YuanChat)
  32. [LiteLLM](https://github.com/BerriAI/litellm): Call all LLM APIs using the OpenAI format [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.]
  33. [GuideLLM](https://github.com/neuralmagic/guidellm): GuideLLM is a powerful tool for evaluating and optimizing the deployment of large language models (LLMs).
  34. [LLM-Engines](https://github.com/jdf-prog/LLM-Engines): A unified inference engine for large language models (LLMs) including open-source models (VLLM, SGLang, Together) and commercial models (OpenAI, Mistral, Claude).
  35. [OARC](https://github.com/Leoleojames1/ollama_agent_roll_cage): ollama_agent_roll_cage (OARC) is a local python agent fusing ollama llm's with Coqui-TTS speech models, Keras classifiers, Llava vision, Whisper recognition, and more to create a unified chatbot agent for local, custom automation.
  36. [g1](https://github.com/bklieger-groq/g1): Using Llama-3.1 70b on Groq to create o1-like reasoning chains.
  37. [MemoryScope](https://github.com/modelscope/MemoryScope): MemoryScope provides LLM chatbots with powerful and flexible long-term memory capabilities, offering a framework for building such abilities.
  38. [OpenLLM](https://github.com/bentoml/OpenLLM): Run any open-source LLMs, such as Llama 3.1, Gemma, as OpenAI compatible API endpoint in the cloud.
  39. [Infinity](https://github.com/infiniflow/infinity): The AI-native database built for LLM applications, providing incredibly fast hybrid search of dense embedding, sparse embedding, tensor and full-text.
  40. [optillm](https://github.com/codelion/optillm): an OpenAI API compatible optimizing inference proxy which implements several state-of-the-art techniques that can improve the accuracy and performance of LLMs.
  41. [LLaMA Box](https://github.com/gpustack/llama-box): LLM inference server implementation based on llama.cpp.
  42. [ZhiLight](https://github.com/zhihu/ZhiLight): A highly optimized inference acceleration engine for Llama and its variants.
  43. [DashInfer](https://github.com/modelscope/dash-infer): DashInfer is a native LLM inference engine aiming to deliver industry-leading performance atop various hardware architectures.
  44. [LocalAI](https://github.com/mudler/LocalAI): The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required.
  45. [ktransformers](https://github.com/kvcache-ai/ktransformers): A Flexible Framework for Experiencing Cutting-edge LLM Inference Optimizations.
  46. [SkyPilot](https://github.com/skypilot-org/skypilot): Run AI and batch jobs on any infra (Kubernetes or 14+ clouds). Get unified execution, cost savings, and high GPU availability via a simple interface.
  47. [Chitu](https://github.com/thu-pacman/chitu): High-performance inference framework for large language models, focusing on efficiency, flexibility, and availability.


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## ËØÑ‰º∞ Evaluation
[](https://github.com/WangRongsheng/awesome-LLM-resourses#ËØÑ‰º∞-evaluation)
  1. [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness): A framework for few-shot evaluation of language models.
  2. [opencompass](https://github.com/open-compass/opencompass): OpenCompass is an LLM evaluation platform, supporting a wide range of models (Llama3, Mistral, InternLM2,GPT-4,LLaMa2, Qwen,GLM, Claude, etc) over 100+ datasets.
  3. [llm-comparator](https://github.com/PAIR-code/llm-comparator): LLM Comparator is an interactive data visualization tool for evaluating and analyzing LLM responses side-by-side, developed.
  4. [EvalScope](https://github.com/modelscope/evalscope)
  5. [Weave](https://weave-docs.wandb.ai/guides/core-types/evaluations): A lightweight toolkit for tracking and evaluating LLM applications.
  6. [MixEval](https://github.com/Psycoy/MixEval/): Deriving Wisdom of the Crowd from LLM Benchmark Mixtures.
  7. [Evaluation guidebook](https://github.com/huggingface/evaluation-guidebook): If you've ever wondered how to make sure an LLM performs well on your specific task, this guide is for you!
  8. [Ollama Benchmark](https://github.com/aidatatools/ollama-benchmark): LLM Benchmark for Throughput via Ollama (Local LLMs).
  9. [VLMEvalKit](https://github.com/open-compass/VLMEvalKit): Open-source evaluation toolkit of large vision-language models (LVLMs), support ~100 VLMs, 40+ benchmarks.
  10. [AGI-Eval](https://agi-eval.cn/mvp/home)
  11. [EvalScope](https://github.com/modelscope/evalscope): A streamlined and customizable framework for efficient large model evaluation and performance benchmarking.
  12. [DeepEval](https://github.com/confident-ai/deepeval): a simple-to-use, open-source LLM evaluation framework, for evaluating and testing large-language model systems.
  13. [Lighteval](https://github.com/huggingface/lighteval): Lighteval is your all-in-one toolkit for evaluating LLMs across multiple backends.
  14. [QwQ/eval](https://github.com/QwenLM/QwQ/tree/main/eval): QwQ is the reasoning model series developed by Qwen team, Alibaba Cloud.


`LLM API ÊúçÂä°Âπ≥Âè∞`Ôºö
  1. [Groq](https://groq.com/)
  2. [Á°ÖÂü∫ÊµÅÂä®](https://cloud.siliconflow.cn/models)
  3. [ÁÅ´Â±±ÂºïÊìé](https://www.volcengine.com/product/ark)
  4. [ÊñáÂøÉÂçÉÂ∏Ü](https://qianfan.cloud.baidu.com/)
  5. [DashScope](https://dashscope.aliyun.com/)
  6. [aisuite](https://github.com/andrewyng/aisuite)
  7. [DeerAPI](https://www.deerapi.com/)
  8. [Qwen-Chat](https://chat.qwenlm.ai/)
  9. [DeepSeek-v3](https://www.deepseek.com/)


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## ‰ΩìÈ™å Usage
[](https://github.com/WangRongsheng/awesome-LLM-resourses#‰ΩìÈ™å-usage)
  1. [LMSYS Chatbot Arena: Benchmarking LLMs in the Wild](https://arena.lmsys.org/)
  2. [CompassArena Âè∏ÂçóÂ§ßÊ®°ÂûãÁ´ûÊäÄÂú∫](https://modelscope.cn/studios/opencompass/CompassArena/summary)
  3. [ÁêÖÁêäÊ¶ú](https://langyb.com/)
  4. [Huggingface Spaces](https://huggingface.co/spaces)
  5. [WiseModel Spaces](https://wisemodel.cn/spaces)
  6. [Poe](https://poe.com/)
  7. [ÊûóÂì•ÁöÑÂ§ßÊ®°ÂûãÈáéÊ¶ú](https://lyihub.com/)
  8. [OpenRouter](https://openrouter.ai/)
  9. [AnyChat](https://huggingface.co/spaces/akhaliq/anychat)


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## Áü•ËØÜÂ∫ì RAG
[](https://github.com/WangRongsheng/awesome-LLM-resourses#Áü•ËØÜÂ∫ì-rag)
  1. [AnythingLLM](https://github.com/Mintplex-Labs/anything-llm): The all-in-one AI app for any LLM with full RAG and AI Agent capabilites.
  2. [MaxKB](https://github.com/1Panel-dev/MaxKB): Âü∫‰∫é LLM Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÁü•ËØÜÂ∫ìÈóÆÁ≠îÁ≥ªÁªü„ÄÇÂºÄÁÆ±Âç≥Áî®ÔºåÊîØÊåÅÂø´ÈÄüÂµåÂÖ•Âà∞Á¨¨‰∏âÊñπ‰∏öÂä°Á≥ªÁªü
  3. [RAGFlow](https://github.com/infiniflow/ragflow): An open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding.
  4. [Dify](https://github.com/langgenius/dify): An open-source LLM app development platform. Dify's intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production.
  5. [FastGPT](https://github.com/labring/FastGPT): A knowledge-based platform built on the LLM, offers out-of-the-box data processing and model invocation capabilities, allows for workflow orchestration through Flow visualization.
  6. [Langchain-Chatchat](https://github.com/chatchat-space/Langchain-Chatchat): Âü∫‰∫é Langchain ‰∏é ChatGLM Á≠â‰∏çÂêåÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊú¨Âú∞Áü•ËØÜÂ∫ìÈóÆÁ≠î
  7. [QAnything](https://github.com/netease-youdao/QAnything): Question and Answer based on Anything.
  8. [Quivr](https://github.com/QuivrHQ/quivr): A personal productivity assistant (RAG) ‚ö°Ô∏èü§ñ Chat with your docs (PDF, CSV, ...) & apps using Langchain, GPT 3.5 / 4 turbo, Private, Anthropic, VertexAI, Ollama, LLMs, Groq that you can share with users ! Local & Private alternative to OpenAI GPTs & ChatGPT powered by retrieval-augmented generation.
  9. [RAG-GPT](https://github.com/open-kf/rag-gpt): RAG-GPT, leveraging LLM and RAG technology, learns from user-customized knowledge bases to provide contextually relevant answers for a wide range of queries, ensuring rapid and accurate information retrieval.
  10. [Verba](https://github.com/weaviate/Verba): Retrieval Augmented Generation (RAG) chatbot powered by Weaviate.
  11. [FlashRAG](https://github.com/RUC-NLPIR/FlashRAG): A Python Toolkit for Efficient RAG Research.
  12. [GraphRAG](https://github.com/microsoft/graphrag): A modular graph-based Retrieval-Augmented Generation (RAG) system.
  13. [LightRAG](https://github.com/SylphAI-Inc/LightRAG): LightRAG helps developers with both building and optimizing Retriever-Agent-Generator pipelines.
  14. [GraphRAG-Ollama-UI](https://github.com/severian42/GraphRAG-Ollama-UI): GraphRAG using Ollama with Gradio UI and Extra Features.
  15. [nano-GraphRAG](https://github.com/gusye1234/nano-graphrag): A simple, easy-to-hack GraphRAG implementation.
  16. [RAG Techniques](https://github.com/NirDiamant/RAG_Techniques): This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.
  17. [ragas](https://github.com/explodinggradients/ragas): Evaluation framework for your Retrieval Augmented Generation (RAG) pipelines.
  18. [kotaemon](https://github.com/Cinnamon/kotaemon): An open-source clean & customizable RAG UI for chatting with your documents. Built with both end users and developers in mind.
  19. [RAGapp](https://github.com/ragapp/ragapp): The easiest way to use Agentic RAG in any enterprise.
  20. [TurboRAG](https://github.com/MooreThreads/TurboRAG): Accelerating Retrieval-Augmented Generation with Precomputed KV Caches for Chunked Text.
  21. [LightRAG](https://github.com/HKUDS/LightRAG): Simple and Fast Retrieval-Augmented Generation.
  22. [TEN](https://github.com/TEN-framework/ten_framework): the Next-Gen AI-Agent Framework, the world's first truly real-time multimodal AI agent framework.
  23. [AutoRAG](https://github.com/Marker-Inc-Korea/AutoRAG): RAG AutoML tool for automatically finding an optimal RAG pipeline for your data.
  24. [KAG](https://github.com/OpenSPG/KAG): KAG is a knowledge-enhanced generation framework based on OpenSPG engine, which is used to build knowledge-enhanced rigorous decision-making and information retrieval knowledge services.
  25. [Fast-GraphRAG](https://github.com/circlemind-ai/fast-graphrag): RAG that intelligently adapts to your use case, data, and queries.
  26. [Tiny-GraphRAG](https://github.com/limafang/tiny-graphrag)
  27. [DB-GPT GraphRAG](https://github.com/eosphoros-ai/DB-GPT/tree/main/dbgpt/storage/knowledge_graph): DB-GPT GraphRAG integrates both triplet-based knowledge graphs and document structure graphs while leveraging community and document retrieval mechanisms to enhance RAG capabilities, achieving comparable performance while consuming only 50% of the tokens required by Microsoft's GraphRAG. Refer to the DB-GPT [Graph RAG User Manual](http://docs.dbgpt.cn/docs/cookbook/rag/graph_rag_app_develop/) for details.
  28. [Chonkie](https://github.com/bhavnicksm/chonkie): The no-nonsense RAG chunking library that's lightweight, lightning-fast, and ready to CHONK your texts.
  29. [RAGLite](https://github.com/superlinear-ai/raglite): RAGLite is a Python toolkit for Retrieval-Augmented Generation (RAG) with PostgreSQL or SQLite.
  30. [KAG](https://github.com/OpenSPG/KAG): KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs.
  31. [CAG](https://github.com/hhhuang/CAG): CAG leverages the extended context windows of modern large language models (LLMs) by preloading all relevant resources into the model‚Äôs context and caching its runtime parameters.
  32. [MiniRAG](https://github.com/HKUDS/MiniRAG): an extremely simple retrieval-augmented generation framework that enables small models to achieve good RAG performance through heterogeneous graph indexing and lightweight topology-enhanced retrieval.
  33. [XRAG](https://github.com/DocAILab/XRAG): a benchmarking framework designed to evaluate the foundational components of advanced Retrieval-Augmented Generation (RAG) systems.
  34. [Rankify](https://github.com/DataScienceUIBK/rankify): A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation.


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## Êô∫ËÉΩ‰Ωì Agents
[](https://github.com/WangRongsheng/awesome-LLM-resourses#Êô∫ËÉΩ‰Ωì-agents)
  1. [AutoGen](https://github.com/microsoft/autogen): AutoGen is a framework that enables the development of LLM applications using multiple agents that can converse with each other to solve tasks. [AutoGen AIStudio](https://autogen-studio.com/)
  2. [CrewAI](https://github.com/joaomdmoura/crewAI): Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.
  3. [Coze](https://www.coze.com/)
  4. [AgentGPT](https://github.com/reworkd/AgentGPT): Assemble, configure, and deploy autonomous AI Agents in your browser.
  5. [XAgent](https://github.com/OpenBMB/XAgent): An Autonomous LLM Agent for Complex Task Solving.
  6. [MobileAgent](https://github.com/X-PLUG/MobileAgent): The Powerful Mobile Device Operation Assistant Family.
  7. [Lagent](https://github.com/InternLM/lagent): A lightweight framework for building LLM-based agents.
  8. [Qwen-Agent](https://github.com/QwenLM/Qwen-Agent): Agent framework and applications built upon Qwen2, featuring Function Calling, Code Interpreter, RAG, and Chrome extension.
  9. [LinkAI](https://link-ai.tech/portal): ‰∏ÄÁ´ôÂºè AI Êô∫ËÉΩ‰ΩìÊê≠Âª∫Âπ≥Âè∞
  10. [Baidu APPBuilder](https://appbuilder.cloud.baidu.com/)
  11. [agentUniverse](https://github.com/alipay/agentUniverse): agentUniverse is a LLM multi-agent framework that allows developers to easily build multi-agent applications. Furthermore, through the community, they can exchange and share practices of patterns across different domains.
  12. [LazyLLM](https://github.com/LazyAGI/LazyLLM): ‰Ωé‰ª£Á†ÅÊûÑÂª∫Â§öAgentÂ§ßÊ®°ÂûãÂ∫îÁî®ÁöÑÂºÄÂèëÂ∑•ÂÖ∑
  13. [AgentScope](https://github.com/modelscope/agentscope): Start building LLM-empowered multi-agent applications in an easier way.
  14. [MoA](https://github.com/togethercomputer/MoA): Mixture of Agents (MoA) is a novel approach that leverages the collective strengths of multiple LLMs to enhance performance, achieving state-of-the-art results.
  15. [Agently](https://github.com/Maplemx/Agently): AI Agent Application Development Framework.
  16. [OmAgent](https://github.com/om-ai-lab/OmAgent): A multimodal agent framework for solving complex tasks.
  17. [Tribe](https://github.com/StreetLamb/tribe): No code tool to rapidly build and coordinate multi-agent teams.
  18. [CAMEL](https://github.com/camel-ai/camel): First LLM multi-agent framework and an open-source community dedicated to finding the scaling law of agents.
  19. [PraisonAI](https://github.com/MervinPraison/PraisonAI/): PraisonAI application combines AutoGen and CrewAI or similar frameworks into a low-code solution for building and managing multi-agent LLM systems, focusing on simplicity, customisation, and efficient human-agent collaboration.
  20. [IoA](https://github.com/openbmb/ioa): An open-source framework for collaborative AI agents, enabling diverse, distributed agents to team up and tackle complex tasks through internet-like connectivity.
  21. [llama-agentic-system ](https://github.com/meta-llama/llama-agentic-system): Agentic components of the Llama Stack APIs.
  22. [Agent Zero](https://github.com/frdel/agent-zero): Agent Zero is not a predefined agentic framework. It is designed to be dynamic, organically growing, and learning as you use it.
  23. [Agents](https://github.com/aiwaves-cn/agents): An Open-source Framework for Data-centric, Self-evolving Autonomous Language Agents.
  24. [AgentScope](https://github.com/modelscope/agentscope): Start building LLM-empowered multi-agent applications in an easier way.
  25. [FastAgency](https://github.com/airtai/fastagency): The fastest way to bring multi-agent workflows to production.
  26. [Swarm](https://github.com/openai/swarm): Framework for building, orchestrating and deploying multi-agent systems. Managed by OpenAI Solutions team. Experimental framework.
  27. [Agent-S](https://github.com/simular-ai/Agent-S): an open agentic framework that uses computers like a human.
  28. [PydanticAI](https://github.com/pydantic/pydantic-ai): Agent Framework / shim to use Pydantic with LLMs.
  29. [Agentarium](https://github.com/Thytu/Agentarium): open-source framework for creating and managing simulations populated with AI-powered agents.
  30. [smolagents](https://github.com/huggingface/smolagents): a barebones library for agents. Agents write python code to call tools and orchestrate other agents.


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## ÊêúÁ¥¢ Search
[](https://github.com/WangRongsheng/awesome-LLM-resourses#ÊêúÁ¥¢-search)
  1. [OpenSearch GPT](https://github.com/supermemoryai/opensearch-ai): SearchGPT / Perplexity clone, but personalised for you.
  2. [MindSearch](https://github.com/InternLM/MindSearch): An LLM-based Multi-agent Framework of Web Search Engine (like Perplexity.ai Pro and SearchGPT).
  3. [nanoPerplexityAI](https://github.com/Yusuke710/nanoPerplexityAI): The simplest open-source implementation of perplexity.ai.
  4. [curiosity](https://github.com/jank/curiosity): Try to build a Perplexity-like user experience.
  5. [MiniPerplx](https://github.com/zaidmukaddam/miniperplx): A minimalistic AI-powered search engine that helps you find information on the internet.


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## ‰π¶Á±ç Book
[](https://github.com/WangRongsheng/awesome-LLM-resourses#‰π¶Á±ç-book)
  1. [„ÄäÂ§ßËßÑÊ®°ËØ≠Ë®ÄÊ®°ÂûãÔºö‰ªéÁêÜËÆ∫Âà∞ÂÆûË∑µ„Äã](https://intro-llm.github.io/)
  2. [„ÄäÂ§ßËØ≠Ë®ÄÊ®°Âûã„Äã](https://llmbook-zh.github.io/)
  3. [„ÄäÂä®ÊâãÂ≠¶Â§ßÊ®°ÂûãDive into LLMs„Äã](https://github.com/Lordog/dive-into-llms)
  4. [„ÄäÂä®ÊâãÂÅöAI Agent„Äã](https://book.douban.com/subject/36884058/)
  5. [„ÄäBuild a Large Language Model (From Scratch)„Äã](https://github.com/rasbt/LLMs-from-scratch)
  6. [„ÄäÂ§öÊ®°ÊÄÅÂ§ßÊ®°Âûã„Äã](https://github.com/HCPLab-SYSU/Book-of-MLM)
  7. [„ÄäGenerative AI Handbook: A Roadmap for Learning Resources„Äã](https://genai-handbook.github.io/)
  8. [„ÄäUnderstanding Deep Learning„Äã](https://udlbook.github.io/udlbook/)
  9. [„ÄäIllustrated book to learn about Transformers & LLMs„Äã](https://www.reddit.com/r/MachineLearning/comments/1ew1hws/p_illustrated_book_to_learn_about_transformers/)
  10. [„ÄäBuilding LLMs for Production: Enhancing LLM Abilities and Reliability with Prompting, Fine-Tuning, and RAG„Äã](https://www.amazon.com/Building-LLMs-Production-Reliability-Fine-Tuning/dp/B0D4FFPFW8?crid=7OAXELUKGJE4&dib=eyJ2IjoiMSJ9.Qr3e3VSH8LSo_j1M7sV7GfS01q_W1LDYd2uGlvGJ8CW-t4DTlng6bSeOlZBryhp6HJN5K1HqWMVVgabU2wz2i9yLpy_AuaZN-raAEbenKx2NHtzZA3A4k-N7GpnldF1baCarA_V1CRF-aCdc9_3WSX7SaEzmpyDv22TTyltcKT74HAb2KiQqBGLhQS3cEAnzChcqGa1Xp-XhbMnplVwT7xZLApE3tGLhDOgi5GmSi9w.8SY_4NBEkm68YF4GwhDnz0r81ZB1d8jr-gK9IMJE5AE&dib_tag=se&keywords=building+llms+for+production&qid=1716376414&sprefix=building+llms+for+production,aps,101&sr=8-1&linkCode=sl1&tag=whatsai06-20&linkId=ee102fda07a0eb51710fcdd8b8d20c28&language=en_US&ref_=as_li_ss_tl)
  11. [„ÄäÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂÆûÊàòÊåáÂçóÔºöÂ∫îÁî®ÂÆûË∑µ‰∏éÂú∫ÊôØËêΩÂú∞„Äã](https://github.com/liucongg/LLMsBook)
  12. [„ÄäHands-On Large Language Models„Äã](https://github.com/handsOnLLM/Hands-On-Large-Language-Models)
  13. [„ÄäËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºöÂ§ßÊ®°ÂûãÁêÜËÆ∫‰∏éÂÆûË∑µ„Äã](https://nlp-book.swufenlp.group/)
  14. [„ÄäÂä®ÊâãÂ≠¶Âº∫ÂåñÂ≠¶‰π†„Äã](https://hrl.boyuai.com/)
  15. [„ÄäÈù¢ÂêëÂºÄÂèëËÄÖÁöÑLLMÂÖ•Èó®ÊïôÁ®ã„Äã](https://datawhalechina.github.io/llm-cookbook/#/)
  16. [„ÄäÂ§ßÊ®°ÂûãÂü∫Á°Ä„Äã](https://github.com/ZJU-LLMs/Foundations-of-LLMs)
  17. [Taming LLMs: A Practical Guide to LLM Pitfalls with Open Source Software ](https://www.tamingllms.com/)
  18. [Foundations of Large Language Models](https://arxiv.org/abs/2501.09223)


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## ËØæÁ®ã Course
[](https://github.com/WangRongsheng/awesome-LLM-resourses#ËØæÁ®ã-course)
> [LLM Resources Hub](https://llmresourceshub.vercel.app/)
  1. [ÊñØÂù¶Á¶è CS224N: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/cs224n/)
  2. [Âê¥ÊÅ©Ëææ: Generative AI for Everyone](https://www.deeplearning.ai/courses/generative-ai-for-everyone/)
  3. [Âê¥ÊÅ©Ëææ: LLM series of courses](https://learn.deeplearning.ai/)
  4. [ACL 2023 Tutorial: Retrieval-based Language Models and Applications](https://acl2023-retrieval-lm.github.io/)
  5. [llm-course: Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks.](https://github.com/mlabonne/llm-course)
  6. [ÂæÆËΩØ: Generative AI for Beginners](https://github.com/microsoft/generative-ai-for-beginners)
  7. [ÂæÆËΩØ: State of GPT](https://www.youtube.com/watch?v=bZQun8Y4L2A)
  8. [HuggingFace NLP Course](https://huggingface.co/learn/nlp-course/chapter1/1)
  9. [Ê∏ÖÂçé NLP ÂàòÁü•ËøúÂõ¢ÈòüÂ§ßÊ®°ÂûãÂÖ¨ÂºÄËØæ](https://www.bilibili.com/video/BV1UG411p7zv/?vd_source=c739db1ebdd361d47af5a0b8497417db)
  10. [ÊñØÂù¶Á¶è CS25: Transformers United V4](https://web.stanford.edu/class/cs25/)
  11. [ÊñØÂù¶Á¶è CS324: Large Language Models](https://stanford-cs324.github.io/winter2022/)
  12. [ÊôÆÊûóÊñØÈ°ø COS 597G (Fall 2022): Understanding Large Language Models](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/)
  13. [Á∫¶Áø∞ÈúçÊôÆÈáëÊñØ CS 601.471/671 NLP: Self-supervised Models](https://self-supervised.cs.jhu.edu/sp2023/index.html)
  14. [ÊùéÂÆèÊØÖ GenAIËØæÁ®ã](https://www.youtube.com/watch?v=yiY4nPOzJEg&list=PLJV_el3uVTsOePyfmkfivYZ7Rqr2nMk3W)
  15. [openai-cookbook](https://github.com/openai/openai-cookbook): Examples and guides for using the OpenAI API.
  16. [Hands on llms](https://github.com/iusztinpaul/hands-on-llms): Learn about LLM, LLMOps, and vector DBS for free by designing, training, and deploying a real-time financial advisor LLM system.
  17. [ÊªëÈìÅÂç¢Â§ßÂ≠¶ CS 886: Recent Advances on Foundation Models](https://cs.uwaterloo.ca/~wenhuche/teaching/cs886/)
  18. [Mistral: Getting Started with Mistral](https://www.deeplearning.ai/short-courses/getting-started-with-mistral/)
  19. [ÊñØÂù¶Á¶è CS25: Transformers United V4](https://web.stanford.edu/class/cs25/)
  20. [Coursera: Chatgpt Â∫îÁî®ÊèêÁ§∫Â∑•Á®ã](https://www.coursera.org/learn/prompt-engineering)
  21. [LangGPT](https://github.com/langgptai/LangGPT): Empowering everyone to become a prompt expert!
  22. [mistralai-cookbook](https://github.com/mistralai/cookbook)
  23. [Introduction to Generative AI 2024 Spring](https://speech.ee.ntu.edu.tw/~hylee/genai/2024-spring.php)
  24. [build nanoGPT](https://github.com/karpathy/build-nanogpt): Video+code lecture on building nanoGPT from scratch.
  25. [LLM101n](https://github.com/karpathy/LLM101n): Let's build a Storyteller.
  26. [Knowledge Graphs for RAG](https://www.deeplearning.ai/short-courses/knowledge-graphs-rag/)
  27. [LLMs From Scratch (Datawhale Version)](https://github.com/datawhalechina/llms-from-scratch-cn)
  28. [OpenRAG](https://openrag.notion.site/Open-RAG-c41b2a4dcdea4527a7c1cd998e763595)
  29. [ÈÄöÂæÄAGI‰πãË∑Ø](https://waytoagi.feishu.cn/wiki/QPe5w5g7UisbEkkow8XcDmOpn8e)
  30. [Andrej Karpathy - Neural Networks: Zero to Hero](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)
  31. [Interactive visualization of Transformer](https://poloclub.github.io/transformer-explainer/)
  32. [andysingal/llm-course](https://github.com/andysingal/llm-course)
  33. [LM-class](https://lm-class.org/lectures)
  34. [Google Advanced: Generative AI for Developers Learning Path](https://www.cloudskillsboost.google/paths/183)
  35. [AnthropicsÔºöPrompt Engineering Interactive Tutorial](https://github.com/anthropics/courses/tree/master/prompt_engineering_interactive_tutorial/Anthropic%201P)
  36. [LLMsBook](https://github.com/liucongg/LLMsBook)
  37. [Large Language Model Agents](https://llmagents-learning.org/f24)
  38. [Cohere LLM University](https://cohere.com/llmu)
  39. [LLMs and Transformers](https://www.ambujtewari.com/LLM-fall2024/)
  40. [Smol Vision](https://github.com/merveenoyan/smol-vision): Recipes for shrinking, optimizing, customizing cutting edge vision models.
  41. [Multimodal RAG: Chat with Videos](https://www.deeplearning.ai/short-courses/multimodal-rag-chat-with-videos/)
  42. [LLMs Interview Note](https://github.com/wdndev/llm_interview_note)
  43. [RAG++ : From POC to production](https://www.wandb.courses/courses/rag-in-production): Advanced RAG course.
  44. [Weights & Biases AI Academy](https://www.wandb.courses/pages/w-b-courses): Finetuning, building with LLMs, Structured outputs and more LLM courses.
  45. [Prompt Engineering & AI tutorials & Resources](https://promptengineering.org/)
  46. [Learn RAG From Scratch ‚Äì Python AI Tutorial from a LangChain Engineer](https://www.youtube.com/watch?v=sVcwVQRHIc8)
  47. [LLM Evaluation: A Complete Course](https://www.comet.com/site/llm-course/)
  48. [HuggingFace Learn](https://huggingface.co/learn)
  49. [Andrej Karpathy: Deep Dive into LLMs like ChatGPT](https://www.youtube.com/watch?v=7xTGNNLPyMI)
  50. [LLMÊäÄÊúØÁßëÊôÆ](https://github.com/karminski/one-small-step)


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## ÊïôÁ®ã Tutorial
[](https://github.com/WangRongsheng/awesome-LLM-resourses#ÊïôÁ®ã-tutorial)
  1. [Âä®ÊâãÂ≠¶Â§ßÊ®°ÂûãÂ∫îÁî®ÂºÄÂèë](https://datawhalechina.github.io/llm-universe/#/)
  2. [AIÂºÄÂèëËÄÖÈ¢ëÈÅì](https://techdiylife.github.io/blog/blog_list.html)
  3. [BÁ´ôÔºö‰∫îÈáåÂ¢©Ëå∂Á§æ](https://space.bilibili.com/615957867/?spm_id_from=333.999.0.0)
  4. [BÁ´ôÔºöÊú®ÁæΩCheney](https://space.bilibili.com/3537113897241540/?spm_id_from=333.999.0.0)
  5. [YTBÔºöAI Anytime](https://www.youtube.com/channel/UC-zVytOQB62OwMhKRi0TDvg)
  6. [BÁ´ôÔºöÊºÜÂ¶ÆÂ¶Æ](https://space.bilibili.com/1262370256/?spm_id_from=333.999.0.0)
  7. [Prompt Engineering Guide](https://www.promptingguide.ai/)
  8. [YTB: AIË∂ÖÂÖÉÂüü](https://www.youtube.com/@AIsuperdomain)
  9. [BÁ´ôÔºöTechBeat‰∫∫Â∑•Êô∫ËÉΩÁ§æÂå∫](https://space.bilibili.com/209732435)
  10. [BÁ´ôÔºöÈªÑÁõäË¥∫](https://space.bilibili.com/322961825)
  11. [BÁ´ôÔºöÊ∑±Â∫¶Â≠¶‰π†Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ](https://space.bilibili.com/507524288)
  12. [LLM Visualization](https://bbycroft.net/llm)
  13. [Áü•‰πé: ÂéüÁü≥‰∫∫Á±ª](https://www.zhihu.com/people/zhang-shi-tou-88-98/posts)
  14. [BÁ´ôÔºöÂ∞èÈªëÈªëËÆ≤AI](https://space.bilibili.com/1963375439/?spm_id_from=333.999.0.0)
  15. [BÁ´ôÔºöÈù¢Â£ÅÁöÑËΩ¶ËæÜÂ∑•Á®ãÂ∏à](https://space.bilibili.com/669720247/?spm_id_from=333.999.0.0)
  16. [BÁ´ôÔºöAIËÄÅÂÖµÊñáÂì≤](https://space.bilibili.com/472543316/?spm_id_from=333.999.0.0)
  17. [Large Language Models (LLMs) with Colab notebooks](https://mlabonne.github.io/blog/)
  18. [YTBÔºöIBM Technology](https://www.youtube.com/@IBMTechnology)
  19. [YTB: Unify Reading Paper Group](https://www.youtube.com/playlist?list=PLwNuX3xB_tv91QvDXlW2TjrLGHW51uMul)
  20. [Chip Huyen](https://huyenchip.com/blog/)
  21. [How Much VRAM](https://github.com/AlexBodner/How_Much_VRAM)
  22. [Blog: ÁßëÂ≠¶Á©∫Èó¥ÔºàËãèÂâëÊûóÔºâ](https://kexue.fm/)
  23. [YTB: Hyung Won Chung](https://www.youtube.com/watch?v=dbo3kNKPaUA)
  24. [Blog: Tejaswi kashyap](https://medium.com/@tejaswi_kashyap)
  25. [Blog: Â∞èÊòáÁöÑÂçöÂÆ¢](https://xiaosheng.blog/)
  26. [Áü•‰πé: ybq](https://www.zhihu.com/people/ybq-29-32/posts)
  27. [W&B articles](https://wandb.ai/fully-connected)
  28. [Huggingface Blog](https://huggingface.co/blog/zh)
  29. [Blog: GbyAI](https://gby.ai/)
  30. [Blog: mlabonne](https://mlabonne.github.io/blog/)
  31. [LLM-Action](https://github.com/liguodongiot/llm-action)
  32. [Blog: Lil‚ÄôLog (OponAI)](https://lilianweng.github.io/)
  33. [BÁ´ô: ÊØõÁéâ‰ªÅ](https://space.bilibili.com/3546823125895398)
  34. [AI-Guide-and-Demos](https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN)
  35. [cnblog: Á¨¨‰∏ÉÂ≠ê](https://www.cnblogs.com/theseventhson)
  36. [Implementation of all RAG techniques in a simpler way.](https://github.com/FareedKhan-dev/all-rag-techniques)


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## ËÆ∫Êñá Paper
[](https://github.com/WangRongsheng/awesome-LLM-resourses#ËÆ∫Êñá-paper)
Note
ü§ù[Huggingface Daily Papers](https://huggingface.co/papers)„ÄÅ[Cool Papers](https://papers.cool/)„ÄÅ[ML Papers Explained](https://github.com/dair-ai/ML-Papers-Explained)
  1. [Hermes-3-Technical-Report](https://nousresearch.com/wp-content/uploads/2024/08/Hermes-3-Technical-Report.pdf)
  2. [The Llama 3 Herd of Models](https://arxiv.org/abs/2407.21783)
  3. [Qwen Technical Report](https://arxiv.org/abs/2309.16609)
  4. [Qwen2 Technical Report](https://arxiv.org/abs/2407.10671)
  5. [Qwen2-vl Technical Report](https://arxiv.org/abs/2409.12191)
  6. [DeepSeek LLM: Scaling Open-Source Language Models with Longtermism](https://arxiv.org/abs/2401.02954)
  7. [DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model](https://arxiv.org/abs/2405.04434)
  8. [Baichuan 2: Open Large-scale Language Models](https://arxiv.org/abs/2309.10305)
  9. [DataComp-LM: In search of the next generation of training sets for language models](https://arxiv.org/abs/2406.11794)
  10. [OLMo: Accelerating the Science of Language Models](https://arxiv.org/abs/2402.00838)
  11. [MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series](https://arxiv.org/abs/2405.19327)
  12. [Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model](https://arxiv.org/abs/2404.04167)
  13. [Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone](https://arxiv.org/abs/2404.14219)
  14. [Jamba-1.5: Hybrid Transformer-Mamba Models at Scale](https://arxiv.org/abs/2408.12570v1)
  15. [Jamba: A Hybrid Transformer-Mamba Language Model](https://arxiv.org/abs/2403.19887)
  16. [Textbooks Are All You Need](https://arxiv.org/abs/2306.11644)
  17. [Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models](https://arxiv.org/abs/2408.02085) `data`
  18. [OLMoE: Open Mixture-of-Experts Language Models](https://arxiv.org/abs/2409.02060)
  19. [Model Merging Paper](https://huggingface.co/collections/osanseviero/model-merging-65097893623330a3a51ead66)
  20. [Baichuan-Omni Technical Report](https://arxiv.org/abs/2410.08565)
  21. [1.5-Pints Technical Report: Pretraining in Days, Not Months ‚Äì Your Language Model Thrives on Quality Data](https://arxiv.org/abs/2408.03506)
  22. [Baichuan Alignment Technical Report](https://arxiv.org/abs/2410.14940v1)
  23. [Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent](https://arxiv.org/abs/2411.02265)
  24. [Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models](https://arxiv.org/abs/2409.17146)
  25. [T√úLU 3: Pushing Frontiers in Open Language Model Post-Training](https://arxiv.org/abs/2411.15124)
  26. [Phi-4 Technical Report](https://arxiv.org/abs/2412.08905)
  27. [Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling](https://arxiv.org/abs/2412.05271)
  28. [Qwen2.5 Technical Report](https://arxiv.org/abs/2412.15115)
  29. [YuLan-Mini: An Open Data-efficient Language Model](https://arxiv.org/abs/2412.17743)
  30. [An Introduction to Vision-Language Modeling](https://arxiv.org/abs/2405.17247)
  31. [DeepSeek V3 Technical Report](https://github.com/WangRongsheng/awesome-LLM-resourses/blob/main/docs/DeepSeek_V3.pdf)
  32. [2 OLMo 2 Furious](https://arxiv.org/abs/2501.00656)
  33. [Yi-Lightning Technical Report](https://arxiv.org/abs/2412.01253)
  34. [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://github.com/deepseek-ai/DeepSeek-R1)
  35. [KIMI K1.5](https://github.com/WangRongsheng/awesome-LLM-resourses/blob/main/docs/Kimi_k1.5.pdf)
  36. [Eagle 2: Building Post-Training Data Strategies from Scratch for Frontier Vision-Language Models](https://arxiv.org/abs/2501.14818)
  37. [Qwen2.5-VL Technical Report](https://arxiv.org/abs/2502.13923)
  38. [Baichuan-M1: Pushing the Medical Capability of Large Language Models](https://arxiv.org/abs/2502.12671)
  39. [Predictable Scale: Part I -- Optimal Hyperparameter Scaling Law in Large Language Model Pretraining](https://arxiv.org/abs/2503.04715)
  40. [SkyLadder: Better and Faster Pretraining via Context Window Scheduling](https://arxiv.org/abs/2503.15450)
  41. [Qwen2.5-Omni technical report](https://github.com/QwenLM/Qwen2.5-Omni/blob/main/assets/Qwen2.5_Omni.pdf)
  42. [Every FLOP Counts: Scaling a 300B Mixture-of-Experts LING LLM without Premium GPUs](https://arxiv.org/abs/2503.05139)
  43. [Gemma 3 Technical Report](https://arxiv.org/abs/2503.19786)


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## Á§æÂå∫ Community
[](https://github.com/WangRongsheng/awesome-LLM-resourses#Á§æÂå∫-community)
  1. [È≠î‰πêÁ§æÂå∫](https://modelers.cn/)
  2. [HuggingFace](https://huggingface.co/)
  3. [ModelScope](https://modelscope.cn/)
  4. [WiseModel](https://www.wisemodel.cn/)
  5. [OpenCSG](https://opencsg.com/)


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## MCP
[](https://github.com/WangRongsheng/awesome-LLM-resourses#mcp)
  1. [MCPÊòØÂï•ÔºüÊäÄÊúØÂéüÁêÜÊòØ‰ªÄ‰πàÔºü‰∏Ä‰∏™ËßÜÈ¢ëÊêûÊáÇMCPÁöÑ‰∏ÄÂàá„ÄÇWindowsÁ≥ªÁªüÈÖçÁΩÆMCPÔºåCursor,Cline ‰ΩøÁî®MCP](https://www.youtube.com/watch?v=McNRkd5CxFY)
  2. [MCPÊòØ‰ªÄ‰πàÔºü‰∏∫Âï•ÊòØ‰∏ã‰∏Ä‰ª£AIÊ†áÂáÜÔºüMCPÂéüÁêÜ+ÂºÄÂèëÂÆûÊàòÔºÅÂú®Cursor„ÄÅClaude„ÄÅCline‰∏≠‰ΩøÁî®MCPÔºåËÆ©AIÁúüÊ≠£Ëá™Âä®ÂåñÔºÅ](https://www.youtube.com/watch?v=jGVsLeDxtQY)


MCPÂ∑•ÂÖ∑ËÅöÂêàÔºö
  1. [smithery.ai](https://smithery.ai/)
  2. [mcp.so](https://mcp.so/)
  3. [modelcontextprotocol/servers](https://github.com/modelcontextprotocol/servers)
  4. [mcp.ad](https://mcp.ad/)
  5. [pulsemcp.com](https://www.pulsemcp.com/)
  6. [awesome-mcp-servers](https://github.com/punkpeye/awesome-mcp-servers)
  7. [glama.ai](https://glama.ai/mcp/servers)
  8. [mcp.composio.dev](https://mcp.composio.dev/)


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## Open o1
[](https://github.com/WangRongsheng/awesome-LLM-resourses#open-o1)
Note
ÂºÄÊîæÁöÑÊäÄÊúØÊòØÊàë‰ª¨Ê∞∏ÊÅíÁöÑËøΩÊ±Ç
  1. <https://github.com/atfortes/Awesome-LLM-Reasoning>
  2. <https://github.com/hijkzzz/Awesome-LLM-Strawberry>
  3. <https://github.com/wjn1996/Awesome-LLM-Reasoning-Openai-o1-Survey>
  4. <https://github.com/srush/awesome-o1>
  5. <https://github.com/open-thought/system-2-research>
  6. [ninehills/blog#121](https://github.com/ninehills/blog/issues/121)
  7. <https://github.com/OpenSource-O1/Open-O1>
  8. <https://github.com/GAIR-NLP/O1-Journey>
  9. <https://github.com/marlaman/show-me>
  10. <https://github.com/bklieger-groq/g1>
  11. <https://github.com/Jaimboh/Llamaberry-Chain-of-Thought-Reasoning-in-AI>
  12. <https://github.com/pseudotensor/open-strawberry>
  13. <https://huggingface.co/collections/peakji/steiner-preview-6712c6987110ce932a44e9a6>
  14. <https://github.com/SimpleBerry/LLaMA-O1>
  15. <https://huggingface.co/collections/Skywork/skywork-o1-open-67453df58e12f6c3934738d0>
  16. <https://huggingface.co/collections/Qwen/qwq-674762b79b75eac01735070a>
  17. <https://github.com/SkyworkAI/skywork-o1-prm-inference>
  18. <https://github.com/RifleZhang/LLaVA-Reasoner-DPO>
  19. <https://github.com/ADaM-BJTU>
  20. <https://github.com/ADaM-BJTU/OpenRFT>
  21. <https://github.com/RUCAIBox/Slow_Thinking_with_LLMs>
  22. <https://github.com/richards199999/Thinking-Claude>
  23. <https://huggingface.co/AGI-0/Art-v0-3B>
  24. <https://huggingface.co/deepseek-ai/DeepSeek-R1>
  25. <https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero>
  26. <https://github.com/huggingface/open-r1>
  27. <https://github.com/hkust-nlp/simpleRL-reason>
  28. <https://github.com/Jiayi-Pan/TinyZero>
  29. <https://github.com/baichuan-inc/Baichuan-M1-14B>
  30. <https://github.com/EvolvingLMMs-Lab/open-r1-multimodal>
  31. <https://github.com/open-thoughts/open-thoughts>
  32. Mini-R1: <https://www.philschmid.de/mini-deepseek-r1>
  33. LLaMA-Berry: <https://arxiv.org/abs/2410.02884>
  34. MCTS-DPO: <https://arxiv.org/abs/2405.00451>
  35. OpenR: <https://github.com/openreasoner/openr>
  36. <https://arxiv.org/abs/2410.02725>
  37. LLaVA-o1: <https://arxiv.org/abs/2411.10440>
  38. Marco-o1: <https://arxiv.org/abs/2411.14405>
  39. OpenAI o1 report: <https://openai.com/index/deliberative-alignment>
  40. DRT-o1: <https://github.com/krystalan/DRT-o1>
  41. VirgoÔºö<https://arxiv.org/abs/2501.01904>
  42. HuatuoGPT-o1Ôºö<https://arxiv.org/abs/2412.18925>
  43. o1 roadmapÔºö<https://arxiv.org/abs/2412.14135>
  44. MulberryÔºö<https://arxiv.org/abs/2412.18319>
  45. <https://arxiv.org/abs/2412.09413>
  46. <https://arxiv.org/abs/2501.02497>
  47. Search-o1:<https://arxiv.org/abs/2501.05366v1>
  48. <https://arxiv.org/abs/2501.18585>
  49. <https://github.com/simplescaling/s1>
  50. <https://github.com/Deep-Agent/R1-V>
  51. <https://github.com/StarRing2022/R1-Nature>
  52. <https://github.com/Unakar/Logic-RL>
  53. <https://github.com/datawhalechina/unlock-deepseek>
  54. <https://github.com/GAIR-NLP/LIMO>
  55. <https://github.com/Zeyi-Lin/easy-r1>
  56. <https://github.com/jackfsuia/nanoRLHF/tree/main/examples/r1-v0>
  57. <https://github.com/FanqingM/R1-Multimodal-Journey>
  58. <https://github.com/dhcode-cpp/X-R1>
  59. <https://github.com/agentica-project/deepscaler>
  60. <https://github.com/ZihanWang314/RAGEN>
  61. <https://github.com/sail-sg/oat-zero>
  62. <https://github.com/TideDra/lmm-r1>
  63. <https://github.com/FlagAI-Open/OpenSeek>
  64. <https://github.com/SwanHubX/ascend_r1_turtorial>
  65. <https://github.com/om-ai-lab/VLM-R1>
  66. <https://github.com/wizardlancet/diagnosis_zero>
  67. <https://github.com/lsdefine/simple_GRPO>
  68. <https://github.com/brendanhogan/DeepSeekRL-Extended>
  69. <https://github.com/Wang-Xiaodong1899/Open-R1-Video>
  70. <https://github.com/lsdefine/simple_GRPO>
  71. <https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero>
  72. <https://github.com/lucasjinreal/Namo-R1>
  73. <https://github.com/hiyouga/EasyR1>
  74. <https://github.com/Fancy-MLLM/R1-Onevision>
  75. <https://github.com/tulerfeng/Video-R1>
  76. <https://huggingface.co/qihoo360/TinyR1-32B-Preview>
  77. <https://github.com/facebookresearch/swe-rl>
  78. <https://github.com/turningpoint-ai/VisualThinker-R1-Zero>
  79. <https://github.com/yuyq96/R1-Vision>
  80. <https://github.com/sungatetop/deepseek-r1-vision>
  81. <https://huggingface.co/qihoo360/Light-R1-32B>
  82. <https://github.com/Liuziyu77/Visual-RFT>
  83. <https://github.com/Mohammadjafari80/GSM8K-RLVR>
  84. <https://github.com/ModalMinds/MM-EUREKA>
  85. <https://github.com/joey00072/nanoGRPO>
  86. <https://github.com/PeterGriffinJin/Search-R1>
  87. <https://openi.pcl.ac.cn/PCL-Reasoner/GRPO-Training-Suite>
  88. <https://github.com/dvlab-research/Seg-Zero>
  89. <https://github.com/HumanMLLM/R1-Omni>
  90. <https://github.com/OpenManus/OpenManus-RL>
  91. <https://arxiv.org/pdf/2503.07536>
  92. <https://github.com/Osilly/Vision-R1>
  93. <https://github.com/LengSicong/MMR1>
  94. <https://github.com/phonism/CP-Zero>
  95. <https://github.com/SkyworkAI/Skywork-R1V>
  96. <https://arxiv.org/abs/2503.13939v1>
  97. <https://github.com/0russwest0/Agent-R1>
  98. <https://github.com/MetabrainAGI/Awaker2.5-R1>
  99. <https://github.com/LG-AI-EXAONE/EXAONE-Deep>
  100. <https://github.com/qiufengqijun/open-r1-reprod>
  101. <https://github.com/SUFE-AIFLM-Lab/Fin-R1>
  102. <https://github.com/sail-sg/understand-r1-zero>
  103. <https://github.com/baibizhe/Efficient-R1-VLLM>
  104. <https://github.com/hkust-nlp/simpleRL-reason>
  105. <https://arxiv.org/abs/2502.19655>
  106. <https://arxiv.org/abs/2503.21620v1>
  107. <https://arxiv.org/abs/2503.16081>
  108. <https://github.com/ShadeCloak/ADORA>


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## Small Language Model
[](https://github.com/WangRongsheng/awesome-LLM-resourses#small-language-model)
  1. <https://github.com/jiahe7ay/MINI_LLM>
  2. <https://github.com/jingyaogong/minimind>
  3. <https://github.com/DLLXW/baby-llama2-chinese>
  4. <https://github.com/charent/ChatLM-mini-Chinese>
  5. <https://github.com/wdndev/tiny-llm-zh>
  6. <https://github.com/Tongjilibo/build_MiniLLM_from_scratch>
  7. <https://github.com/jzhang38/TinyLlama>
  8. <https://github.com/AI-Study-Han/Zero-Chatgpt>
  9. <https://github.com/loubnabnl/nanotron-smol-cluster> ([‰ΩøÁî®CosmopediaËÆ≠ÁªÉcosmo-1b](https://huggingface.co/blog/zh/cosmopedia))
  10. <https://github.com/charent/Phi2-mini-Chinese>
  11. <https://github.com/allenai/OLMo>
  12. <https://github.com/keeeeenw/MicroLlama>
  13. <https://github.com/Chinese-Tiny-LLM/Chinese-Tiny-LLM>
  14. <https://github.com/leeguandong/MiniLLaMA3>
  15. <https://github.com/Pints-AI/1.5-Pints>
  16. <https://github.com/zhanshijinwat/Steel-LLM>
  17. <https://github.com/RUC-GSAI/YuLan-Mini>
  18. <https://github.com/Om-Alve/smolGPT>


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## Small Vision Language Model
[](https://github.com/WangRongsheng/awesome-LLM-resourses#small-vision-language-model)
  1. <https://github.com/jingyaogong/minimind-v>
  2. <https://github.com/yuanzhoulvpi2017/zero_nlp/tree/main/train_llava>
  3. <https://github.com/AI-Study-Han/Zero-Qwen-VL>
  4. <https://github.com/Coobiw/MPP-LLaVA>
  5. <https://github.com/qnguyen3/nanoLLaVA>
  6. <https://github.com/TinyLLaVA/TinyLLaVA_Factory>
  7. <https://github.com/ZhangXJ199/TinyLLaVA-Video>
  8. <https://github.com/Emericen/tiny-qwen>
  9. <https://github.com/merveenoyan/smol-vision>


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
## Tips
[](https://github.com/WangRongsheng/awesome-LLM-resourses#tips)
  1. [What We Learned from a Year of Building with LLMs (Part I)](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/)
  2. [What We Learned from a Year of Building with LLMs (Part II)](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-ii/)
  3. [What We Learned from a Year of Building with LLMs (Part III): Strategy](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-iii-strategy/)
  4. [ËΩªÊùæÂÖ•Èó®Â§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâ](https://www.bilibili.com/video/BV1pF4m1V7FB/?spm_id_from=333.999.0.0&vd_source=c739db1ebdd361d47af5a0b8497417db)
  5. [LLMs for Text Classification: A Guide to Supervised Learning](https://www.striveworks.com/blog/llms-for-text-classification-a-guide-to-supervised-learning)
  6. [Unsupervised Text Classification: Categorize Natural Language With LLMs](https://www.striveworks.com/blog/unsupervised-text-classification-how-to-use-llms-to-categorize-natural-language-data)
  7. [Text Classification With LLMs: A Roundup of the Best Methods](https://www.striveworks.com/blog/text-classification-with-llms-a-roundup-of-the-best-methods)
  8. [LLM Pricing](https://docs.google.com/spreadsheets/d/18GHPEBJzDbICmMStPVkNWA_hQHiWmLcqUdEJA1b4MJM/edit?gid=0#gid=0)
  9. [Uncensor any LLM with abliteration](https://huggingface.co/blog/mlabonne/abliteration)
  10. [Tiny LLM Universe](https://github.com/datawhalechina/tiny-universe)
  11. [Zero-Chatgpt](https://github.com/AI-Study-Han/Zero-Chatgpt)
  12. [Zero-Qwen-VL](https://github.com/AI-Study-Han/Zero-Qwen-VL)
  13. [finetune-Qwen2-VL](https://github.com/zhangfaen/finetune-Qwen2-VL)
  14. [MPP-LLaVA](https://github.com/Coobiw/MPP-LLaVA)
  15. [build_MiniLLM_from_scratch](https://github.com/Tongjilibo/build_MiniLLM_from_scratch)
  16. [Tiny LLM zh](https://github.com/wdndev/tiny-llm-zh)
  17. [MiniMind](https://github.com/jingyaogong/minimind): 3Â∞èÊó∂ÂÆåÂÖ®‰ªé0ËÆ≠ÁªÉ‰∏Ä‰∏™‰ªÖÊúâ26MÁöÑÂ∞èÂèÇÊï∞GPTÔºåÊúÄ‰Ωé‰ªÖÈúÄ2GÊòæÂç°Âç≥ÂèØÊé®ÁêÜËÆ≠ÁªÉ.
  18. [LLM-Travel](https://github.com/Glanvery/LLM-Travel): Ëá¥Âäõ‰∫éÊ∑±ÂÖ•ÁêÜËß£„ÄÅÊé¢ËÆ®‰ª•ÂèäÂÆûÁé∞‰∏éÂ§ßÊ®°ÂûãÁõ∏ÂÖ≥ÁöÑÂêÑÁßçÊäÄÊúØ„ÄÅÂéüÁêÜÂíåÂ∫îÁî®
  19. [Knowledge distillation: Teaching LLM's with synthetic data](https://wandb.ai/byyoung3/ML_NEWS3/reports/Knowledge-distillation-Teaching-LLM-s-with-synthetic-data--Vmlldzo5MTMyMzA2)
  20. [Part 1: Methods for adapting large language models](https://ai.meta.com/blog/adapting-large-language-models-llms/)
  21. [Part 2: To fine-tune or not to fine-tune](https://ai.meta.com/blog/when-to-fine-tune-llms-vs-other-techniques/)
  22. [Part 3: How to fine-tune: Focus on effective datasets](https://ai.meta.com/blog/how-to-fine-tune-llms-peft-dataset-curation/)
  23. [Reader-LM: Small Language Models for Cleaning and Converting HTML to Markdown](https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/?nocache=1)
  24. [LLMsÂ∫îÁî®ÊûÑÂª∫‰∏ÄÂπ¥‰πãÂøÉÂæó](https://iangyan.github.io/2024/09/08/building-with-llms-part-1/)
  25. [LLMËÆ≠ÁªÉ-pretrain](https://zhuanlan.zhihu.com/p/718354385)
  26. [pytorch-llama](https://github.com/hkproj/pytorch-llama): LLaMA 2 implemented from scratch in PyTorch.
  27. [Preference Optimization for Vision Language Models with TRL](https://huggingface.co/blog/dpo_vlm) „Äê[support model](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForVision2Seq)„Äë
  28. [Fine-tuning visual language models using SFTTrainer](https://huggingface.co/blog/vlms) „Äê[docs](https://huggingface.co/docs/trl/sft_trainer#extending-sfttrainer-for-vision-language-models)„Äë
  29. [A Visual Guide to Mixture of Experts (MoE)](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts)
  30. [Role-Playing in Large Language Models like ChatGPT](https://promptengineering.org/role-playing-in-large-language-models-like-chatgpt/)
  31. [Distributed Training Guide](https://github.com/LambdaLabsML/distributed-training-guide): Best practices & guides on how to write distributed pytorch training code.
  32. [Chat Templates](https://hf-mirror.com/blog/chat-templates)
  33. [Top 20+ RAG Interview Questions](https://www.analyticsvidhya.com/blog/2024/04/rag-interview-questions/)
  34. [LLM-Dojo ÂºÄÊ∫êÂ§ßÊ®°ÂûãÂ≠¶‰π†Âú∫ÊâÄÔºå‰ΩøÁî®ÁÆÄÊ¥Å‰∏îÊòìÈòÖËØªÁöÑ‰ª£Á†ÅÊûÑÂª∫Ê®°ÂûãËÆ≠ÁªÉÊ°ÜÊû∂](https://github.com/mst272/LLM-Dojo)
  35. [o1 isn‚Äôt a chat model (and that‚Äôs the point)](https://www.latent.space/p/o1-skill-issue)
  36. [Beam SearchÂø´ÈÄüÁêÜËß£Âèä‰ª£Á†ÅËß£Êûê](https://www.cnblogs.com/nickchen121/p/15499576.html)
  37. [Âü∫‰∫é transformers ÁöÑ generate() ÊñπÊ≥ïÂÆûÁé∞Â§öÊ†∑ÂåñÊñáÊú¨ÁîüÊàêÔºöÂèÇÊï∞Âê´‰πâÂíåÁÆóÊ≥ïÂéüÁêÜËß£ËØª](https://blog.csdn.net/muyao987/article/details/125917234)
  38. [The Ultra-Scale Playbook: Training LLMs on GPU Clusters](https://huggingface.co/spaces/nanotron/ultrascale-playbook)


**[‚Ü• back to top](https://github.com/WangRongsheng/awesome-LLM-resourses#Contents)**
[![](https://camo.githubusercontent.com/2722992d519a722218f896d5f5231d49f337aaff4514e78bd59ac935334e916a/68747470733a2f2f692e696d6775722e636f6d2f77617856496d762e706e67)](https://camo.githubusercontent.com/2722992d519a722218f896d5f5231d49f337aaff4514e78bd59ac935334e916a/68747470733a2f2f692e696d6775722e636f6d2f77617856496d762e706e67)
Â¶ÇÊûú‰Ω†ËßâÂæóÊú¨È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåÊ¨¢ËøéÂºïÁî®Ôºö
```
@misc{wang2024llm,
   title={awesome-LLM-resourses}, 
   author={Rongsheng Wang},
   year={2024},
   publisher = {GitHub},
   journal = {GitHub repository},
   howpublished = {\url{https://github.com/WangRongsheng/awesome-LLM-resourses}},
}
```

[![Stargazers over time](https://camo.githubusercontent.com/b7ad25bdc61e9beab0756cf490492ece4c64e418f3089db724acab868097e21a/68747470733a2f2f7374617263686172742e63632f57616e67526f6e677368656e672f617765736f6d652d4c4c4d2d7265736f75727365732e737667)](https://starchart.cc/WangRongsheng/awesome-LLM-resourses)
## About
üßë‚ÄçüöÄ ÂÖ®‰∏ñÁïåÊúÄÂ•ΩÁöÑLLMËµÑÊñôÊÄªÁªìÔºàÊï∞ÊçÆÂ§ÑÁêÜ„ÄÅÊ®°ÂûãËÆ≠ÁªÉ„ÄÅÊ®°ÂûãÈÉ®ÁΩ≤„ÄÅo1 Ê®°Âûã„ÄÅMCP„ÄÅÂ∞èËØ≠Ë®ÄÊ®°Âûã„ÄÅËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºâ | Summary of the world's best LLM resources. 
[wangrongsheng.github.io/awesome-LLM-resourses/](https://wangrongsheng.github.io/awesome-LLM-resourses/ "https://wangrongsheng.github.io/awesome-LLM-resourses/")
### Topics
[ course ](https://github.com/topics/course "Topic: course") [ book ](https://github.com/topics/book "Topic: book") [ openai ](https://github.com/topics/openai "Topic: openai") [ awesome-list ](https://github.com/topics/awesome-list "Topic: awesome-list") [ webui ](https://github.com/topics/webui "Topic: webui") [ llama ](https://github.com/topics/llama "Topic: llama") [ mistral ](https://github.com/topics/mistral "Topic: mistral") [ rag ](https://github.com/topics/rag "Topic: rag") [ large-language-models ](https://github.com/topics/large-language-models "Topic: large-language-models") [ llm ](https://github.com/topics/llm "Topic: llm") [ retrieval-augmented-generation ](https://github.com/topics/retrieval-augmented-generation "Topic: retrieval-augmented-generation") [ qwen ](https://github.com/topics/qwen "Topic: qwen")
### Resources
[ Readme ](https://github.com/WangRongsheng/awesome-LLM-resourses#readme-ov-file)
### License
[ Apache-2.0 license ](https://github.com/WangRongsheng/awesome-LLM-resourses#Apache-2.0-1-ov-file)
### Code of conduct
[ Code of conduct ](https://github.com/WangRongsheng/awesome-LLM-resourses#coc-ov-file)
[ Activity](https://github.com/WangRongsheng/awesome-LLM-resourses/activity)
### Stars
[ **4.5k** stars](https://github.com/WangRongsheng/awesome-LLM-resourses/stargazers)
### Watchers
[ **64** watching](https://github.com/WangRongsheng/awesome-LLM-resourses/watchers)
### Forks
[ **472** forks](https://github.com/WangRongsheng/awesome-LLM-resourses/forks)
[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FWangRongsheng%2Fawesome-LLM-resourses&report=WangRongsheng+%28user%29)
##  [Contributors 7](https://github.com/WangRongsheng/awesome-LLM-resourses/graphs/contributors)
## Footer
[ ](https://github.com "GitHub") ¬© 2025 GitHub, Inc. 
### Footer navigation
  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
  * [Security](https://github.com/security)
  * [Status](https://www.githubstatus.com/)
  * [Docs](https://docs.github.com/)
  * [Contact](https://support.github.com?tags=dotcom-footer)
  * Manage cookies 
  * Do not share my personal information 


You can‚Äôt perform that action at this time. 
